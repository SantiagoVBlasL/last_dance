{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a943e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿GPU visible?: True\n",
      "¿GPU visible?: True\n",
      "torch.cuda.is_available -> True\n",
      "torch.version.cuda      -> 11.8\n",
      "cupy GPU visible        -> True\n",
      "fatal: no es un repositorio git (ni ninguno de los directorios superiores): .git\n",
      "[INFO] Git commit hash: N/A\n",
      "[INFO] --- Configuración de la Ejecución (v1.7.0) ---\n",
      "[INFO] batch_size: 64\n",
      "[INFO] beta_vae: 6.6\n",
      "[INFO] channels_to_use: [1, 2, 5]\n",
      "[INFO] classifier_calibrate: True\n",
      "[INFO] classifier_hp_tune_ratio: 0.25\n",
      "[INFO] classifier_stratify_cols: ['Sex']\n",
      "[INFO] classifier_types: ['xgb', 'svm', 'logreg']\n",
      "[INFO] classifier_use_class_weight: True\n",
      "[INFO] cyclical_beta_n_cycles: 4\n",
      "[INFO] cyclical_beta_ratio_increase: 0.4\n",
      "[INFO] decoder_type: convtranspose\n",
      "[INFO] dropout_rate_vae: 0.2\n",
      "[INFO] early_stopping_patience_vae: 30\n",
      "[INFO] epochs_vae: 300\n",
      "[INFO] git_hash: N/A\n",
      "[INFO] global_tensor_path: /home/diego/Escritorio/limpio/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "[INFO] gridsearch_scoring: roc_auc\n",
      "[INFO] inner_folds: 5\n",
      "[INFO] intermediate_fc_dim_vae: quarter\n",
      "[INFO] latent_dim: 256\n",
      "[INFO] latent_features_type: mu\n",
      "[INFO] log_interval_epochs_vae: 5\n",
      "[INFO] lr_scheduler_T0: 30\n",
      "[INFO] lr_scheduler_eta_min: 1e-07\n",
      "[INFO] lr_scheduler_patience_vae: 15\n",
      "[INFO] lr_scheduler_type: cosine_warm\n",
      "[INFO] lr_vae: 0.0001\n",
      "[INFO] metadata_features: ['Age', 'Sex']\n",
      "[INFO] metadata_path: /home/diego/Escritorio/limpio/SubjectsData_AAL3_procesado.csv\n",
      "[INFO] mlp_classifier_hidden_layers: 64,16\n",
      "[INFO] n_jobs_gridsearch: 8\n",
      "[INFO] norm_mode: zscore_offdiag\n",
      "[INFO] num_conv_layers_encoder: 4\n",
      "[INFO] num_workers: 4\n",
      "[INFO] outer_folds: 5\n",
      "[INFO] output_dir: ./resultados_FIN_v2\n",
      "[INFO] repeated_outer_folds_n_repeats: 1\n",
      "[INFO] save_fold_artefacts: True\n",
      "[INFO] save_vae_training_history: True\n",
      "[INFO] seed: 42\n",
      "[INFO] tune_sampler_params: False\n",
      "[INFO] use_layernorm_vae_fc: False\n",
      "[INFO] use_optuna_pruner: True\n",
      "[INFO] use_smote: True\n",
      "[INFO] vae_final_activation: tanh\n",
      "[INFO] vae_val_split_ratio: 0.2\n",
      "[INFO] weight_decay_vae: 1e-05\n",
      "[INFO] ------------------------------------\n",
      "[INFO] Cargando tensor global desde: /home/diego/Escritorio/limpio/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "[INFO] Tensor global cargado. Forma: (431, 7, 131, 131)\n",
      "[INFO] Cargando metadatos desde: /home/diego/Escritorio/limpio/SubjectsData_AAL3_procesado.csv\n",
      "[INFO] Metadatos cargados. Forma: (434, 32)\n",
      "[INFO] Usando canales seleccionados (índices): [1, 2, 5]\n",
      "[INFO] Nombres de canales seleccionados: ['Pearson_Full_FisherZ_Signed', 'MI_KNN_Symmetric', 'DistanceCorr']\n",
      "[INFO] Estratificando folds del CLASIFICADOR por: ['ResearchGroup_Mapped', 'Sex']\n",
      "[INFO] Sujetos CN/AD para clasificación: 184. CN: 89, AD: 95\n",
      "[INFO] Usando CV externa: StratifiedKFold con 5 iteraciones totales.\n",
      "[INFO] --- Iniciando Fold 1/5 ---\n",
      "[INFO] Fold 1/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 19 (51.4%)\n",
      "      M: 18 (48.6%)\n",
      "[INFO] Fold 1/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 187 (47.5%)\n",
      "      M: 207 (52.5%)\n",
      "    Age_Group:\n",
      "      0: 104 (26.4%)\n",
      "      1: 102 (25.9%)\n",
      "      2: 91 (23.1%)\n",
      "      3: 97 (24.6%)\n",
      "[INFO]   Fold 1/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 1/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 62 (19.7%)\n",
      "      CN: 56 (17.8%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 149 (47.3%)\n",
      "      M: 166 (52.7%)\n",
      "    Age_Group:\n",
      "      0: 84 (26.7%)\n",
      "      1: 81 (25.7%)\n",
      "      2: 73 (23.2%)\n",
      "      3: 77 (24.4%)\n",
      "[INFO] Fold 1/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 14 (17.7%)\n",
      "      CN: 15 (19.0%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 38 (48.1%)\n",
      "      M: 41 (51.9%)\n",
      "    Age_Group:\n",
      "      0: 20 (25.3%)\n",
      "      1: 21 (26.6%)\n",
      "      2: 18 (22.8%)\n",
      "      3: 20 (25.3%)\n",
      "[INFO]   Fold 1/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.046, std=0.777)\n",
      "[INFO] Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.059, std=0.815)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.397, std=1.627)\n",
      "[INFO]   Fold 1/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 1/5 Usando scheduler: CosineAnnealingWarmRestarts (T_0=30)\n",
      "[INFO]   Fold 1/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 1/5 VAE E5/300, TrL: 63276.75 (R: 63195.58, KLD: 92.25), Beta: 0.880, LR: 9.38e-05, ValL: 62047.47 (R: 62002.37, KLD: 51.25)\n",
      "[INFO]   Fold 1/5 VAE E10/300, TrL: 58395.53 (R: 57964.34, KLD: 217.77), Beta: 1.980, LR: 7.59e-05, ValL: 56246.84 (R: 55433.56, KLD: 410.75)\n",
      "[INFO]   Fold 1/5 VAE E15/300, TrL: 53332.07 (R: 52549.02, KLD: 254.24), Beta: 3.080, LR: 5.11e-05, ValL: 52745.15 (R: 51849.69, KLD: 290.74)\n",
      "[INFO]   Fold 1/5 VAE E20/300, TrL: 51814.90 (R: 51118.04, KLD: 166.71), Beta: 4.180, LR: 2.60e-05, ValL: 50919.44 (R: 50218.80, KLD: 167.62)\n",
      "[INFO]   Fold 1/5 VAE E25/300, TrL: 51201.99 (R: 50381.47, KLD: 155.40), Beta: 5.280, LR: 7.32e-06, ValL: 50364.44 (R: 49549.68, KLD: 154.31)\n",
      "[INFO]   Fold 1/5 VAE E30/300, TrL: 51226.32 (R: 50272.16, KLD: 149.55), Beta: 6.380, LR: 1.11e-07, ValL: 50402.86 (R: 49452.25, KLD: 149.00)\n",
      "[INFO]   Fold 1/5 VAE E35/300, TrL: 48286.30 (R: 47576.73, KLD: 107.51), Beta: 6.600, LR: 9.38e-05, ValL: 46532.94 (R: 45804.99, KLD: 110.30)\n",
      "[INFO]   Fold 1/5 VAE E40/300, TrL: 45666.46 (R: 45041.65, KLD: 94.67), Beta: 6.600, LR: 7.59e-05, ValL: 43852.44 (R: 43196.94, KLD: 99.32)\n",
      "[INFO]   Fold 1/5 VAE E45/300, TrL: 44041.84 (R: 43450.13, KLD: 89.65), Beta: 6.600, LR: 5.11e-05, ValL: 42327.47 (R: 41684.54, KLD: 97.41)\n",
      "[INFO]   Fold 1/5 VAE E50/300, TrL: 43088.56 (R: 42511.32, KLD: 87.46), Beta: 6.600, LR: 2.60e-05, ValL: 41427.54 (R: 40842.56, KLD: 88.63)\n",
      "[INFO]   Fold 1/5 VAE E55/300, TrL: 42601.28 (R: 42023.86, KLD: 87.49), Beta: 6.600, LR: 7.32e-06, ValL: 41169.55 (R: 40611.46, KLD: 84.56)\n",
      "[INFO]   Fold 1/5 VAE E60/300, TrL: 42553.83 (R: 41974.65, KLD: 87.75), Beta: 6.600, LR: 1.11e-07, ValL: 41057.80 (R: 40502.66, KLD: 84.11)\n",
      "[INFO]   Fold 1/5 VAE E65/300, TrL: 41514.51 (R: 40914.29, KLD: 90.94), Beta: 6.600, LR: 9.38e-05, ValL: 39804.89 (R: 39245.77, KLD: 84.72)\n",
      "[INFO]   Fold 1/5 VAE E70/300, TrL: 40418.28 (R: 39816.87, KLD: 91.12), Beta: 6.600, LR: 7.59e-05, ValL: 38995.67 (R: 38435.89, KLD: 84.82)\n",
      "[INFO]   Fold 1/5 VAE E75/300, TrL: 39784.27 (R: 39183.07, KLD: 91.09), Beta: 6.600, LR: 5.11e-05, ValL: 38528.48 (R: 37935.45, KLD: 89.85)\n",
      "[INFO]   Fold 1/5 VAE E80/300, TrL: 38760.99 (R: 38656.45, KLD: 118.79), Beta: 0.880, LR: 2.60e-05, ValL: 37687.38 (R: 37579.83, KLD: 122.22)\n",
      "[INFO]   Fold 1/5 VAE E85/300, TrL: 38797.46 (R: 38547.60, KLD: 126.19), Beta: 1.980, LR: 7.32e-06, ValL: 37663.72 (R: 37408.93, KLD: 128.68)\n",
      "[INFO]   Fold 1/5 VAE E90/300, TrL: 38830.65 (R: 38441.12, KLD: 126.47), Beta: 3.080, LR: 1.11e-07, ValL: 37757.15 (R: 37351.50, KLD: 131.70)\n",
      "[INFO]   Fold 1/5 VAE E95/300, TrL: 38355.59 (R: 37897.82, KLD: 109.51), Beta: 4.180, LR: 9.38e-05, ValL: 37280.16 (R: 36833.13, KLD: 106.94)\n",
      "[INFO]   Fold 1/5 VAE E100/300, TrL: 37934.30 (R: 37358.56, KLD: 109.04), Beta: 5.280, LR: 7.59e-05, ValL: 36934.19 (R: 36368.89, KLD: 107.06)\n",
      "[INFO]   Fold 1/5 VAE E105/300, TrL: 37517.21 (R: 36871.46, KLD: 101.21), Beta: 6.380, LR: 5.11e-05, ValL: 36562.44 (R: 35947.67, KLD: 96.36)\n",
      "[INFO]   Fold 1/5 VAE E110/300, TrL: 37347.53 (R: 36714.39, KLD: 95.93), Beta: 6.600, LR: 2.60e-05, ValL: 36383.21 (R: 35808.91, KLD: 87.02)\n",
      "[INFO]   Fold 1/5 VAE E115/300, TrL: 37233.24 (R: 36608.21, KLD: 94.70), Beta: 6.600, LR: 7.32e-06, ValL: 36275.10 (R: 35709.31, KLD: 85.73)\n",
      "[INFO]   Fold 1/5 VAE E120/300, TrL: 37264.29 (R: 36633.38, KLD: 95.59), Beta: 6.600, LR: 1.11e-07, ValL: 36183.44 (R: 35616.61, KLD: 85.88)\n",
      "[INFO]   Fold 1/5 VAE E125/300, TrL: 36907.75 (R: 36279.53, KLD: 95.19), Beta: 6.600, LR: 9.38e-05, ValL: 35829.40 (R: 35230.50, KLD: 90.74)\n",
      "[INFO]   Fold 1/5 VAE E130/300, TrL: 36488.28 (R: 35842.22, KLD: 97.89), Beta: 6.600, LR: 7.59e-05, ValL: 35546.23 (R: 34952.97, KLD: 89.89)\n",
      "[INFO]   Fold 1/5 VAE E135/300, TrL: 36308.44 (R: 35641.25, KLD: 101.09), Beta: 6.600, LR: 5.11e-05, ValL: 35319.66 (R: 34712.17, KLD: 92.04)\n",
      "[INFO]   Fold 1/5 VAE E140/300, TrL: 36129.01 (R: 35503.98, KLD: 94.70), Beta: 6.600, LR: 2.60e-05, ValL: 35139.04 (R: 34550.04, KLD: 89.24)\n",
      "[INFO]   Fold 1/5 VAE E145/300, TrL: 35953.55 (R: 35310.82, KLD: 97.38), Beta: 6.600, LR: 7.32e-06, ValL: 35055.27 (R: 34475.75, KLD: 87.81)\n",
      "[INFO]   Fold 1/5 VAE E150/300, TrL: 36012.32 (R: 35376.38, KLD: 96.35), Beta: 6.600, LR: 1.11e-07, ValL: 35037.61 (R: 34465.70, KLD: 86.65)\n",
      "[INFO]   Fold 1/5 VAE E155/300, TrL: 34997.68 (R: 34863.23, KLD: 152.79), Beta: 0.880, LR: 9.38e-05, ValL: 34224.77 (R: 34086.82, KLD: 156.76)\n",
      "[INFO]   Fold 1/5 VAE E160/300, TrL: 34749.84 (R: 34396.51, KLD: 178.45), Beta: 1.980, LR: 7.59e-05, ValL: 34077.77 (R: 33736.33, KLD: 172.45)\n",
      "[INFO]   Fold 1/5 VAE E165/300, TrL: 34797.62 (R: 34290.07, KLD: 164.79), Beta: 3.080, LR: 5.11e-05, ValL: 34055.86 (R: 33560.31, KLD: 160.89)\n",
      "[INFO]   Fold 1/5 VAE E170/300, TrL: 34810.69 (R: 34172.79, KLD: 152.61), Beta: 4.180, LR: 2.60e-05, ValL: 34102.20 (R: 33496.06, KLD: 145.01)\n",
      "[INFO]   Fold 1/5 VAE E175/300, TrL: 34714.89 (R: 33962.45, KLD: 142.51), Beta: 5.280, LR: 7.32e-06, ValL: 34180.47 (R: 33479.33, KLD: 132.79)\n",
      "[INFO]   Fold 1/5 VAE E180/300, TrL: 35003.82 (R: 34096.20, KLD: 142.26), Beta: 6.380, LR: 1.11e-07, ValL: 34301.87 (R: 33465.67, KLD: 131.07)\n",
      "[INFO]   Fold 1/5 VAE E185/300, TrL: 34807.00 (R: 34100.88, KLD: 106.99), Beta: 6.600, LR: 9.38e-05, ValL: 34152.14 (R: 33471.65, KLD: 103.10)\n",
      "[INFO]   Fold 1/5 VAE E190/300, TrL: 34542.96 (R: 33840.08, KLD: 106.50), Beta: 6.600, LR: 7.59e-05, ValL: 33909.77 (R: 33295.21, KLD: 93.11)\n",
      "[INFO]   Fold 1/5 VAE E195/300, TrL: 34304.51 (R: 33607.91, KLD: 105.54), Beta: 6.600, LR: 5.11e-05, ValL: 33770.99 (R: 33124.64, KLD: 97.93)\n",
      "[INFO]   Fold 1/5 VAE E200/300, TrL: 34196.33 (R: 33508.60, KLD: 104.20), Beta: 6.600, LR: 2.60e-05, ValL: 33681.11 (R: 33068.09, KLD: 92.88)\n",
      "[INFO]   Fold 1/5 VAE E205/300, TrL: 34163.07 (R: 33475.01, KLD: 104.25), Beta: 6.600, LR: 7.32e-06, ValL: 33568.87 (R: 32966.28, KLD: 91.30)\n",
      "[INFO]   Fold 1/5 VAE E210/300, TrL: 34136.39 (R: 33448.94, KLD: 104.16), Beta: 6.600, LR: 1.11e-07, ValL: 33506.11 (R: 32904.25, KLD: 91.19)\n",
      "[INFO]   Fold 1/5 VAE E215/300, TrL: 33983.72 (R: 33281.18, KLD: 106.45), Beta: 6.600, LR: 9.38e-05, ValL: 33522.75 (R: 32898.28, KLD: 94.62)\n",
      "[INFO]   Fold 1/5 VAE E220/300, TrL: 33807.05 (R: 33101.76, KLD: 106.86), Beta: 6.600, LR: 7.59e-05, ValL: 33302.36 (R: 32677.62, KLD: 94.66)\n",
      "[INFO]   Fold 1/5 VAE E225/300, TrL: 33733.52 (R: 33031.87, KLD: 106.31), Beta: 6.600, LR: 5.11e-05, ValL: 33172.52 (R: 32555.27, KLD: 93.52)\n",
      "[INFO]   Fold 1/5 VAE E230/300, TrL: 32955.04 (R: 32840.87, KLD: 129.74), Beta: 0.880, LR: 2.60e-05, ValL: 32579.81 (R: 32475.05, KLD: 119.04)\n",
      "[INFO]   Fold 1/5 VAE E235/300, TrL: 32938.62 (R: 32667.00, KLD: 137.18), Beta: 1.980, LR: 7.32e-06, ValL: 32593.78 (R: 32345.51, KLD: 125.39)\n",
      "[INFO]   Fold 1/5 VAE E240/300, TrL: 33047.55 (R: 32619.69, KLD: 138.92), Beta: 3.080, LR: 1.11e-07, ValL: 32773.89 (R: 32380.09, KLD: 127.86)\n",
      "[INFO]   Fold 1/5 VAE E245/300, TrL: 33138.53 (R: 32558.97, KLD: 138.65), Beta: 4.180, LR: 9.38e-05, ValL: 32791.30 (R: 32273.63, KLD: 123.84)\n",
      "[INFO]   Fold 1/5 VAE E250/300, TrL: 32985.21 (R: 32300.90, KLD: 129.60), Beta: 5.280, LR: 7.59e-05, ValL: 32759.50 (R: 32148.76, KLD: 115.67)\n",
      "[INFO]   Fold 1/5 VAE E255/300, TrL: 33039.19 (R: 32264.39, KLD: 121.44), Beta: 6.380, LR: 5.11e-05, ValL: 32778.19 (R: 32114.43, KLD: 104.04)\n",
      "[INFO]   Fold 1/5 Early stopping VAE en epoch 258. Mejor val_loss: 32510.9195\n",
      "[INFO]   Fold 1/5 VAE final model loaded (best val_loss: 32510.9195).\n",
      "[INFO]   Fold 1/5 Modelo VAE guardado en: resultados_FIN_v2/fold_1/vae_model_fold_1.pt\n",
      "[INFO] Fold 1/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 73 (49.7%)\n",
      "      M: 74 (50.3%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 258)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 345, 'model__learning_rate': 0.021947577388656367, 'model__max_depth': 6, 'model__subsample': 0.7333284812098514, 'model__colsample_bytree': 0.26163344894030083, 'model__min_child_weight': 1.1138779789931483}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 1 (xgb): AUC=0.8743, Bal.Acc=0.7822\n",
      "[INFO]       Pipeline completo de xgb del fold 1 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__estimator__C': 297.483069977277, 'model__estimator__gamma': 0.00012042250173935259, 'model__estimator__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 1 (svm): AUC=0.8363, Bal.Acc=0.7573\n",
      "[INFO]       Pipeline completo de svm del fold 1 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.010910923027412167}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 1 (logreg): AUC=0.8889, Bal.Acc=0.8085\n",
      "[INFO]       Pipeline completo de logreg del fold 1 guardado.\n",
      "[INFO]   Fold 1/5 completado en 286.65 segundos.\n",
      "[INFO] --- Iniciando Fold 2/5 ---\n",
      "[INFO] Fold 2/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 19 (51.4%)\n",
      "      M: 18 (48.6%)\n",
      "[INFO] Fold 2/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 187 (47.5%)\n",
      "      M: 207 (52.5%)\n",
      "    Age_Group:\n",
      "      0: 98 (24.9%)\n",
      "      1: 101 (25.6%)\n",
      "      2: 94 (23.9%)\n",
      "      3: 101 (25.6%)\n",
      "[INFO]   Fold 2/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 2/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 61 (19.4%)\n",
      "      CN: 57 (18.1%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 150 (47.6%)\n",
      "      M: 165 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 79 (25.1%)\n",
      "      1: 81 (25.7%)\n",
      "      2: 75 (23.8%)\n",
      "      3: 80 (25.4%)\n",
      "[INFO] Fold 2/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 15 (19.0%)\n",
      "      CN: 14 (17.7%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 37 (46.8%)\n",
      "      M: 42 (53.2%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 20 (25.3%)\n",
      "      2: 19 (24.1%)\n",
      "      3: 21 (26.6%)\n",
      "[INFO]   Fold 2/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.049, std=0.776)\n",
      "[INFO] Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.055, std=0.813)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.408, std=1.730)\n",
      "[INFO]   Fold 2/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 2/5 Usando scheduler: CosineAnnealingWarmRestarts (T_0=30)\n",
      "[INFO]   Fold 2/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 2/5 VAE E5/300, TrL: 63840.16 (R: 63761.01, KLD: 89.94), Beta: 0.880, LR: 9.38e-05, ValL: 57931.68 (R: 57893.04, KLD: 43.91)\n",
      "[INFO]   Fold 2/5 VAE E10/300, TrL: 60253.30 (R: 59934.16, KLD: 161.18), Beta: 1.980, LR: 7.59e-05, ValL: 53158.00 (R: 52562.44, KLD: 300.78)\n",
      "[INFO]   Fold 2/5 VAE E15/300, TrL: 54787.42 (R: 53966.47, KLD: 266.54), Beta: 3.080, LR: 5.11e-05, ValL: 49229.23 (R: 47918.08, KLD: 425.70)\n",
      "[INFO]   Fold 2/5 VAE E20/300, TrL: 52628.05 (R: 51847.73, KLD: 186.68), Beta: 4.180, LR: 2.60e-05, ValL: 47318.82 (R: 46398.45, KLD: 220.18)\n",
      "[INFO]   Fold 2/5 VAE E25/300, TrL: 52099.43 (R: 51259.97, KLD: 158.99), Beta: 5.280, LR: 7.32e-06, ValL: 46845.01 (R: 45887.76, KLD: 181.30)\n",
      "[INFO]   Fold 2/5 VAE E30/300, TrL: 52169.50 (R: 51196.94, KLD: 152.44), Beta: 6.380, LR: 1.11e-07, ValL: 46932.29 (R: 45806.72, KLD: 176.42)\n",
      "[INFO]   Fold 2/5 VAE E35/300, TrL: 49449.91 (R: 48728.81, KLD: 109.26), Beta: 6.600, LR: 9.38e-05, ValL: 43812.55 (R: 43064.12, KLD: 113.40)\n",
      "[INFO]   Fold 2/5 VAE E40/300, TrL: 46827.92 (R: 46195.84, KLD: 95.77), Beta: 6.600, LR: 7.59e-05, ValL: 40817.24 (R: 40148.76, KLD: 101.28)\n",
      "[INFO]   Fold 2/5 VAE E45/300, TrL: 45006.23 (R: 44421.84, KLD: 88.54), Beta: 6.600, LR: 5.11e-05, ValL: 38846.45 (R: 38236.95, KLD: 92.35)\n",
      "[INFO]   Fold 2/5 VAE E50/300, TrL: 43997.08 (R: 43426.34, KLD: 86.48), Beta: 6.600, LR: 2.60e-05, ValL: 37956.96 (R: 37384.35, KLD: 86.76)\n",
      "[INFO]   Fold 2/5 VAE E55/300, TrL: 43676.90 (R: 43105.64, KLD: 86.56), Beta: 6.600, LR: 7.32e-06, ValL: 37634.02 (R: 37078.77, KLD: 84.13)\n",
      "[INFO]   Fold 2/5 VAE E60/300, TrL: 43544.33 (R: 42974.15, KLD: 86.39), Beta: 6.600, LR: 1.11e-07, ValL: 37483.61 (R: 36940.09, KLD: 82.35)\n",
      "[INFO]   Fold 2/5 VAE E65/300, TrL: 42130.89 (R: 41562.25, KLD: 86.16), Beta: 6.600, LR: 9.38e-05, ValL: 36234.20 (R: 35611.87, KLD: 94.29)\n",
      "[INFO]   Fold 2/5 VAE E70/300, TrL: 41004.18 (R: 40428.46, KLD: 87.23), Beta: 6.600, LR: 7.59e-05, ValL: 35130.15 (R: 34589.87, KLD: 81.86)\n",
      "[INFO]   Fold 2/5 VAE E75/300, TrL: 40252.59 (R: 39648.46, KLD: 91.54), Beta: 6.600, LR: 5.11e-05, ValL: 34543.88 (R: 33977.19, KLD: 85.86)\n",
      "[INFO]   Fold 2/5 VAE E80/300, TrL: 39241.19 (R: 39135.93, KLD: 119.62), Beta: 0.880, LR: 2.60e-05, ValL: 33532.28 (R: 33423.38, KLD: 123.76)\n",
      "[INFO]   Fold 2/5 VAE E85/300, TrL: 39287.39 (R: 39037.33, KLD: 126.29), Beta: 1.980, LR: 7.32e-06, ValL: 33578.13 (R: 33317.08, KLD: 131.84)\n",
      "[INFO]   Fold 2/5 VAE E90/300, TrL: 39420.02 (R: 39029.97, KLD: 126.64), Beta: 3.080, LR: 1.11e-07, ValL: 33673.98 (R: 33276.15, KLD: 129.16)\n",
      "[INFO]   Fold 2/5 VAE E95/300, TrL: 38861.26 (R: 38390.46, KLD: 112.63), Beta: 4.180, LR: 9.38e-05, ValL: 33079.20 (R: 32574.51, KLD: 120.74)\n",
      "[INFO]   Fold 2/5 VAE E100/300, TrL: 38336.24 (R: 37751.96, KLD: 110.66), Beta: 5.280, LR: 7.59e-05, ValL: 32612.35 (R: 31981.10, KLD: 119.55)\n",
      "[INFO]   Fold 2/5 VAE E105/300, TrL: 38066.59 (R: 37406.85, KLD: 103.41), Beta: 6.380, LR: 5.11e-05, ValL: 32281.36 (R: 31666.99, KLD: 96.30)\n",
      "[INFO]   Fold 2/5 VAE E110/300, TrL: 37747.89 (R: 37081.11, KLD: 101.03), Beta: 6.600, LR: 2.60e-05, ValL: 32097.84 (R: 31474.14, KLD: 94.50)\n",
      "[INFO]   Fold 2/5 VAE E115/300, TrL: 37606.74 (R: 36968.71, KLD: 96.67), Beta: 6.600, LR: 7.32e-06, ValL: 32020.95 (R: 31431.95, KLD: 89.24)\n",
      "[INFO]   Fold 2/5 VAE E120/300, TrL: 37452.67 (R: 36807.05, KLD: 97.82), Beta: 6.600, LR: 1.11e-07, ValL: 32029.74 (R: 31451.05, KLD: 87.68)\n",
      "[INFO]   Fold 2/5 VAE E125/300, TrL: 37262.30 (R: 36614.44, KLD: 98.16), Beta: 6.600, LR: 9.38e-05, ValL: 31566.06 (R: 30974.60, KLD: 89.61)\n",
      "[INFO]   Fold 2/5 VAE E130/300, TrL: 36809.53 (R: 36153.57, KLD: 99.39), Beta: 6.600, LR: 7.59e-05, ValL: 31247.45 (R: 30667.09, KLD: 87.93)\n",
      "[INFO]   Fold 2/5 VAE E135/300, TrL: 36539.69 (R: 35873.02, KLD: 101.01), Beta: 6.600, LR: 5.11e-05, ValL: 31001.02 (R: 30391.68, KLD: 92.33)\n",
      "[INFO]   Fold 2/5 VAE E140/300, TrL: 36215.53 (R: 35559.61, KLD: 99.38), Beta: 6.600, LR: 2.60e-05, ValL: 30863.42 (R: 30269.07, KLD: 90.05)\n",
      "[INFO]   Fold 2/5 VAE E145/300, TrL: 36130.93 (R: 35486.48, KLD: 97.64), Beta: 6.600, LR: 7.32e-06, ValL: 30767.10 (R: 30183.16, KLD: 88.48)\n",
      "[INFO]   Fold 2/5 VAE E150/300, TrL: 36083.93 (R: 35443.89, KLD: 96.98), Beta: 6.600, LR: 1.11e-07, ValL: 30711.90 (R: 30132.32, KLD: 87.82)\n",
      "[INFO]   Fold 2/5 VAE E155/300, TrL: 35185.92 (R: 35040.45, KLD: 165.31), Beta: 0.880, LR: 9.38e-05, ValL: 29834.33 (R: 29678.02, KLD: 177.62)\n",
      "[INFO]   Fold 2/5 VAE E160/300, TrL: 34995.47 (R: 34640.02, KLD: 179.52), Beta: 1.980, LR: 7.59e-05, ValL: 29734.62 (R: 29399.57, KLD: 169.22)\n",
      "[INFO]   Fold 2/5 VAE E165/300, TrL: 34997.41 (R: 34478.31, KLD: 168.54), Beta: 3.080, LR: 5.11e-05, ValL: 29595.49 (R: 29098.52, KLD: 161.35)\n",
      "[INFO]   Fold 2/5 VAE E170/300, TrL: 34949.67 (R: 34294.72, KLD: 156.69), Beta: 4.180, LR: 2.60e-05, ValL: 29576.92 (R: 28950.96, KLD: 149.75)\n",
      "[INFO]   Fold 2/5 VAE E175/300, TrL: 34940.55 (R: 34168.07, KLD: 146.30), Beta: 5.280, LR: 7.32e-06, ValL: 29764.26 (R: 29047.04, KLD: 135.84)\n",
      "[INFO]   Fold 2/5 VAE E180/300, TrL: 35251.54 (R: 34324.24, KLD: 145.35), Beta: 6.380, LR: 1.11e-07, ValL: 29832.48 (R: 28985.23, KLD: 132.80)\n",
      "[INFO]   Fold 2/5 VAE E185/300, TrL: 35005.03 (R: 34254.57, KLD: 113.71), Beta: 6.600, LR: 9.38e-05, ValL: 29664.56 (R: 28952.94, KLD: 107.82)\n",
      "[INFO]   Fold 2/5 VAE E190/300, TrL: 34799.76 (R: 34067.59, KLD: 110.93), Beta: 6.600, LR: 7.59e-05, ValL: 29430.11 (R: 28762.52, KLD: 101.15)\n",
      "[INFO]   Fold 2/5 VAE E195/300, TrL: 34521.99 (R: 33817.96, KLD: 106.67), Beta: 6.600, LR: 5.11e-05, ValL: 29365.81 (R: 28746.54, KLD: 93.83)\n",
      "[INFO]   Fold 2/5 VAE E200/300, TrL: 34415.45 (R: 33705.60, KLD: 107.55), Beta: 6.600, LR: 2.60e-05, ValL: 29140.32 (R: 28525.96, KLD: 93.09)\n",
      "[INFO]   Fold 2/5 VAE E205/300, TrL: 34303.19 (R: 33595.39, KLD: 107.24), Beta: 6.600, LR: 7.32e-06, ValL: 29110.83 (R: 28502.49, KLD: 92.17)\n",
      "[INFO]   Fold 2/5 VAE E210/300, TrL: 34332.05 (R: 33623.90, KLD: 107.30), Beta: 6.600, LR: 1.11e-07, ValL: 29075.48 (R: 28470.98, KLD: 91.59)\n",
      "[INFO]   Fold 2/5 VAE E215/300, TrL: 34174.30 (R: 33449.40, KLD: 109.83), Beta: 6.600, LR: 9.38e-05, ValL: 29024.15 (R: 28386.73, KLD: 96.58)\n",
      "[INFO]   Fold 2/5 VAE E220/300, TrL: 34119.67 (R: 33359.04, KLD: 115.25), Beta: 6.600, LR: 7.59e-05, ValL: 28882.72 (R: 28224.19, KLD: 99.78)\n",
      "[INFO]   Fold 2/5 VAE E225/300, TrL: 33790.07 (R: 33070.73, KLD: 108.99), Beta: 6.600, LR: 5.11e-05, ValL: 28797.61 (R: 28170.65, KLD: 94.99)\n",
      "[INFO]   Fold 2/5 VAE E230/300, TrL: 33050.24 (R: 32935.70, KLD: 130.16), Beta: 0.880, LR: 2.60e-05, ValL: 28091.22 (R: 27987.15, KLD: 118.26)\n",
      "[INFO]   Fold 2/5 VAE E235/300, TrL: 33067.34 (R: 32792.71, KLD: 138.70), Beta: 1.980, LR: 7.32e-06, ValL: 28177.16 (R: 27932.23, KLD: 123.70)\n",
      "[INFO]   Fold 2/5 VAE E240/300, TrL: 33197.99 (R: 32770.02, KLD: 138.95), Beta: 3.080, LR: 1.11e-07, ValL: 28251.68 (R: 27863.99, KLD: 125.87)\n",
      "[INFO]   Fold 2/5 VAE E245/300, TrL: 33220.31 (R: 32627.47, KLD: 141.83), Beta: 4.180, LR: 9.38e-05, ValL: 28276.32 (R: 27764.95, KLD: 122.34)\n",
      "[INFO]   Fold 2/5 VAE E250/300, TrL: 33311.29 (R: 32613.56, KLD: 132.15), Beta: 5.280, LR: 7.59e-05, ValL: 28338.96 (R: 27741.75, KLD: 113.11)\n",
      "[INFO]   Fold 2/5 VAE E255/300, TrL: 33281.09 (R: 32494.11, KLD: 123.35), Beta: 6.380, LR: 5.11e-05, ValL: 28328.34 (R: 27662.07, KLD: 104.43)\n",
      "[INFO]   Fold 2/5 VAE E260/300, TrL: 33323.17 (R: 32545.10, KLD: 117.89), Beta: 6.600, LR: 2.60e-05, ValL: 28204.53 (R: 27546.26, KLD: 99.74)\n",
      "[INFO]   Fold 2/5 Early stopping VAE en epoch 261. Mejor val_loss: 28024.7600\n",
      "[INFO]   Fold 2/5 VAE final model loaded (best val_loss: 28024.7600).\n",
      "[INFO]   Fold 2/5 Modelo VAE guardado en: resultados_FIN_v2/fold_2/vae_model_fold_2.pt\n",
      "[INFO] Fold 2/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 73 (49.7%)\n",
      "      M: 74 (50.3%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 258)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 230, 'model__learning_rate': 0.010324363450554094, 'model__max_depth': 12, 'model__subsample': 0.9402591563343392, 'model__colsample_bytree': 0.38953635867149417, 'model__min_child_weight': 0.7017751918189853}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 2 (xgb): AUC=0.6579, Bal.Acc=0.6213\n",
      "[INFO]       Pipeline completo de xgb del fold 2 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__estimator__C': 5815.6026056907085, 'model__estimator__gamma': 3.686425592100406e-07, 'model__estimator__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 2 (svm): AUC=0.7982, Bal.Acc=0.6754\n",
      "[INFO]       Pipeline completo de svm del fold 2 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.009159165849103099}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 2 (logreg): AUC=0.7778, Bal.Acc=0.7325\n",
      "[INFO]       Pipeline completo de logreg del fold 2 guardado.\n",
      "[INFO]   Fold 2/5 completado en 208.17 segundos.\n",
      "[INFO] --- Iniciando Fold 3/5 ---\n",
      "[INFO] Fold 3/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 18 (48.6%)\n",
      "      M: 19 (51.4%)\n",
      "[INFO] Fold 3/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 188 (47.7%)\n",
      "      M: 206 (52.3%)\n",
      "    Age_Group:\n",
      "      0: 97 (24.6%)\n",
      "      1: 104 (26.4%)\n",
      "      2: 97 (24.6%)\n",
      "      3: 96 (24.4%)\n",
      "[INFO]   Fold 3/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 3/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 60 (19.0%)\n",
      "      CN: 58 (18.4%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 150 (47.6%)\n",
      "      M: 165 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 78 (24.8%)\n",
      "      1: 83 (26.3%)\n",
      "      2: 78 (24.8%)\n",
      "      3: 76 (24.1%)\n",
      "[INFO] Fold 3/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 16 (20.3%)\n",
      "      CN: 13 (16.5%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 38 (48.1%)\n",
      "      M: 41 (51.9%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 21 (26.6%)\n",
      "      2: 19 (24.1%)\n",
      "      3: 20 (25.3%)\n",
      "[INFO]   Fold 3/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.050, std=0.780)\n",
      "[INFO] Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.054, std=0.812)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.419, std=1.767)\n",
      "[INFO]   Fold 3/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 3/5 Usando scheduler: CosineAnnealingWarmRestarts (T_0=30)\n",
      "[INFO]   Fold 3/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 3/5 VAE E5/300, TrL: 62946.52 (R: 62866.78, KLD: 90.61), Beta: 0.880, LR: 9.38e-05, ValL: 55467.59 (R: 55424.80, KLD: 48.63)\n",
      "[INFO]   Fold 3/5 VAE E10/300, TrL: 58657.30 (R: 58283.49, KLD: 188.80), Beta: 1.980, LR: 7.59e-05, ValL: 50351.93 (R: 49520.69, KLD: 419.82)\n",
      "[INFO]   Fold 3/5 VAE E15/300, TrL: 53199.77 (R: 52360.97, KLD: 272.34), Beta: 3.080, LR: 5.11e-05, ValL: 47355.12 (R: 45983.59, KLD: 445.30)\n",
      "[INFO]   Fold 3/5 VAE E20/300, TrL: 51731.01 (R: 51036.43, KLD: 166.17), Beta: 4.180, LR: 2.60e-05, ValL: 45727.27 (R: 44813.67, KLD: 218.57)\n",
      "[INFO]   Fold 3/5 VAE E25/300, TrL: 51376.98 (R: 50609.04, KLD: 145.44), Beta: 5.280, LR: 7.32e-06, ValL: 45442.64 (R: 44397.91, KLD: 197.86)\n",
      "[INFO]   Fold 3/5 VAE E30/300, TrL: 51380.22 (R: 50460.71, KLD: 144.12), Beta: 6.380, LR: 1.11e-07, ValL: 45483.38 (R: 44275.11, KLD: 189.38)\n",
      "[INFO]   Fold 3/5 VAE E35/300, TrL: 49008.29 (R: 48341.40, KLD: 101.04), Beta: 6.600, LR: 9.38e-05, ValL: 42468.49 (R: 41622.72, KLD: 128.15)\n",
      "[INFO]   Fold 3/5 VAE E40/300, TrL: 46498.31 (R: 45901.50, KLD: 90.43), Beta: 6.600, LR: 7.59e-05, ValL: 40003.13 (R: 39182.75, KLD: 124.30)\n",
      "[INFO]   Fold 3/5 VAE E45/300, TrL: 44771.39 (R: 44198.78, KLD: 86.76), Beta: 6.600, LR: 5.11e-05, ValL: 38345.72 (R: 37638.60, KLD: 107.14)\n",
      "[INFO]   Fold 3/5 VAE E50/300, TrL: 43929.09 (R: 43383.86, KLD: 82.61), Beta: 6.600, LR: 2.60e-05, ValL: 37494.87 (R: 36858.14, KLD: 96.47)\n",
      "[INFO]   Fold 3/5 VAE E55/300, TrL: 43519.48 (R: 42973.86, KLD: 82.67), Beta: 6.600, LR: 7.32e-06, ValL: 37140.33 (R: 36528.77, KLD: 92.66)\n",
      "[INFO]   Fold 3/5 VAE E60/300, TrL: 43458.79 (R: 42908.13, KLD: 83.43), Beta: 6.600, LR: 1.11e-07, ValL: 37062.63 (R: 36445.60, KLD: 93.49)\n",
      "[INFO]   Fold 3/5 VAE E65/300, TrL: 42078.37 (R: 41519.19, KLD: 84.72), Beta: 6.600, LR: 9.38e-05, ValL: 35679.26 (R: 35028.96, KLD: 98.53)\n",
      "[INFO]   Fold 3/5 VAE E70/300, TrL: 41011.02 (R: 40442.26, KLD: 86.18), Beta: 6.600, LR: 7.59e-05, ValL: 34629.51 (R: 34009.03, KLD: 94.01)\n",
      "[INFO]   Fold 3/5 VAE E75/300, TrL: 40346.41 (R: 39787.35, KLD: 84.71), Beta: 6.600, LR: 5.11e-05, ValL: 34006.85 (R: 33400.21, KLD: 91.92)\n",
      "[INFO]   Fold 3/5 VAE E80/300, TrL: 39250.84 (R: 39147.99, KLD: 116.87), Beta: 0.880, LR: 2.60e-05, ValL: 33131.00 (R: 33008.85, KLD: 138.81)\n",
      "[INFO]   Fold 3/5 VAE E85/300, TrL: 39220.86 (R: 38972.10, KLD: 125.64), Beta: 1.980, LR: 7.32e-06, ValL: 33110.07 (R: 32805.72, KLD: 153.71)\n",
      "[INFO]   Fold 3/5 VAE E90/300, TrL: 39329.96 (R: 38945.77, KLD: 124.74), Beta: 3.080, LR: 1.11e-07, ValL: 33231.32 (R: 32757.86, KLD: 153.72)\n",
      "[INFO]   Fold 3/5 VAE E95/300, TrL: 38821.96 (R: 38338.04, KLD: 115.77), Beta: 4.180, LR: 9.38e-05, ValL: 32666.45 (R: 32071.72, KLD: 142.28)\n",
      "[INFO]   Fold 3/5 VAE E100/300, TrL: 38117.80 (R: 37549.56, KLD: 107.62), Beta: 5.280, LR: 7.59e-05, ValL: 32070.29 (R: 31450.39, KLD: 117.40)\n",
      "[INFO]   Fold 3/5 VAE E105/300, TrL: 37855.61 (R: 37222.17, KLD: 99.29), Beta: 6.380, LR: 5.11e-05, ValL: 31789.85 (R: 31106.87, KLD: 107.05)\n",
      "[INFO]   Fold 3/5 VAE E110/300, TrL: 37604.73 (R: 36972.68, KLD: 95.76), Beta: 6.600, LR: 2.60e-05, ValL: 31493.28 (R: 30838.02, KLD: 99.28)\n",
      "[INFO]   Fold 3/5 VAE E115/300, TrL: 37395.81 (R: 36790.77, KLD: 91.67), Beta: 6.600, LR: 7.32e-06, ValL: 31344.19 (R: 30741.90, KLD: 91.26)\n",
      "[INFO]   Fold 3/5 VAE E120/300, TrL: 37341.02 (R: 36715.60, KLD: 94.76), Beta: 6.600, LR: 1.11e-07, ValL: 31370.43 (R: 30743.17, KLD: 95.04)\n",
      "[INFO]   Fold 3/5 VAE E125/300, TrL: 36962.88 (R: 36329.06, KLD: 96.03), Beta: 6.600, LR: 9.38e-05, ValL: 31009.86 (R: 30361.41, KLD: 98.25)\n",
      "[INFO]   Fold 3/5 VAE E130/300, TrL: 36518.56 (R: 35865.77, KLD: 98.91), Beta: 6.600, LR: 7.59e-05, ValL: 30769.67 (R: 30055.86, KLD: 108.15)\n",
      "[INFO]   Fold 3/5 VAE E135/300, TrL: 36302.25 (R: 35678.90, KLD: 94.45), Beta: 6.600, LR: 5.11e-05, ValL: 30429.73 (R: 29813.04, KLD: 93.44)\n",
      "[INFO]   Fold 3/5 VAE E140/300, TrL: 36048.97 (R: 35421.23, KLD: 95.11), Beta: 6.600, LR: 2.60e-05, ValL: 30212.54 (R: 29604.65, KLD: 92.10)\n",
      "[INFO]   Fold 3/5 VAE E145/300, TrL: 35950.93 (R: 35315.72, KLD: 96.24), Beta: 6.600, LR: 7.32e-06, ValL: 30169.24 (R: 29552.99, KLD: 93.37)\n",
      "[INFO]   Fold 3/5 VAE E150/300, TrL: 36037.63 (R: 35407.43, KLD: 95.49), Beta: 6.600, LR: 1.11e-07, ValL: 30190.26 (R: 29580.12, KLD: 92.45)\n",
      "[INFO]   Fold 3/5 VAE E155/300, TrL: 34972.42 (R: 34831.84, KLD: 159.75), Beta: 0.880, LR: 9.38e-05, ValL: 29306.97 (R: 29153.46, KLD: 174.43)\n",
      "[INFO]   Fold 3/5 VAE E160/300, TrL: 34838.36 (R: 34485.98, KLD: 177.97), Beta: 1.980, LR: 7.59e-05, ValL: 29239.41 (R: 28839.31, KLD: 202.07)\n",
      "[INFO]   Fold 3/5 VAE E165/300, TrL: 34778.45 (R: 34270.15, KLD: 165.04), Beta: 3.080, LR: 5.11e-05, ValL: 29245.05 (R: 28706.75, KLD: 174.77)\n",
      "[INFO]   Fold 3/5 VAE E170/300, TrL: 34703.60 (R: 34074.91, KLD: 150.40), Beta: 4.180, LR: 2.60e-05, ValL: 29268.69 (R: 28621.21, KLD: 154.90)\n",
      "[INFO]   Fold 3/5 VAE E175/300, TrL: 34826.05 (R: 34068.97, KLD: 143.39), Beta: 5.280, LR: 7.32e-06, ValL: 29346.60 (R: 28579.94, KLD: 145.20)\n",
      "[INFO]   Fold 3/5 VAE E180/300, TrL: 34887.01 (R: 33981.94, KLD: 141.86), Beta: 6.380, LR: 1.11e-07, ValL: 29453.49 (R: 28556.89, KLD: 140.53)\n",
      "[INFO]   Fold 3/5 VAE E185/300, TrL: 34734.21 (R: 34010.23, KLD: 109.69), Beta: 6.600, LR: 9.38e-05, ValL: 29271.24 (R: 28589.54, KLD: 103.29)\n",
      "[INFO]   Fold 3/5 VAE E190/300, TrL: 34509.51 (R: 33779.42, KLD: 110.62), Beta: 6.600, LR: 7.59e-05, ValL: 29065.28 (R: 28374.72, KLD: 104.63)\n",
      "[INFO]   Fold 3/5 VAE E195/300, TrL: 34474.14 (R: 33757.80, KLD: 108.54), Beta: 6.600, LR: 5.11e-05, ValL: 28928.65 (R: 28251.18, KLD: 102.65)\n",
      "[INFO]   Fold 3/5 VAE E200/300, TrL: 34222.97 (R: 33521.37, KLD: 106.30), Beta: 6.600, LR: 2.60e-05, ValL: 28792.38 (R: 28137.91, KLD: 99.16)\n",
      "[INFO]   Fold 3/5 VAE E205/300, TrL: 34124.27 (R: 33425.42, KLD: 105.89), Beta: 6.600, LR: 7.32e-06, ValL: 28770.19 (R: 28126.17, KLD: 97.58)\n",
      "[INFO]   Fold 3/5 VAE E210/300, TrL: 34159.95 (R: 33462.16, KLD: 105.73), Beta: 6.600, LR: 1.11e-07, ValL: 28799.79 (R: 28162.84, KLD: 96.51)\n",
      "[INFO]   Fold 3/5 VAE E215/300, TrL: 34118.26 (R: 33406.57, KLD: 107.83), Beta: 6.600, LR: 9.38e-05, ValL: 28672.84 (R: 28019.62, KLD: 98.97)\n",
      "[INFO]   Fold 3/5 VAE E220/300, TrL: 33854.16 (R: 33135.80, KLD: 108.84), Beta: 6.600, LR: 7.59e-05, ValL: 28460.19 (R: 27813.47, KLD: 97.99)\n",
      "[INFO]   Fold 3/5 VAE E225/300, TrL: 33600.58 (R: 32880.96, KLD: 109.03), Beta: 6.600, LR: 5.11e-05, ValL: 28331.90 (R: 27700.01, KLD: 95.74)\n",
      "[INFO]   Fold 3/5 VAE E230/300, TrL: 32888.46 (R: 32773.69, KLD: 130.42), Beta: 0.880, LR: 2.60e-05, ValL: 27703.77 (R: 27592.55, KLD: 126.38)\n",
      "[INFO]   Fold 3/5 VAE E235/300, TrL: 32943.21 (R: 32666.03, KLD: 139.99), Beta: 1.980, LR: 7.32e-06, ValL: 27778.24 (R: 27509.11, KLD: 135.93)\n",
      "[INFO]   Fold 3/5 VAE E240/300, TrL: 33146.07 (R: 32714.36, KLD: 140.16), Beta: 3.080, LR: 1.11e-07, ValL: 27923.30 (R: 27502.82, KLD: 136.52)\n",
      "[INFO]   Fold 3/5 VAE E245/300, TrL: 33155.61 (R: 32575.46, KLD: 138.79), Beta: 4.180, LR: 9.38e-05, ValL: 27988.16 (R: 27437.15, KLD: 131.82)\n",
      "[INFO]   Fold 3/5 VAE E250/300, TrL: 33154.16 (R: 32473.53, KLD: 128.91), Beta: 5.280, LR: 7.59e-05, ValL: 27968.89 (R: 27318.39, KLD: 123.20)\n",
      "[INFO]   Fold 3/5 VAE E255/300, TrL: 33052.19 (R: 32256.97, KLD: 124.64), Beta: 6.380, LR: 5.11e-05, ValL: 28059.70 (R: 27344.00, KLD: 112.18)\n",
      "[INFO]   Fold 3/5 Early stopping VAE en epoch 257. Mejor val_loss: 27659.3342\n",
      "[INFO]   Fold 3/5 VAE final model loaded (best val_loss: 27659.3342).\n",
      "[INFO]   Fold 3/5 Modelo VAE guardado en: resultados_FIN_v2/fold_3/vae_model_fold_3.pt\n",
      "[INFO] Fold 3/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 74 (50.3%)\n",
      "      M: 73 (49.7%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 258)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 564, 'model__learning_rate': 0.04913237035151997, 'model__max_depth': 12, 'model__subsample': 0.9533223421801951, 'model__colsample_bytree': 0.9131523389770951, 'model__min_child_weight': 1.2328908555054783}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 3 (xgb): AUC=0.7924, Bal.Acc=0.7251\n",
      "[INFO]       Pipeline completo de xgb del fold 3 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__estimator__C': 2.855881946983472, 'model__estimator__gamma': 0.0003881270932620947, 'model__estimator__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 3 (svm): AUC=0.8041, Bal.Acc=0.7295\n",
      "[INFO]       Pipeline completo de svm del fold 3 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.003868508472675826}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 3 (logreg): AUC=0.8129, Bal.Acc=0.7544\n",
      "[INFO]       Pipeline completo de logreg del fold 3 guardado.\n",
      "[INFO]   Fold 3/5 completado en 215.77 segundos.\n",
      "[INFO] --- Iniciando Fold 4/5 ---\n",
      "[INFO] Fold 4/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 18 (48.6%)\n",
      "      M: 19 (51.4%)\n",
      "[INFO] Fold 4/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 188 (47.7%)\n",
      "      M: 206 (52.3%)\n",
      "    Age_Group:\n",
      "      0: 99 (25.1%)\n",
      "      1: 96 (24.4%)\n",
      "      2: 98 (24.9%)\n",
      "      3: 101 (25.6%)\n",
      "[INFO]   Fold 4/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 4/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 62 (19.7%)\n",
      "      CN: 56 (17.8%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 150 (47.6%)\n",
      "      M: 165 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 80 (25.4%)\n",
      "      1: 77 (24.4%)\n",
      "      2: 78 (24.8%)\n",
      "      3: 80 (25.4%)\n",
      "[INFO] Fold 4/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 14 (17.7%)\n",
      "      CN: 15 (19.0%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 38 (48.1%)\n",
      "      M: 41 (51.9%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 19 (24.1%)\n",
      "      2: 20 (25.3%)\n",
      "      3: 21 (26.6%)\n",
      "[INFO]   Fold 4/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.775)\n",
      "[INFO] Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.058, std=0.816)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.403, std=1.693)\n",
      "[INFO]   Fold 4/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 4/5 Usando scheduler: CosineAnnealingWarmRestarts (T_0=30)\n",
      "[INFO]   Fold 4/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 4/5 VAE E5/300, TrL: 63211.73 (R: 63130.46, KLD: 92.35), Beta: 0.880, LR: 9.38e-05, ValL: 57610.80 (R: 57564.26, KLD: 52.89)\n",
      "[INFO]   Fold 4/5 VAE E10/300, TrL: 58690.17 (R: 58305.55, KLD: 194.25), Beta: 1.980, LR: 7.59e-05, ValL: 51980.34 (R: 51075.85, KLD: 456.81)\n",
      "[INFO]   Fold 4/5 VAE E15/300, TrL: 53594.23 (R: 52766.66, KLD: 268.69), Beta: 3.080, LR: 5.11e-05, ValL: 48841.64 (R: 47876.49, KLD: 313.36)\n",
      "[INFO]   Fold 4/5 VAE E20/300, TrL: 52132.58 (R: 51440.71, KLD: 165.52), Beta: 4.180, LR: 2.60e-05, ValL: 47001.93 (R: 46382.48, KLD: 148.19)\n",
      "[INFO]   Fold 4/5 VAE E25/300, TrL: 51574.35 (R: 50761.78, KLD: 153.90), Beta: 5.280, LR: 7.32e-06, ValL: 46598.15 (R: 45825.20, KLD: 146.39)\n",
      "[INFO]   Fold 4/5 VAE E30/300, TrL: 51559.61 (R: 50611.71, KLD: 148.57), Beta: 6.380, LR: 1.11e-07, ValL: 46606.89 (R: 45707.10, KLD: 141.03)\n",
      "[INFO]   Fold 4/5 VAE E35/300, TrL: 49009.58 (R: 48312.43, KLD: 105.63), Beta: 6.600, LR: 9.38e-05, ValL: 43624.17 (R: 42844.01, KLD: 118.21)\n",
      "[INFO]   Fold 4/5 VAE E40/300, TrL: 46513.54 (R: 45884.33, KLD: 95.34), Beta: 6.600, LR: 7.59e-05, ValL: 40800.61 (R: 40205.07, KLD: 90.23)\n",
      "[INFO]   Fold 4/5 VAE E45/300, TrL: 45011.17 (R: 44410.39, KLD: 91.03), Beta: 6.600, LR: 5.11e-05, ValL: 39205.65 (R: 38619.40, KLD: 88.83)\n",
      "[INFO]   Fold 4/5 VAE E50/300, TrL: 44216.38 (R: 43604.52, KLD: 92.71), Beta: 6.600, LR: 2.60e-05, ValL: 38435.84 (R: 37868.93, KLD: 85.89)\n",
      "[INFO]   Fold 4/5 VAE E55/300, TrL: 43694.40 (R: 43101.64, KLD: 89.81), Beta: 6.600, LR: 7.32e-06, ValL: 38087.30 (R: 37524.95, KLD: 85.20)\n",
      "[INFO]   Fold 4/5 VAE E60/300, TrL: 43678.99 (R: 43089.76, KLD: 89.28), Beta: 6.600, LR: 1.11e-07, ValL: 38044.80 (R: 37499.26, KLD: 82.66)\n",
      "[INFO]   Fold 4/5 VAE E65/300, TrL: 42422.89 (R: 41817.97, KLD: 91.65), Beta: 6.600, LR: 9.38e-05, ValL: 36693.80 (R: 36066.34, KLD: 95.07)\n",
      "[INFO]   Fold 4/5 VAE E70/300, TrL: 41413.81 (R: 40761.18, KLD: 98.88), Beta: 6.600, LR: 7.59e-05, ValL: 35612.56 (R: 34965.83, KLD: 97.99)\n",
      "[INFO]   Fold 4/5 VAE E75/300, TrL: 40702.59 (R: 40108.75, KLD: 89.98), Beta: 6.600, LR: 5.11e-05, ValL: 34866.43 (R: 34287.76, KLD: 87.68)\n",
      "[INFO]   Fold 4/5 VAE E80/300, TrL: 39541.79 (R: 39433.65, KLD: 122.89), Beta: 0.880, LR: 2.60e-05, ValL: 33753.49 (R: 33647.54, KLD: 120.41)\n",
      "[INFO]   Fold 4/5 VAE E85/300, TrL: 39374.68 (R: 39106.57, KLD: 135.41), Beta: 1.980, LR: 7.32e-06, ValL: 33740.62 (R: 33481.81, KLD: 130.71)\n",
      "[INFO]   Fold 4/5 VAE E90/300, TrL: 39601.05 (R: 39192.13, KLD: 132.77), Beta: 3.080, LR: 1.11e-07, ValL: 33894.97 (R: 33484.57, KLD: 133.24)\n",
      "[INFO]   Fold 4/5 VAE E95/300, TrL: 39019.35 (R: 38530.48, KLD: 116.95), Beta: 4.180, LR: 9.38e-05, ValL: 33225.63 (R: 32749.80, KLD: 113.84)\n",
      "[INFO]   Fold 4/5 VAE E100/300, TrL: 38578.41 (R: 37985.19, KLD: 112.35), Beta: 5.280, LR: 7.59e-05, ValL: 32887.70 (R: 32240.38, KLD: 122.60)\n",
      "[INFO]   Fold 4/5 VAE E105/300, TrL: 38079.12 (R: 37414.68, KLD: 104.14), Beta: 6.380, LR: 5.11e-05, ValL: 32365.70 (R: 31752.57, KLD: 96.10)\n",
      "[INFO]   Fold 4/5 VAE E110/300, TrL: 37826.57 (R: 37162.89, KLD: 100.56), Beta: 6.600, LR: 2.60e-05, ValL: 32128.44 (R: 31512.25, KLD: 93.36)\n",
      "[INFO]   Fold 4/5 VAE E115/300, TrL: 37725.21 (R: 37077.52, KLD: 98.13), Beta: 6.600, LR: 7.32e-06, ValL: 32028.58 (R: 31453.59, KLD: 87.12)\n",
      "[INFO]   Fold 4/5 VAE E120/300, TrL: 37592.37 (R: 36946.05, KLD: 97.93), Beta: 6.600, LR: 1.11e-07, ValL: 31986.90 (R: 31408.62, KLD: 87.62)\n",
      "[INFO]   Fold 4/5 VAE E125/300, TrL: 37291.48 (R: 36619.61, KLD: 101.80), Beta: 6.600, LR: 9.38e-05, ValL: 31635.81 (R: 31013.19, KLD: 94.34)\n",
      "[INFO]   Fold 4/5 VAE E130/300, TrL: 36849.90 (R: 36175.02, KLD: 102.25), Beta: 6.600, LR: 7.59e-05, ValL: 31410.24 (R: 30798.57, KLD: 92.68)\n",
      "[INFO]   Fold 4/5 VAE E135/300, TrL: 36570.56 (R: 35880.64, KLD: 104.53), Beta: 6.600, LR: 5.11e-05, ValL: 30894.33 (R: 30301.13, KLD: 89.88)\n",
      "[INFO]   Fold 4/5 VAE E140/300, TrL: 36186.25 (R: 35525.41, KLD: 100.13), Beta: 6.600, LR: 2.60e-05, ValL: 30748.08 (R: 30163.87, KLD: 88.52)\n",
      "[INFO]   Fold 4/5 VAE E145/300, TrL: 36125.55 (R: 35458.62, KLD: 101.05), Beta: 6.600, LR: 7.32e-06, ValL: 30737.07 (R: 30159.85, KLD: 87.46)\n",
      "[INFO]   Fold 4/5 VAE E150/300, TrL: 36130.30 (R: 35468.35, KLD: 100.29), Beta: 6.600, LR: 1.11e-07, ValL: 30764.68 (R: 30187.39, KLD: 87.47)\n",
      "[INFO]   Fold 4/5 VAE E155/300, TrL: 35118.10 (R: 34979.42, KLD: 157.60), Beta: 0.880, LR: 9.38e-05, ValL: 30099.65 (R: 29960.33, KLD: 158.31)\n",
      "[INFO]   Fold 4/5 VAE E160/300, TrL: 35001.60 (R: 34648.46, KLD: 178.35), Beta: 1.980, LR: 7.59e-05, ValL: 29697.90 (R: 29359.51, KLD: 170.90)\n",
      "[INFO]   Fold 4/5 VAE E165/300, TrL: 34796.06 (R: 34276.67, KLD: 168.63), Beta: 3.080, LR: 5.11e-05, ValL: 29735.12 (R: 29252.91, KLD: 156.56)\n",
      "[INFO]   Fold 4/5 VAE E170/300, TrL: 34927.80 (R: 34275.36, KLD: 156.09), Beta: 4.180, LR: 2.60e-05, ValL: 29857.87 (R: 29253.35, KLD: 144.62)\n",
      "[INFO]   Fold 4/5 VAE E175/300, TrL: 34993.24 (R: 34210.11, KLD: 148.32), Beta: 5.280, LR: 7.32e-06, ValL: 29966.59 (R: 29248.26, KLD: 136.05)\n",
      "[INFO]   Fold 4/5 VAE E180/300, TrL: 35044.75 (R: 34110.40, KLD: 146.45), Beta: 6.380, LR: 1.11e-07, ValL: 30080.16 (R: 29227.20, KLD: 133.69)\n",
      "[INFO]   Fold 4/5 VAE E185/300, TrL: 34866.06 (R: 34121.03, KLD: 112.88), Beta: 6.600, LR: 9.38e-05, ValL: 29900.62 (R: 29211.23, KLD: 104.45)\n",
      "[INFO]   Fold 4/5 VAE E190/300, TrL: 34744.93 (R: 33999.15, KLD: 113.00), Beta: 6.600, LR: 7.59e-05, ValL: 29679.75 (R: 29013.02, KLD: 101.02)\n",
      "[INFO]   Fold 4/5 VAE E195/300, TrL: 34434.75 (R: 33705.20, KLD: 110.54), Beta: 6.600, LR: 5.11e-05, ValL: 29523.38 (R: 28886.99, KLD: 96.42)\n",
      "[INFO]   Fold 4/5 VAE E200/300, TrL: 34302.86 (R: 33561.38, KLD: 112.35), Beta: 6.600, LR: 2.60e-05, ValL: 29450.10 (R: 28811.71, KLD: 96.73)\n",
      "[INFO]   Fold 4/5 VAE E205/300, TrL: 34059.37 (R: 33335.54, KLD: 109.67), Beta: 6.600, LR: 7.32e-06, ValL: 29296.77 (R: 28690.70, KLD: 91.83)\n",
      "[INFO]   Fold 4/5 VAE E210/300, TrL: 34234.56 (R: 33507.71, KLD: 110.13), Beta: 6.600, LR: 1.11e-07, ValL: 29325.67 (R: 28707.27, KLD: 93.70)\n",
      "[INFO]   Fold 4/5 VAE E215/300, TrL: 34047.54 (R: 33314.47, KLD: 111.07), Beta: 6.600, LR: 9.38e-05, ValL: 29232.99 (R: 28595.04, KLD: 96.66)\n",
      "[INFO]   Fold 4/5 VAE E220/300, TrL: 33945.08 (R: 33200.74, KLD: 112.78), Beta: 6.600, LR: 7.59e-05, ValL: 29182.36 (R: 28541.75, KLD: 97.06)\n",
      "[INFO]   Fold 4/5 VAE E225/300, TrL: 33727.45 (R: 32982.53, KLD: 112.87), Beta: 6.600, LR: 5.11e-05, ValL: 29071.38 (R: 28426.48, KLD: 97.71)\n",
      "[INFO]   Fold 4/5 VAE E230/300, TrL: 33000.96 (R: 32885.57, KLD: 131.12), Beta: 0.880, LR: 2.60e-05, ValL: 28330.96 (R: 28226.68, KLD: 118.50)\n",
      "[INFO]   Fold 4/5 VAE E235/300, TrL: 33059.23 (R: 32777.52, KLD: 142.28), Beta: 1.980, LR: 7.32e-06, ValL: 28518.48 (R: 28263.50, KLD: 128.78)\n",
      "[INFO]   Fold 4/5 VAE E240/300, TrL: 33091.66 (R: 32649.85, KLD: 143.45), Beta: 3.080, LR: 1.11e-07, ValL: 28482.38 (R: 28085.88, KLD: 128.73)\n",
      "[INFO]   Fold 4/5 VAE E245/300, TrL: 33238.01 (R: 32634.01, KLD: 144.50), Beta: 4.180, LR: 9.38e-05, ValL: 28627.38 (R: 28090.51, KLD: 128.44)\n",
      "[INFO]   Fold 4/5 VAE E250/300, TrL: 33092.67 (R: 32372.94, KLD: 136.31), Beta: 5.280, LR: 7.59e-05, ValL: 28605.91 (R: 27991.17, KLD: 116.43)\n",
      "[INFO]   Fold 4/5 VAE E255/300, TrL: 33091.54 (R: 32284.76, KLD: 126.46), Beta: 6.380, LR: 5.11e-05, ValL: 28575.66 (R: 27890.07, KLD: 107.46)\n",
      "[INFO]   Fold 4/5 Early stopping VAE en epoch 258. Mejor val_loss: 28191.8770\n",
      "[INFO]   Fold 4/5 VAE final model loaded (best val_loss: 28191.8770).\n",
      "[INFO]   Fold 4/5 Modelo VAE guardado en: resultados_FIN_v2/fold_4/vae_model_fold_4.pt\n",
      "[INFO] Fold 4/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 74 (50.3%)\n",
      "      M: 73 (49.7%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 258)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 1109, 'model__learning_rate': 0.0098770842391434, 'model__max_depth': 12, 'model__subsample': 0.30225168482894593, 'model__colsample_bytree': 0.10245749913292085, 'model__min_child_weight': 0.5080756656697669}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 4 (xgb): AUC=0.7485, Bal.Acc=0.7544\n",
      "[INFO]       Pipeline completo de xgb del fold 4 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__estimator__C': 50.5406514138572, 'model__estimator__gamma': 5.688090985285566e-05, 'model__estimator__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 4 (svm): AUC=0.7442, Bal.Acc=0.7018\n",
      "[INFO]       Pipeline completo de svm del fold 4 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.009846519024036507}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 4 (logreg): AUC=0.7690, Bal.Acc=0.7558\n",
      "[INFO]       Pipeline completo de logreg del fold 4 guardado.\n",
      "[INFO]   Fold 4/5 completado en 300.69 segundos.\n",
      "[INFO] --- Iniciando Fold 5/5 ---\n",
      "[INFO] Fold 5/5 Test Set (Clasificador) (N=36):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (52.8%)\n",
      "      CN: 17 (47.2%)\n",
      "    Sex:\n",
      "      F: 18 (50.0%)\n",
      "      M: 18 (50.0%)\n",
      "[INFO] Fold 5/5 Pool Entrenamiento VAE (N=395):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.2%)\n",
      "      CN: 72 (18.2%)\n",
      "      MCI: 247 (62.5%)\n",
      "    Sex:\n",
      "      F: 188 (47.6%)\n",
      "      M: 207 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 101 (25.6%)\n",
      "      1: 105 (26.6%)\n",
      "      2: 98 (24.8%)\n",
      "      3: 91 (23.0%)\n",
      "[INFO]   Fold 5/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 5/5 Actual Train Set (VAE) (N=316):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 61 (19.3%)\n",
      "      CN: 58 (18.4%)\n",
      "      MCI: 197 (62.3%)\n",
      "    Sex:\n",
      "      F: 151 (47.8%)\n",
      "      M: 165 (52.2%)\n",
      "    Age_Group:\n",
      "      0: 82 (25.9%)\n",
      "      1: 84 (26.6%)\n",
      "      2: 77 (24.4%)\n",
      "      3: 73 (23.1%)\n",
      "[INFO] Fold 5/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 15 (19.0%)\n",
      "      CN: 14 (17.7%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 37 (46.8%)\n",
      "      M: 42 (53.2%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 21 (26.6%)\n",
      "      2: 21 (26.6%)\n",
      "      3: 18 (22.8%)\n",
      "[INFO]   Fold 5/5 Sujetos VAE actual train: 316, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 316 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.777)\n",
      "[INFO] Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.057, std=0.814)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.407, std=1.702)\n",
      "[INFO]   Fold 5/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 5/5 Usando scheduler: CosineAnnealingWarmRestarts (T_0=30)\n",
      "[INFO]   Fold 5/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 5/5 VAE E5/300, TrL: 63112.33 (R: 63031.39, KLD: 91.98), Beta: 0.880, LR: 9.38e-05, ValL: 61638.18 (R: 61596.65, KLD: 47.20)\n",
      "[INFO]   Fold 5/5 VAE E10/300, TrL: 58820.73 (R: 58449.18, KLD: 187.65), Beta: 1.980, LR: 7.59e-05, ValL: 56154.32 (R: 55418.91, KLD: 371.42)\n",
      "[INFO]   Fold 5/5 VAE E15/300, TrL: 53931.19 (R: 53101.81, KLD: 269.28), Beta: 3.080, LR: 5.11e-05, ValL: 52964.97 (R: 51764.41, KLD: 389.79)\n",
      "[INFO]   Fold 5/5 VAE E20/300, TrL: 51858.40 (R: 51113.79, KLD: 178.14), Beta: 4.180, LR: 2.60e-05, ValL: 51030.84 (R: 50161.03, KLD: 208.09)\n",
      "[INFO]   Fold 5/5 VAE E25/300, TrL: 51380.39 (R: 50545.88, KLD: 158.05), Beta: 5.280, LR: 7.32e-06, ValL: 50540.91 (R: 49591.89, KLD: 179.74)\n",
      "[INFO]   Fold 5/5 VAE E30/300, TrL: 51331.55 (R: 50348.12, KLD: 154.14), Beta: 6.380, LR: 1.11e-07, ValL: 50586.75 (R: 49479.06, KLD: 173.62)\n",
      "[INFO]   Fold 5/5 VAE E35/300, TrL: 48363.08 (R: 47628.65, KLD: 111.28), Beta: 6.600, LR: 9.38e-05, ValL: 46808.44 (R: 46042.82, KLD: 116.00)\n",
      "[INFO]   Fold 5/5 VAE E40/300, TrL: 45699.62 (R: 45054.43, KLD: 97.76), Beta: 6.600, LR: 7.59e-05, ValL: 43964.07 (R: 43281.30, KLD: 103.45)\n",
      "[INFO]   Fold 5/5 VAE E45/300, TrL: 44015.96 (R: 43394.07, KLD: 94.23), Beta: 6.600, LR: 5.11e-05, ValL: 42345.07 (R: 41736.49, KLD: 92.21)\n",
      "[INFO]   Fold 5/5 VAE E50/300, TrL: 43209.38 (R: 42610.76, KLD: 90.70), Beta: 6.600, LR: 2.60e-05, ValL: 41503.11 (R: 40950.49, KLD: 83.73)\n",
      "[INFO]   Fold 5/5 VAE E55/300, TrL: 42865.81 (R: 42260.33, KLD: 91.74), Beta: 6.600, LR: 7.32e-06, ValL: 41209.67 (R: 40669.71, KLD: 81.81)\n",
      "[INFO]   Fold 5/5 VAE E60/300, TrL: 42947.82 (R: 42350.93, KLD: 90.44), Beta: 6.600, LR: 1.11e-07, ValL: 41163.61 (R: 40622.95, KLD: 81.92)\n",
      "[INFO]   Fold 5/5 VAE E65/300, TrL: 41658.23 (R: 41026.11, KLD: 95.78), Beta: 6.600, LR: 9.38e-05, ValL: 39923.09 (R: 39300.13, KLD: 94.39)\n",
      "[INFO]   Fold 5/5 VAE E70/300, TrL: 40430.91 (R: 39777.17, KLD: 99.05), Beta: 6.600, LR: 7.59e-05, ValL: 38922.68 (R: 38355.37, KLD: 85.96)\n",
      "[INFO]   Fold 5/5 VAE E75/300, TrL: 39881.35 (R: 39274.55, KLD: 91.94), Beta: 6.600, LR: 5.11e-05, ValL: 38386.98 (R: 37773.12, KLD: 93.01)\n",
      "[INFO]   Fold 5/5 VAE E80/300, TrL: 38968.05 (R: 38859.96, KLD: 122.84), Beta: 0.880, LR: 2.60e-05, ValL: 37493.17 (R: 37382.38, KLD: 125.89)\n",
      "[INFO]   Fold 5/5 VAE E85/300, TrL: 38904.98 (R: 38635.12, KLD: 136.29), Beta: 1.980, LR: 7.32e-06, ValL: 37470.25 (R: 37209.33, KLD: 131.78)\n",
      "[INFO]   Fold 5/5 VAE E90/300, TrL: 38913.24 (R: 38503.35, KLD: 133.08), Beta: 3.080, LR: 1.11e-07, ValL: 37563.84 (R: 37159.64, KLD: 131.23)\n",
      "[INFO]   Fold 5/5 VAE E95/300, TrL: 38586.16 (R: 38042.16, KLD: 130.14), Beta: 4.180, LR: 9.38e-05, ValL: 37241.64 (R: 36680.00, KLD: 134.37)\n",
      "[INFO]   Fold 5/5 VAE E100/300, TrL: 37934.22 (R: 37316.25, KLD: 117.04), Beta: 5.280, LR: 7.59e-05, ValL: 36629.95 (R: 36080.25, KLD: 104.11)\n",
      "[INFO]   Fold 5/5 VAE E105/300, TrL: 37627.09 (R: 36931.75, KLD: 108.99), Beta: 6.380, LR: 5.11e-05, ValL: 36373.17 (R: 35748.60, KLD: 97.90)\n",
      "[INFO]   Fold 5/5 VAE E110/300, TrL: 37301.51 (R: 36638.76, KLD: 100.42), Beta: 6.600, LR: 2.60e-05, ValL: 36111.74 (R: 35530.12, KLD: 88.12)\n",
      "[INFO]   Fold 5/5 VAE E115/300, TrL: 37337.04 (R: 36671.92, KLD: 100.78), Beta: 6.600, LR: 7.32e-06, ValL: 36059.05 (R: 35489.46, KLD: 86.30)\n",
      "[INFO]   Fold 5/5 VAE E120/300, TrL: 37296.82 (R: 36646.47, KLD: 98.54), Beta: 6.600, LR: 1.11e-07, ValL: 35982.38 (R: 35421.49, KLD: 84.98)\n",
      "[INFO]   Fold 5/5 VAE E125/300, TrL: 36907.02 (R: 36251.95, KLD: 99.25), Beta: 6.600, LR: 9.38e-05, ValL: 35710.28 (R: 35111.86, KLD: 90.67)\n",
      "[INFO]   Fold 5/5 VAE E130/300, TrL: 36505.42 (R: 35837.83, KLD: 101.15), Beta: 6.600, LR: 7.59e-05, ValL: 35173.27 (R: 34621.55, KLD: 83.59)\n",
      "[INFO]   Fold 5/5 VAE E135/300, TrL: 36257.15 (R: 35569.02, KLD: 104.26), Beta: 6.600, LR: 5.11e-05, ValL: 35127.00 (R: 34496.55, KLD: 95.52)\n",
      "[INFO]   Fold 5/5 VAE E140/300, TrL: 36017.28 (R: 35359.98, KLD: 99.59), Beta: 6.600, LR: 2.60e-05, ValL: 34945.84 (R: 34376.17, KLD: 86.31)\n",
      "[INFO]   Fold 5/5 VAE E145/300, TrL: 35889.98 (R: 35231.13, KLD: 99.83), Beta: 6.600, LR: 7.32e-06, ValL: 34826.69 (R: 34261.11, KLD: 85.69)\n",
      "[INFO]   Fold 5/5 VAE E150/300, TrL: 35924.71 (R: 35276.26, KLD: 98.25), Beta: 6.600, LR: 1.11e-07, ValL: 34798.49 (R: 34243.59, KLD: 84.08)\n",
      "[INFO]   Fold 5/5 VAE E155/300, TrL: 34955.32 (R: 34813.84, KLD: 160.78), Beta: 0.880, LR: 9.38e-05, ValL: 33991.23 (R: 33856.10, KLD: 153.56)\n",
      "[INFO]   Fold 5/5 VAE E160/300, TrL: 34759.07 (R: 34405.02, KLD: 178.81), Beta: 1.980, LR: 7.59e-05, ValL: 33794.07 (R: 33467.28, KLD: 165.05)\n",
      "[INFO]   Fold 5/5 VAE E165/300, TrL: 34770.95 (R: 34256.32, KLD: 167.09), Beta: 3.080, LR: 5.11e-05, ValL: 33716.26 (R: 33251.66, KLD: 150.85)\n",
      "[INFO]   Fold 5/5 VAE E170/300, TrL: 34656.83 (R: 34010.19, KLD: 154.70), Beta: 4.180, LR: 2.60e-05, ValL: 33751.57 (R: 33164.63, KLD: 140.42)\n",
      "[INFO]   Fold 5/5 VAE E175/300, TrL: 34797.97 (R: 34036.69, KLD: 144.18), Beta: 5.280, LR: 7.32e-06, ValL: 33867.23 (R: 33191.45, KLD: 127.99)\n",
      "[INFO]   Fold 5/5 VAE E180/300, TrL: 34937.01 (R: 34031.58, KLD: 141.92), Beta: 6.380, LR: 1.11e-07, ValL: 33969.36 (R: 33171.94, KLD: 124.99)\n",
      "[INFO]   Fold 5/5 VAE E185/300, TrL: 34692.69 (R: 33983.68, KLD: 107.42), Beta: 6.600, LR: 9.38e-05, ValL: 33847.18 (R: 33214.13, KLD: 95.92)\n",
      "[INFO]   Fold 5/5 VAE E190/300, TrL: 34443.05 (R: 33717.40, KLD: 109.95), Beta: 6.600, LR: 7.59e-05, ValL: 33632.56 (R: 33017.89, KLD: 93.13)\n",
      "[INFO]   Fold 5/5 VAE E195/300, TrL: 34352.62 (R: 33634.24, KLD: 108.85), Beta: 6.600, LR: 5.11e-05, ValL: 33519.94 (R: 32910.33, KLD: 92.37)\n",
      "[INFO]   Fold 5/5 VAE E200/300, TrL: 34175.54 (R: 33456.10, KLD: 109.01), Beta: 6.600, LR: 2.60e-05, ValL: 33476.52 (R: 32870.94, KLD: 91.75)\n",
      "[INFO]   Fold 5/5 VAE E205/300, TrL: 34150.62 (R: 33438.19, KLD: 107.94), Beta: 6.600, LR: 7.32e-06, ValL: 33367.30 (R: 32793.97, KLD: 86.87)\n",
      "[INFO]   Fold 5/5 VAE E210/300, TrL: 34088.29 (R: 33383.24, KLD: 106.83), Beta: 6.600, LR: 1.11e-07, ValL: 33330.59 (R: 32752.76, KLD: 87.55)\n",
      "[INFO]   Fold 5/5 VAE E215/300, TrL: 33922.70 (R: 33187.66, KLD: 111.37), Beta: 6.600, LR: 9.38e-05, ValL: 33270.67 (R: 32671.40, KLD: 90.80)\n",
      "[INFO]   Fold 5/5 VAE E220/300, TrL: 33933.59 (R: 33193.69, KLD: 112.11), Beta: 6.600, LR: 7.59e-05, ValL: 33094.68 (R: 32480.53, KLD: 93.05)\n",
      "[INFO]   Fold 5/5 VAE E225/300, TrL: 33723.80 (R: 32994.19, KLD: 110.55), Beta: 6.600, LR: 5.11e-05, ValL: 33089.29 (R: 32485.15, KLD: 91.54)\n",
      "[INFO]   Fold 5/5 VAE E230/300, TrL: 32811.27 (R: 32697.95, KLD: 128.77), Beta: 0.880, LR: 2.60e-05, ValL: 32392.05 (R: 32291.34, KLD: 114.44)\n",
      "[INFO]   Fold 5/5 VAE E235/300, TrL: 32829.92 (R: 32555.00, KLD: 138.85), Beta: 1.980, LR: 7.32e-06, ValL: 32474.58 (R: 32235.33, KLD: 120.83)\n",
      "[INFO]   Fold 5/5 VAE E240/300, TrL: 33001.23 (R: 32576.47, KLD: 137.91), Beta: 3.080, LR: 1.11e-07, ValL: 32609.44 (R: 32233.95, KLD: 121.91)\n",
      "[INFO]   Fold 5/5 VAE E245/300, TrL: 33182.81 (R: 32595.46, KLD: 140.51), Beta: 4.180, LR: 9.38e-05, ValL: 32595.16 (R: 32099.94, KLD: 118.47)\n",
      "[INFO]   Fold 5/5 VAE E250/300, TrL: 33065.95 (R: 32375.41, KLD: 130.78), Beta: 5.280, LR: 7.59e-05, ValL: 32696.43 (R: 32111.83, KLD: 110.72)\n",
      "[INFO]   Fold 5/5 VAE E255/300, TrL: 33110.85 (R: 32322.43, KLD: 123.58), Beta: 6.380, LR: 5.11e-05, ValL: 32576.15 (R: 31941.59, KLD: 99.46)\n",
      "[INFO]   Fold 5/5 Early stopping VAE en epoch 258. Mejor val_loss: 32351.4693\n",
      "[INFO]   Fold 5/5 VAE final model loaded (best val_loss: 32351.4693).\n",
      "[INFO]   Fold 5/5 Modelo VAE guardado en: resultados_FIN_v2/fold_5/vae_model_fold_5.pt\n",
      "[INFO] Fold 5/5 Pool Train/Dev (Clasificador) (N=148):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.4%)\n",
      "      CN: 72 (48.6%)\n",
      "    Sex:\n",
      "      F: 74 (50.0%)\n",
      "      M: 74 (50.0%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (148, 258)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 947, 'model__learning_rate': 0.00015920992047247095, 'model__max_depth': 3, 'model__subsample': 0.6704140907063927, 'model__colsample_bytree': 0.40744389245919854, 'model__min_child_weight': 0.5449125144346689}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 5 (xgb): AUC=0.7152, Bal.Acc=0.6331\n",
      "[INFO]       Pipeline completo de xgb del fold 5 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__estimator__C': 40.20674527085555, 'model__estimator__gamma': 2.0011131760010656e-05, 'model__estimator__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 5 (svm): AUC=0.7043, Bal.Acc=0.6192\n",
      "[INFO]       Pipeline completo de svm del fold 5 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.01774965291093695}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 5 (logreg): AUC=0.7461, Bal.Acc=0.7508\n",
      "[INFO]       Pipeline completo de logreg del fold 5 guardado.\n",
      "[INFO]   Fold 5/5 completado en 219.19 segundos.\n",
      "[INFO] \n",
      "--- Resumen de Rendimiento para Clasificador: xgb (Promedio sobre Folds Externos) ---\n",
      "[INFO] Auc                 : 0.7577 +/- 0.0816\n",
      "[INFO] Pr_auc              : 0.7778 +/- 0.0781\n",
      "[INFO] Accuracy            : 0.7062 +/- 0.0721\n",
      "[INFO] Balanced_accuracy   : 0.7032 +/- 0.0724\n",
      "[INFO] Sensitivity         : 0.7895 +/- 0.1053\n",
      "[INFO] Specificity         : 0.6170 +/- 0.0791\n",
      "[INFO] F1_score            : 0.7335 +/- 0.0727\n",
      "[INFO] \n",
      "--- Resumen de Rendimiento para Clasificador: svm (Promedio sobre Folds Externos) ---\n",
      "[INFO] Auc                 : 0.7774 +/- 0.0526\n",
      "[INFO] Pr_auc              : 0.7786 +/- 0.0483\n",
      "[INFO] Accuracy            : 0.6952 +/- 0.0559\n",
      "[INFO] Balanced_accuracy   : 0.6966 +/- 0.0530\n",
      "[INFO] Sensitivity         : 0.6737 +/- 0.1141\n",
      "[INFO] Specificity         : 0.7196 +/- 0.0525\n",
      "[INFO] F1_score            : 0.6917 +/- 0.0770\n",
      "[INFO] \n",
      "--- Resumen de Rendimiento para Clasificador: logreg (Promedio sobre Folds Externos) ---\n",
      "[INFO] Auc                 : 0.7989 +/- 0.0557\n",
      "[INFO] Pr_auc              : 0.7948 +/- 0.0716\n",
      "[INFO] Accuracy            : 0.7608 +/- 0.0301\n",
      "[INFO] Balanced_accuracy   : 0.7604 +/- 0.0285\n",
      "[INFO] Sensitivity         : 0.7789 +/- 0.1012\n",
      "[INFO] Specificity         : 0.7418 +/- 0.0619\n",
      "[INFO] F1_score            : 0.7683 +/- 0.0444\n",
      "[INFO] Resultados detallados de todos los clasificadores guardados en: resultados_FIN_v2/all_folds_metrics_MULTI_xgb_vaeconvtranspose4l_ld256_beta6.6_normzscore_offdiag_ch3sel_intFCquarter_drop0.2_ln0_outer5x1_scoreroc_auc.csv\n",
      "[INFO] Sumario estadístico de métricas (por clasificador) guardado en: resultados_FIN_v2/summary_metrics_MULTI_xgb_vaeconvtranspose4l_ld256_beta6.6_normzscore_offdiag_ch3sel_intFCquarter_drop0.2_ln0_outer5x1_scoreroc_auc.txt\n",
      "[INFO] Pipeline completo en 1230.53 segundos.\n",
      "[INFO] --- Consideraciones Finales ---\n",
      "[INFO] Normalización: 'zscore_offdiag'. Activación VAE: 'tanh'. Asegurar compatibilidad.\n"
     ]
    }
   ],
   "source": [
    "!python serentipia3.py \\\n",
    "    --global_tensor_path /home/diego/Escritorio/limpio/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz \\\n",
    "    --metadata_path /home/diego/Escritorio/limpio/SubjectsData_AAL3_procesado.csv \\\n",
    "    --output_dir ./resultados_FIN_v2 \\\n",
    "    --channels_to_use 1 2 5 \\\n",
    "    --classifier_types xgb svm logreg \\\n",
    "    --classifier_calibrate \\\n",
    "    --outer_folds 5 \\\n",
    "    --repeated_outer_folds_n_repeats 1 \\\n",
    "    --epochs_vae 300 \\\n",
    "    --early_stopping_patience_vae 30 \\\n",
    "    --lr_scheduler_type cosine_warm --lr_scheduler_T0 30 \\\n",
    "    --batch_size 64 \\\n",
    "    --beta_vae 6.6 \\\n",
    "    --latent_dim 256 \\\n",
    "    --n_jobs_gridsearch 8 \\\n",
    "    --metadata_features Age Sex \\\n",
    "    --use_smote \\\n",
    "    --use_optuna_pruner \\\n",
    "    --classifier_use_class_weight \\\n",
    "    --save_fold_artefacts \\\n",
    "    --gridsearch_scoring roc_auc \\\n",
    "    --save_vae_training_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
