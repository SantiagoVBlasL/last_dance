{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a943e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿GPU visible?: True\n",
      "¿GPU visible?: True\n",
      "¿GPU visible?: True\n",
      "torch.cuda.is_available -> True\n",
      "torch.version.cuda      -> 11.8\n",
      "cupy GPU visible        -> True\n",
      "fatal: no es un repositorio git (ni ninguno de los directorios superiores): .git\n",
      "[INFO] Git commit hash: N/A\n",
      "[INFO] --- Configuración de la Ejecución (v1.7.0) ---\n",
      "[INFO] batch_size: 64\n",
      "[INFO] beta_vae: 4.5\n",
      "[INFO] channels_to_use: [1, 5]\n",
      "[INFO] classifier_calibrate: False\n",
      "[INFO] classifier_hp_tune_ratio: 0.25\n",
      "[INFO] classifier_stratify_cols: ['Sex']\n",
      "[INFO] classifier_types: ['xgb', 'svm', 'logreg']\n",
      "[INFO] classifier_use_class_weight: True\n",
      "[INFO] cyclical_beta_n_cycles: 4\n",
      "[INFO] cyclical_beta_ratio_increase: 0.4\n",
      "[INFO] decoder_type: convtranspose\n",
      "[INFO] dropout_rate_vae: 0.2\n",
      "[INFO] early_stopping_patience_vae: 30\n",
      "[INFO] epochs_vae: 300\n",
      "[INFO] git_hash: N/A\n",
      "[INFO] global_tensor_path: /home/diego/Escritorio/limpio/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "[INFO] gridsearch_scoring: roc_auc\n",
      "[INFO] inner_folds: 5\n",
      "[INFO] intermediate_fc_dim_vae: quarter\n",
      "[INFO] latent_dim: 512\n",
      "[INFO] latent_features_type: mu\n",
      "[INFO] log_interval_epochs_vae: 5\n",
      "[INFO] lr_scheduler_T0: 50\n",
      "[INFO] lr_scheduler_eta_min: 1e-07\n",
      "[INFO] lr_scheduler_patience_vae: 15\n",
      "[INFO] lr_scheduler_type: plateau\n",
      "[INFO] lr_vae: 0.0001\n",
      "[INFO] metadata_features: ['Age', 'Sex']\n",
      "[INFO] metadata_path: /home/diego/Escritorio/limpio/SubjectsData_AAL3_procesado.csv\n",
      "[INFO] mlp_classifier_hidden_layers: 64,16\n",
      "[INFO] n_jobs_gridsearch: 8\n",
      "[INFO] norm_mode: zscore_offdiag\n",
      "[INFO] num_conv_layers_encoder: 4\n",
      "[INFO] num_workers: 4\n",
      "[INFO] outer_folds: 5\n",
      "[INFO] output_dir: ./resultados_FIN_v2\n",
      "[INFO] repeated_outer_folds_n_repeats: 1\n",
      "[INFO] save_fold_artefacts: True\n",
      "[INFO] save_vae_training_history: True\n",
      "[INFO] seed: 42\n",
      "[INFO] tune_sampler_params: False\n",
      "[INFO] use_layernorm_vae_fc: False\n",
      "[INFO] use_optuna_pruner: True\n",
      "[INFO] use_smote: True\n",
      "[INFO] vae_final_activation: tanh\n",
      "[INFO] vae_val_split_ratio: 0.2\n",
      "[INFO] weight_decay_vae: 1e-05\n",
      "[INFO] ------------------------------------\n",
      "[INFO] Cargando tensor global desde: /home/diego/Escritorio/limpio/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "[INFO] Tensor global cargado. Forma: (431, 7, 131, 131)\n",
      "[INFO] Cargando metadatos desde: /home/diego/Escritorio/limpio/SubjectsData_AAL3_procesado.csv\n",
      "[INFO] Metadatos cargados. Forma: (434, 32)\n",
      "[INFO] Usando canales seleccionados (índices): [1, 5]\n",
      "[INFO] Nombres de canales seleccionados: ['Pearson_Full_FisherZ_Signed', 'DistanceCorr']\n",
      "[INFO] Estratificando folds del CLASIFICADOR por: ['ResearchGroup_Mapped', 'Sex']\n",
      "[INFO] Sujetos CN/AD para clasificación: 184. CN: 89, AD: 95\n",
      "[INFO] Usando CV externa: StratifiedKFold con 5 iteraciones totales.\n",
      "[INFO] --- Iniciando Fold 1/5 ---\n",
      "[INFO] Fold 1/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 19 (51.4%)\n",
      "      M: 18 (48.6%)\n",
      "[INFO] Fold 1/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 187 (47.5%)\n",
      "      M: 207 (52.5%)\n",
      "    Age_Group:\n",
      "      0: 104 (26.4%)\n",
      "      1: 102 (25.9%)\n",
      "      2: 91 (23.1%)\n",
      "      3: 97 (24.6%)\n",
      "[INFO]   Fold 1/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 1/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 62 (19.7%)\n",
      "      CN: 56 (17.8%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 149 (47.3%)\n",
      "      M: 166 (52.7%)\n",
      "    Age_Group:\n",
      "      0: 84 (26.7%)\n",
      "      1: 81 (25.7%)\n",
      "      2: 73 (23.2%)\n",
      "      3: 77 (24.4%)\n",
      "[INFO] Fold 1/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 14 (17.7%)\n",
      "      CN: 15 (19.0%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 38 (48.1%)\n",
      "      M: 41 (51.9%)\n",
      "    Age_Group:\n",
      "      0: 20 (25.3%)\n",
      "      1: 21 (26.6%)\n",
      "      2: 18 (22.8%)\n",
      "      3: 20 (25.3%)\n",
      "[INFO]   Fold 1/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 2 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.046, std=0.777)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.397, std=1.627)\n",
      "[INFO]   Fold 1/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 1/5 Usando scheduler: ReduceLROnPlateau\n",
      "[INFO]   Fold 1/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 1/5 VAE E5/300, TrL: 44552.22 (R: 44440.76, KLD: 185.76), Beta: 0.600, LR: 1.00e-04, ValL: 44177.33 (R: 44108.86, KLD: 114.12)\n",
      "[INFO]   Fold 1/5 VAE E10/300, TrL: 40019.28 (R: 39491.07, KLD: 391.27), Beta: 1.350, LR: 1.00e-04, ValL: 38617.04 (R: 37634.27, KLD: 727.97)\n",
      "[INFO]   Fold 1/5 VAE E15/300, TrL: 34898.51 (R: 34294.86, KLD: 287.45), Beta: 2.100, LR: 1.00e-04, ValL: 34402.66 (R: 33816.38, KLD: 279.18)\n",
      "[INFO]   Fold 1/5 VAE E20/300, TrL: 32582.82 (R: 32048.06, KLD: 187.64), Beta: 2.850, LR: 1.00e-04, ValL: 32004.59 (R: 31527.48, KLD: 167.41)\n",
      "[INFO]   Fold 1/5 VAE E25/300, TrL: 30948.03 (R: 30399.89, KLD: 152.26), Beta: 3.600, LR: 1.00e-04, ValL: 30372.17 (R: 29857.44, KLD: 142.98)\n",
      "[INFO]   Fold 1/5 VAE E30/300, TrL: 29564.52 (R: 29008.41, KLD: 127.84), Beta: 4.350, LR: 1.00e-04, ValL: 28921.69 (R: 28429.60, KLD: 113.13)\n",
      "[INFO]   Fold 1/5 VAE E35/300, TrL: 28477.82 (R: 27920.90, KLD: 123.76), Beta: 4.500, LR: 1.00e-04, ValL: 27939.07 (R: 27426.14, KLD: 113.98)\n",
      "[INFO]   Fold 1/5 VAE E40/300, TrL: 27616.92 (R: 27078.11, KLD: 119.74), Beta: 4.500, LR: 1.00e-04, ValL: 26981.92 (R: 26515.88, KLD: 103.56)\n",
      "[INFO]   Fold 1/5 VAE E45/300, TrL: 26882.12 (R: 26341.00, KLD: 120.25), Beta: 4.500, LR: 1.00e-04, ValL: 26330.99 (R: 25925.38, KLD: 90.13)\n",
      "[INFO]   Fold 1/5 VAE E50/300, TrL: 26270.18 (R: 25738.95, KLD: 118.05), Beta: 4.500, LR: 1.00e-04, ValL: 25905.68 (R: 25503.71, KLD: 89.33)\n",
      "[INFO]   Fold 1/5 VAE E55/300, TrL: 25723.69 (R: 25200.98, KLD: 116.16), Beta: 4.500, LR: 1.00e-04, ValL: 25418.65 (R: 25016.75, KLD: 89.31)\n",
      "[INFO]   Fold 1/5 VAE E60/300, TrL: 25205.81 (R: 24670.82, KLD: 118.89), Beta: 4.500, LR: 1.00e-04, ValL: 25035.62 (R: 24634.25, KLD: 89.19)\n",
      "[INFO]   Fold 1/5 VAE E65/300, TrL: 24926.06 (R: 24402.83, KLD: 116.27), Beta: 4.500, LR: 1.00e-04, ValL: 24693.17 (R: 24305.09, KLD: 86.24)\n",
      "[INFO]   Fold 1/5 VAE E70/300, TrL: 24580.05 (R: 24015.18, KLD: 125.53), Beta: 4.500, LR: 1.00e-04, ValL: 24494.24 (R: 24084.60, KLD: 91.03)\n",
      "[INFO]   Fold 1/5 VAE E75/300, TrL: 24109.22 (R: 23573.96, KLD: 118.95), Beta: 4.500, LR: 1.00e-04, ValL: 24184.40 (R: 23804.33, KLD: 84.46)\n",
      "[INFO]   Fold 1/5 VAE E80/300, TrL: 23330.53 (R: 23207.64, KLD: 204.83), Beta: 0.600, LR: 1.00e-04, ValL: 23528.26 (R: 23429.60, KLD: 164.42)\n",
      "[INFO]   Fold 1/5 VAE E85/300, TrL: 23281.49 (R: 22998.58, KLD: 209.56), Beta: 1.350, LR: 1.00e-04, ValL: 23323.85 (R: 23091.29, KLD: 172.26)\n",
      "[INFO]   Fold 1/5 VAE E90/300, TrL: 23114.94 (R: 22718.36, KLD: 188.85), Beta: 2.100, LR: 1.00e-04, ValL: 23341.68 (R: 23008.40, KLD: 158.71)\n",
      "[INFO]   Fold 1/5 VAE E95/300, TrL: 22996.34 (R: 22537.95, KLD: 160.84), Beta: 2.850, LR: 1.00e-04, ValL: 23212.93 (R: 22844.28, KLD: 129.35)\n",
      "[INFO]   Fold 1/5 VAE E100/300, TrL: 22956.24 (R: 22413.84, KLD: 150.67), Beta: 3.600, LR: 1.00e-04, ValL: 23139.33 (R: 22740.34, KLD: 110.83)\n",
      "[INFO]   Fold 1/5 VAE E105/300, TrL: 22884.71 (R: 22246.09, KLD: 146.81), Beta: 4.350, LR: 1.00e-04, ValL: 23162.35 (R: 22691.69, KLD: 108.20)\n",
      "[INFO]   Fold 1/5 VAE E110/300, TrL: 22769.16 (R: 22178.54, KLD: 131.25), Beta: 4.500, LR: 1.00e-04, ValL: 23025.19 (R: 22577.33, KLD: 99.52)\n",
      "[INFO]   Fold 1/5 VAE E115/300, TrL: 22598.34 (R: 22011.59, KLD: 130.39), Beta: 4.500, LR: 1.00e-04, ValL: 22954.04 (R: 22481.54, KLD: 105.00)\n",
      "[INFO]   Fold 1/5 VAE E120/300, TrL: 22471.11 (R: 21857.47, KLD: 136.36), Beta: 4.500, LR: 1.00e-04, ValL: 22806.81 (R: 22340.19, KLD: 103.69)\n",
      "[INFO]   Fold 1/5 VAE E125/300, TrL: 22287.64 (R: 21706.77, KLD: 129.08), Beta: 4.500, LR: 1.00e-04, ValL: 22653.56 (R: 22198.54, KLD: 101.12)\n",
      "[INFO]   Fold 1/5 VAE E130/300, TrL: 22293.19 (R: 21690.02, KLD: 134.04), Beta: 4.500, LR: 1.00e-04, ValL: 22627.30 (R: 22149.31, KLD: 106.22)\n",
      "[INFO]   Fold 1/5 VAE E135/300, TrL: 22094.37 (R: 21479.81, KLD: 136.57), Beta: 4.500, LR: 1.00e-04, ValL: 22540.02 (R: 22084.90, KLD: 101.14)\n",
      "[INFO]   Fold 1/5 VAE E140/300, TrL: 21988.09 (R: 21398.22, KLD: 131.08), Beta: 4.500, LR: 1.00e-04, ValL: 22478.30 (R: 22015.79, KLD: 102.78)\n",
      "[INFO]   Fold 1/5 VAE E145/300, TrL: 22006.07 (R: 21338.09, KLD: 148.44), Beta: 4.500, LR: 1.00e-04, ValL: 22478.50 (R: 21959.68, KLD: 115.29)\n",
      "[INFO]   Fold 1/5 VAE E150/300, TrL: 21826.65 (R: 21184.56, KLD: 142.69), Beta: 4.500, LR: 1.00e-04, ValL: 22424.54 (R: 21907.00, KLD: 115.01)\n",
      "[INFO]   Fold 1/5 VAE E155/300, TrL: 21029.72 (R: 20913.33, KLD: 193.98), Beta: 0.600, LR: 1.00e-04, ValL: 21660.72 (R: 21562.28, KLD: 164.05)\n",
      "[INFO]   Fold 1/5 VAE E160/300, TrL: 20966.47 (R: 20676.58, KLD: 214.74), Beta: 1.350, LR: 1.00e-04, ValL: 21756.07 (R: 21502.73, KLD: 187.66)\n",
      "[INFO]   Fold 1/5 VAE E165/300, TrL: 21047.59 (R: 20625.90, KLD: 200.80), Beta: 2.100, LR: 1.00e-04, ValL: 21797.91 (R: 21446.38, KLD: 167.40)\n",
      "[INFO]   Fold 1/5 VAE E170/300, TrL: 21125.35 (R: 20616.20, KLD: 178.65), Beta: 2.850, LR: 1.00e-04, ValL: 21821.39 (R: 21393.53, KLD: 150.12)\n",
      "[INFO]   Fold 1/5 Learning rate reducido a 1.00e-05. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 1/5 VAE E175/300, TrL: 21045.44 (R: 20450.89, KLD: 165.15), Beta: 3.600, LR: 1.00e-05, ValL: 21873.47 (R: 21389.72, KLD: 134.38)\n",
      "[INFO]   Fold 1/5 VAE E180/300, TrL: 21132.61 (R: 20430.32, KLD: 161.45), Beta: 4.350, LR: 1.00e-05, ValL: 21980.84 (R: 21418.14, KLD: 129.36)\n",
      "[INFO]   Fold 1/5 VAE E185/300, TrL: 21246.79 (R: 20543.96, KLD: 156.18), Beta: 4.500, LR: 1.00e-05, ValL: 21900.71 (R: 21339.65, KLD: 124.68)\n",
      "[INFO]   Fold 1/5 Learning rate reducido a 1.00e-06. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 1/5 VAE E190/300, TrL: 21227.80 (R: 20533.59, KLD: 154.27), Beta: 4.500, LR: 1.00e-06, ValL: 21907.25 (R: 21361.46, KLD: 121.29)\n",
      "[INFO]   Fold 1/5 VAE E195/300, TrL: 21095.48 (R: 20409.86, KLD: 152.36), Beta: 4.500, LR: 1.00e-06, ValL: 21914.50 (R: 21371.50, KLD: 120.67)\n",
      "[INFO]   Fold 1/5 VAE E200/300, TrL: 21224.54 (R: 20534.79, KLD: 153.28), Beta: 4.500, LR: 1.00e-06, ValL: 21890.53 (R: 21344.53, KLD: 121.33)\n",
      "[INFO]   Fold 1/5 Learning rate reducido a 1.00e-07. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 1/5 VAE E205/300, TrL: 21177.13 (R: 20493.56, KLD: 151.91), Beta: 4.500, LR: 1.00e-07, ValL: 21951.87 (R: 21413.97, KLD: 119.53)\n",
      "[INFO]   Fold 1/5 VAE E210/300, TrL: 21180.53 (R: 20494.49, KLD: 152.45), Beta: 4.500, LR: 1.00e-07, ValL: 21931.93 (R: 21396.86, KLD: 118.90)\n",
      "[INFO]   Fold 1/5 VAE E215/300, TrL: 21140.10 (R: 20451.51, KLD: 153.02), Beta: 4.500, LR: 1.00e-07, ValL: 21938.99 (R: 21398.38, KLD: 120.14)\n",
      "[INFO]   Fold 1/5 Learning rate reducido a 1.00e-08. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 1/5 VAE E220/300, TrL: 21185.86 (R: 20500.19, KLD: 152.37), Beta: 4.500, LR: 1.00e-07, ValL: 21934.06 (R: 21395.34, KLD: 119.72)\n",
      "[INFO]   Fold 1/5 VAE E225/300, TrL: 21239.14 (R: 20557.75, KLD: 151.42), Beta: 4.500, LR: 1.00e-08, ValL: 21954.97 (R: 21418.25, KLD: 119.27)\n",
      "[INFO]   Fold 1/5 VAE E230/300, TrL: 20673.95 (R: 20583.19, KLD: 151.26), Beta: 0.600, LR: 1.00e-08, ValL: 21410.77 (R: 21338.88, KLD: 119.81)\n",
      "[INFO]   Fold 1/5 VAE E235/300, TrL: 20685.39 (R: 20480.41, KLD: 151.84), Beta: 1.350, LR: 1.00e-08, ValL: 21604.15 (R: 21442.76, KLD: 119.55)\n",
      "[INFO]   Fold 1/5 VAE E240/300, TrL: 20798.91 (R: 20478.83, KLD: 152.42), Beta: 2.100, LR: 1.00e-08, ValL: 21708.55 (R: 21457.67, KLD: 119.47)\n",
      "[INFO]   Fold 1/5 VAE E245/300, TrL: 20888.21 (R: 20457.83, KLD: 151.01), Beta: 2.850, LR: 1.00e-08, ValL: 21725.09 (R: 21387.32, KLD: 118.52)\n",
      "[INFO]   Fold 1/5 VAE E250/300, TrL: 21067.05 (R: 20513.76, KLD: 153.69), Beta: 3.600, LR: 1.00e-08, ValL: 21845.05 (R: 21410.84, KLD: 120.61)\n",
      "[INFO]   Fold 1/5 VAE E255/300, TrL: 21100.82 (R: 20444.32, KLD: 150.92), Beta: 4.350, LR: 1.00e-08, ValL: 21890.31 (R: 21368.30, KLD: 120.00)\n",
      "[INFO]   Fold 1/5 Early stopping VAE en epoch 258. Mejor val_loss: 21401.1676\n",
      "[INFO]   Fold 1/5 VAE final model loaded (best val_loss: 21401.1676).\n",
      "[INFO]   Fold 1/5 Modelo VAE guardado en: resultados_FIN_v2/fold_1/vae_model_fold_1.pt\n",
      "[INFO] Fold 1/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 73 (49.7%)\n",
      "      M: 74 (50.3%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 514)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 1374, 'model__learning_rate': 0.03429958729524469, 'model__max_depth': 5, 'model__subsample': 0.6217728422130795, 'model__colsample_bytree': 0.6156090918100828, 'model__min_child_weight': 1.5010908714868791}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 1 (xgb): AUC=0.8567, Bal.Acc=0.7558\n",
      "[INFO]       Pipeline completo de xgb del fold 1 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__C': 8436.359542865315, 'model__gamma': 3.437901114772467e-05, 'model__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 1 (svm): AUC=0.7456, Bal.Acc=0.7018\n",
      "[INFO]       Pipeline completo de svm del fold 1 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 1.1670546224919343}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 1 (logreg): AUC=0.7953, Bal.Acc=0.7544\n",
      "[INFO]       Pipeline completo de logreg del fold 1 guardado.\n",
      "[INFO]   Fold 1/5 completado en 479.42 segundos.\n",
      "[INFO] --- Iniciando Fold 2/5 ---\n",
      "[INFO] Fold 2/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 19 (51.4%)\n",
      "      M: 18 (48.6%)\n",
      "[INFO] Fold 2/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 187 (47.5%)\n",
      "      M: 207 (52.5%)\n",
      "    Age_Group:\n",
      "      0: 98 (24.9%)\n",
      "      1: 101 (25.6%)\n",
      "      2: 94 (23.9%)\n",
      "      3: 101 (25.6%)\n",
      "[INFO]   Fold 2/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 2/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 61 (19.4%)\n",
      "      CN: 57 (18.1%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 150 (47.6%)\n",
      "      M: 165 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 79 (25.1%)\n",
      "      1: 81 (25.7%)\n",
      "      2: 75 (23.8%)\n",
      "      3: 80 (25.4%)\n",
      "[INFO] Fold 2/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 15 (19.0%)\n",
      "      CN: 14 (17.7%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 37 (46.8%)\n",
      "      M: 42 (53.2%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 20 (25.3%)\n",
      "      2: 19 (24.1%)\n",
      "      3: 21 (26.6%)\n",
      "[INFO]   Fold 2/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 2 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.049, std=0.776)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.408, std=1.730)\n",
      "[INFO]   Fold 2/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 2/5 Usando scheduler: ReduceLROnPlateau\n",
      "[INFO]   Fold 2/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 2/5 VAE E5/300, TrL: 43807.82 (R: 43700.31, KLD: 179.18), Beta: 0.600, LR: 1.00e-04, ValL: 37711.17 (R: 37651.75, KLD: 99.04)\n",
      "[INFO]   Fold 2/5 VAE E10/300, TrL: 39591.00 (R: 39117.26, KLD: 350.92), Beta: 1.350, LR: 1.00e-04, ValL: 32714.15 (R: 31742.43, KLD: 719.79)\n",
      "[INFO]   Fold 2/5 VAE E15/300, TrL: 34504.17 (R: 33876.23, KLD: 299.01), Beta: 2.100, LR: 1.00e-04, ValL: 28849.34 (R: 28235.50, KLD: 292.31)\n",
      "[INFO]   Fold 2/5 VAE E20/300, TrL: 32388.33 (R: 31823.82, KLD: 198.07), Beta: 2.850, LR: 1.00e-04, ValL: 26747.01 (R: 26180.96, KLD: 198.61)\n",
      "[INFO]   Fold 2/5 VAE E25/300, TrL: 30780.72 (R: 30200.48, KLD: 161.18), Beta: 3.600, LR: 1.00e-04, ValL: 25193.48 (R: 24624.80, KLD: 157.97)\n",
      "[INFO]   Fold 2/5 VAE E30/300, TrL: 29663.61 (R: 29049.45, KLD: 141.19), Beta: 4.350, LR: 1.00e-04, ValL: 23899.21 (R: 23312.45, KLD: 134.89)\n",
      "[INFO]   Fold 2/5 VAE E35/300, TrL: 28505.85 (R: 27969.94, KLD: 119.09), Beta: 4.500, LR: 1.00e-04, ValL: 22788.64 (R: 22300.77, KLD: 108.42)\n",
      "[INFO]   Fold 2/5 VAE E40/300, TrL: 27714.71 (R: 27148.44, KLD: 125.84), Beta: 4.500, LR: 1.00e-04, ValL: 21896.09 (R: 21492.96, KLD: 89.59)\n",
      "[INFO]   Fold 2/5 VAE E45/300, TrL: 27114.53 (R: 26612.25, KLD: 111.62), Beta: 4.500, LR: 1.00e-04, ValL: 21408.88 (R: 20940.36, KLD: 104.12)\n",
      "[INFO]   Fold 2/5 VAE E50/300, TrL: 26562.20 (R: 26016.56, KLD: 121.25), Beta: 4.500, LR: 1.00e-04, ValL: 20826.33 (R: 20379.01, KLD: 99.40)\n",
      "[INFO]   Fold 2/5 VAE E55/300, TrL: 26172.66 (R: 25591.21, KLD: 129.21), Beta: 4.500, LR: 1.00e-04, ValL: 20461.35 (R: 19997.26, KLD: 103.13)\n",
      "[INFO]   Fold 2/5 VAE E60/300, TrL: 25643.95 (R: 25098.28, KLD: 121.26), Beta: 4.500, LR: 1.00e-04, ValL: 19995.59 (R: 19580.34, KLD: 92.28)\n",
      "[INFO]   Fold 2/5 VAE E65/300, TrL: 25264.07 (R: 24737.77, KLD: 116.96), Beta: 4.500, LR: 1.00e-04, ValL: 19541.10 (R: 19149.80, KLD: 86.96)\n",
      "[INFO]   Fold 2/5 VAE E70/300, TrL: 24851.42 (R: 24312.17, KLD: 119.83), Beta: 4.500, LR: 1.00e-04, ValL: 19240.16 (R: 18839.54, KLD: 89.03)\n",
      "[INFO]   Fold 2/5 VAE E75/300, TrL: 24559.33 (R: 24038.49, KLD: 115.74), Beta: 4.500, LR: 1.00e-04, ValL: 19002.74 (R: 18582.14, KLD: 93.47)\n",
      "[INFO]   Fold 2/5 VAE E80/300, TrL: 23754.55 (R: 23633.80, KLD: 201.25), Beta: 0.600, LR: 1.00e-04, ValL: 18170.25 (R: 18069.74, KLD: 167.52)\n",
      "[INFO]   Fold 2/5 VAE E85/300, TrL: 23632.21 (R: 23344.66, KLD: 213.00), Beta: 1.350, LR: 1.00e-04, ValL: 18023.76 (R: 17776.11, KLD: 183.44)\n",
      "[INFO]   Fold 2/5 VAE E90/300, TrL: 23390.35 (R: 22997.22, KLD: 187.21), Beta: 2.100, LR: 1.00e-04, ValL: 17930.91 (R: 17593.11, KLD: 160.86)\n",
      "[INFO]   Fold 2/5 VAE E95/300, TrL: 23366.73 (R: 22877.59, KLD: 171.63), Beta: 2.850, LR: 1.00e-04, ValL: 17901.21 (R: 17499.54, KLD: 140.94)\n",
      "[INFO]   Fold 2/5 VAE E100/300, TrL: 23252.64 (R: 22707.53, KLD: 151.42), Beta: 3.600, LR: 1.00e-04, ValL: 17773.50 (R: 17322.78, KLD: 125.20)\n",
      "[INFO]   Fold 2/5 VAE E105/300, TrL: 23101.84 (R: 22483.29, KLD: 142.20), Beta: 4.350, LR: 1.00e-04, ValL: 17642.83 (R: 17162.11, KLD: 110.51)\n",
      "[INFO]   Fold 2/5 VAE E110/300, TrL: 23046.12 (R: 22455.55, KLD: 131.24), Beta: 4.500, LR: 1.00e-04, ValL: 17659.31 (R: 17119.79, KLD: 119.89)\n",
      "[INFO]   Fold 2/5 VAE E115/300, TrL: 22798.95 (R: 22191.62, KLD: 134.96), Beta: 4.500, LR: 1.00e-04, ValL: 17452.05 (R: 16950.21, KLD: 111.52)\n",
      "[INFO]   Fold 2/5 VAE E120/300, TrL: 22620.31 (R: 22033.46, KLD: 130.41), Beta: 4.500, LR: 1.00e-04, ValL: 17268.24 (R: 16800.19, KLD: 104.01)\n",
      "[INFO]   Fold 2/5 VAE E125/300, TrL: 22531.14 (R: 21952.29, KLD: 128.63), Beta: 4.500, LR: 1.00e-04, ValL: 17218.51 (R: 16753.78, KLD: 103.27)\n",
      "[INFO]   Fold 2/5 VAE E130/300, TrL: 22414.88 (R: 21834.94, KLD: 128.88), Beta: 4.500, LR: 1.00e-04, ValL: 17136.79 (R: 16683.61, KLD: 100.71)\n",
      "[INFO]   Fold 2/5 VAE E135/300, TrL: 22313.02 (R: 21736.09, KLD: 128.21), Beta: 4.500, LR: 1.00e-04, ValL: 17030.36 (R: 16562.89, KLD: 103.88)\n",
      "[INFO]   Fold 2/5 VAE E140/300, TrL: 22196.31 (R: 21617.52, KLD: 128.62), Beta: 4.500, LR: 1.00e-04, ValL: 16923.71 (R: 16454.72, KLD: 104.22)\n",
      "[INFO]   Fold 2/5 VAE E145/300, TrL: 22037.62 (R: 21446.65, KLD: 131.33), Beta: 4.500, LR: 1.00e-04, ValL: 16859.41 (R: 16386.87, KLD: 105.01)\n",
      "[INFO]   Fold 2/5 VAE E150/300, TrL: 21932.39 (R: 21347.98, KLD: 129.87), Beta: 4.500, LR: 1.00e-04, ValL: 16783.64 (R: 16311.09, KLD: 105.01)\n",
      "[INFO]   Fold 2/5 VAE E155/300, TrL: 21188.70 (R: 21073.03, KLD: 192.78), Beta: 0.600, LR: 1.00e-04, ValL: 16267.53 (R: 16164.67, KLD: 171.44)\n",
      "[INFO]   Fold 2/5 VAE E160/300, TrL: 21213.45 (R: 20918.39, KLD: 218.56), Beta: 1.350, LR: 1.00e-04, ValL: 16256.63 (R: 15995.91, KLD: 193.13)\n",
      "[INFO]   Fold 2/5 VAE E165/300, TrL: 21243.23 (R: 20820.78, KLD: 201.17), Beta: 2.100, LR: 1.00e-04, ValL: 16286.48 (R: 15921.00, KLD: 174.04)\n",
      "[INFO]   Fold 2/5 VAE E170/300, TrL: 21303.65 (R: 20791.27, KLD: 179.78), Beta: 2.850, LR: 1.00e-04, ValL: 16395.00 (R: 15958.16, KLD: 153.28)\n",
      "[INFO]   Fold 2/5 Learning rate reducido a 1.00e-05. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 2/5 VAE E175/300, TrL: 21428.62 (R: 20846.56, KLD: 161.68), Beta: 3.600, LR: 1.00e-05, ValL: 16396.24 (R: 15912.72, KLD: 134.31)\n",
      "[INFO]   Fold 2/5 VAE E180/300, TrL: 21401.30 (R: 20712.06, KLD: 158.45), Beta: 4.350, LR: 1.00e-05, ValL: 16479.39 (R: 15921.43, KLD: 128.27)\n",
      "[INFO]   Fold 2/5 VAE E185/300, TrL: 21475.23 (R: 20781.52, KLD: 154.16), Beta: 4.500, LR: 1.00e-05, ValL: 16481.15 (R: 15922.40, KLD: 124.17)\n",
      "[INFO]   Fold 2/5 Learning rate reducido a 1.00e-06. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 2/5 VAE E190/300, TrL: 21423.49 (R: 20751.18, KLD: 149.40), Beta: 4.500, LR: 1.00e-05, ValL: 16464.76 (R: 15930.69, KLD: 118.68)\n",
      "[INFO]   Fold 2/5 VAE E195/300, TrL: 21538.27 (R: 20858.39, KLD: 151.08), Beta: 4.500, LR: 1.00e-06, ValL: 16421.74 (R: 15887.05, KLD: 118.82)\n",
      "[INFO]   Fold 2/5 VAE E200/300, TrL: 21349.13 (R: 20680.68, KLD: 148.54), Beta: 4.500, LR: 1.00e-06, ValL: 16435.30 (R: 15901.37, KLD: 118.65)\n",
      "[INFO]   Fold 2/5 VAE E205/300, TrL: 21418.09 (R: 20751.06, KLD: 148.23), Beta: 4.500, LR: 1.00e-06, ValL: 16434.69 (R: 15898.03, KLD: 119.26)\n",
      "[INFO]   Fold 2/5 Learning rate reducido a 1.00e-07. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 2/5 VAE E210/300, TrL: 21335.06 (R: 20659.82, KLD: 150.05), Beta: 4.500, LR: 1.00e-07, ValL: 16481.67 (R: 15946.85, KLD: 118.85)\n",
      "[INFO]   Fold 2/5 VAE E215/300, TrL: 21348.62 (R: 20679.04, KLD: 148.80), Beta: 4.500, LR: 1.00e-07, ValL: 16410.48 (R: 15879.85, KLD: 117.92)\n",
      "[INFO]   Fold 2/5 VAE E220/300, TrL: 21401.24 (R: 20729.87, KLD: 149.19), Beta: 4.500, LR: 1.00e-07, ValL: 16431.23 (R: 15899.00, KLD: 118.27)\n",
      "[INFO]   Fold 2/5 Learning rate reducido a 1.00e-08. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 2/5 VAE E225/300, TrL: 21388.53 (R: 20718.09, KLD: 148.99), Beta: 4.500, LR: 1.00e-08, ValL: 16417.38 (R: 15885.07, KLD: 118.29)\n",
      "[INFO]   Fold 2/5 VAE E230/300, TrL: 20868.62 (R: 20778.82, KLD: 149.66), Beta: 0.600, LR: 1.00e-08, ValL: 15931.60 (R: 15860.23, KLD: 118.95)\n",
      "[INFO]   Fold 2/5 VAE E235/300, TrL: 20944.18 (R: 20743.08, KLD: 148.96), Beta: 1.350, LR: 1.00e-08, ValL: 16095.68 (R: 15936.13, KLD: 118.19)\n",
      "[INFO]   Fold 2/5 VAE E240/300, TrL: 21000.91 (R: 20686.15, KLD: 149.89), Beta: 2.100, LR: 1.00e-08, ValL: 16121.67 (R: 15873.10, KLD: 118.36)\n",
      "[INFO]   Fold 2/5 VAE E245/300, TrL: 21087.25 (R: 20664.94, KLD: 148.18), Beta: 2.850, LR: 1.00e-08, ValL: 16202.63 (R: 15865.88, KLD: 118.16)\n",
      "[INFO]   Fold 2/5 VAE E250/300, TrL: 21291.41 (R: 20751.19, KLD: 150.06), Beta: 3.600, LR: 1.00e-08, ValL: 16356.97 (R: 15930.62, KLD: 118.43)\n",
      "[INFO]   Fold 2/5 VAE E255/300, TrL: 21439.52 (R: 20793.01, KLD: 148.62), Beta: 4.350, LR: 1.00e-08, ValL: 16413.89 (R: 15899.37, KLD: 118.28)\n",
      "[INFO]   Fold 2/5 Early stopping VAE en epoch 258. Mejor val_loss: 15899.5687\n",
      "[INFO]   Fold 2/5 VAE final model loaded (best val_loss: 15899.5687).\n",
      "[INFO]   Fold 2/5 Modelo VAE guardado en: resultados_FIN_v2/fold_2/vae_model_fold_2.pt\n",
      "[INFO] Fold 2/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 73 (49.7%)\n",
      "      M: 74 (50.3%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 514)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 1142, 'model__learning_rate': 0.004292934360065019, 'model__max_depth': 5, 'model__subsample': 0.5110392044855513, 'model__colsample_bytree': 0.6249337931042787, 'model__min_child_weight': 1.469825565426142}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 2 (xgb): AUC=0.7281, Bal.Acc=0.7588\n",
      "[INFO]       Pipeline completo de xgb del fold 2 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__C': 534.1837491068931, 'model__gamma': 7.479020026559421e-07, 'model__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 2 (svm): AUC=0.6959, Bal.Acc=0.6740\n",
      "[INFO]       Pipeline completo de svm del fold 2 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.0022240262425309715}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 2 (logreg): AUC=0.7339, Bal.Acc=0.7018\n",
      "[INFO]       Pipeline completo de logreg del fold 2 guardado.\n",
      "[INFO]   Fold 2/5 completado en 568.46 segundos.\n",
      "[INFO] --- Iniciando Fold 3/5 ---\n",
      "[INFO] Fold 3/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 18 (48.6%)\n",
      "      M: 19 (51.4%)\n",
      "[INFO] Fold 3/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 188 (47.7%)\n",
      "      M: 206 (52.3%)\n",
      "    Age_Group:\n",
      "      0: 97 (24.6%)\n",
      "      1: 104 (26.4%)\n",
      "      2: 97 (24.6%)\n",
      "      3: 96 (24.4%)\n",
      "[INFO]   Fold 3/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 3/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 60 (19.0%)\n",
      "      CN: 58 (18.4%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 150 (47.6%)\n",
      "      M: 165 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 78 (24.8%)\n",
      "      1: 83 (26.3%)\n",
      "      2: 78 (24.8%)\n",
      "      3: 76 (24.1%)\n",
      "[INFO] Fold 3/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 16 (20.3%)\n",
      "      CN: 13 (16.5%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 38 (48.1%)\n",
      "      M: 41 (51.9%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 21 (26.6%)\n",
      "      2: 19 (24.1%)\n",
      "      3: 20 (25.3%)\n",
      "[INFO]   Fold 3/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 2 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.050, std=0.780)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.419, std=1.767)\n",
      "[INFO]   Fold 3/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 3/5 Usando scheduler: ReduceLROnPlateau\n",
      "[INFO]   Fold 3/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 3/5 VAE E5/300, TrL: 43812.31 (R: 43704.37, KLD: 179.91), Beta: 0.600, LR: 1.00e-04, ValL: 36901.91 (R: 36844.10, KLD: 96.36)\n",
      "[INFO]   Fold 3/5 VAE E10/300, TrL: 39773.20 (R: 39306.42, KLD: 345.76), Beta: 1.350, LR: 1.00e-04, ValL: 32165.29 (R: 31183.64, KLD: 727.15)\n",
      "[INFO]   Fold 3/5 VAE E15/300, TrL: 34614.68 (R: 33936.59, KLD: 322.90), Beta: 2.100, LR: 1.00e-04, ValL: 28347.47 (R: 27511.85, KLD: 397.91)\n",
      "[INFO]   Fold 3/5 VAE E20/300, TrL: 32081.04 (R: 31483.59, KLD: 209.63), Beta: 2.850, LR: 1.00e-04, ValL: 26089.46 (R: 25224.54, KLD: 303.48)\n",
      "[INFO]   Fold 3/5 VAE E25/300, TrL: 30310.08 (R: 29712.31, KLD: 166.05), Beta: 3.600, LR: 1.00e-04, ValL: 24482.25 (R: 23596.41, KLD: 246.07)\n",
      "[INFO]   Fold 3/5 VAE E30/300, TrL: 29001.41 (R: 28358.59, KLD: 147.77), Beta: 4.350, LR: 1.00e-04, ValL: 23220.24 (R: 22444.37, KLD: 178.36)\n",
      "[INFO]   Fold 3/5 VAE E35/300, TrL: 27885.29 (R: 27296.40, KLD: 130.87), Beta: 4.500, LR: 1.00e-04, ValL: 22177.33 (R: 21509.54, KLD: 148.40)\n",
      "[INFO]   Fold 3/5 VAE E40/300, TrL: 27175.88 (R: 26590.42, KLD: 130.10), Beta: 4.500, LR: 1.00e-04, ValL: 21709.26 (R: 20904.45, KLD: 178.85)\n",
      "[INFO]   Fold 3/5 VAE E45/300, TrL: 26473.43 (R: 25902.31, KLD: 126.92), Beta: 4.500, LR: 1.00e-04, ValL: 20913.86 (R: 20321.47, KLD: 131.64)\n",
      "[INFO]   Fold 3/5 VAE E50/300, TrL: 26000.73 (R: 25435.57, KLD: 125.59), Beta: 4.500, LR: 1.00e-04, ValL: 20604.92 (R: 19962.04, KLD: 142.86)\n",
      "[INFO]   Fold 3/5 VAE E55/300, TrL: 25568.70 (R: 25033.23, KLD: 119.00), Beta: 4.500, LR: 1.00e-04, ValL: 20044.38 (R: 19501.37, KLD: 120.67)\n",
      "[INFO]   Fold 3/5 VAE E60/300, TrL: 25030.64 (R: 24478.34, KLD: 122.73), Beta: 4.500, LR: 1.00e-04, ValL: 19695.81 (R: 19110.62, KLD: 130.04)\n",
      "[INFO]   Fold 3/5 VAE E65/300, TrL: 24824.27 (R: 24278.68, KLD: 121.24), Beta: 4.500, LR: 1.00e-04, ValL: 19314.56 (R: 18764.16, KLD: 122.31)\n",
      "[INFO]   Fold 3/5 VAE E70/300, TrL: 24508.59 (R: 23959.40, KLD: 122.04), Beta: 4.500, LR: 1.00e-04, ValL: 19162.03 (R: 18602.45, KLD: 124.35)\n",
      "[INFO]   Fold 3/5 VAE E75/300, TrL: 24214.47 (R: 23659.75, KLD: 123.27), Beta: 4.500, LR: 1.00e-04, ValL: 18765.95 (R: 18234.99, KLD: 117.99)\n",
      "[INFO]   Fold 3/5 VAE E80/300, TrL: 23317.31 (R: 23193.52, KLD: 206.32), Beta: 0.600, LR: 1.00e-04, ValL: 18087.73 (R: 17940.86, KLD: 244.77)\n",
      "[INFO]   Fold 3/5 VAE E85/300, TrL: 23176.99 (R: 22891.38, KLD: 211.56), Beta: 1.350, LR: 1.00e-04, ValL: 17960.85 (R: 17660.62, KLD: 222.39)\n",
      "[INFO]   Fold 3/5 VAE E90/300, TrL: 23160.12 (R: 22769.85, KLD: 185.84), Beta: 2.100, LR: 1.00e-04, ValL: 17944.23 (R: 17522.05, KLD: 201.04)\n",
      "[INFO]   Fold 3/5 VAE E95/300, TrL: 23092.46 (R: 22618.72, KLD: 166.22), Beta: 2.850, LR: 1.00e-04, ValL: 17920.51 (R: 17424.17, KLD: 174.15)\n",
      "[INFO]   Fold 3/5 VAE E100/300, TrL: 22964.15 (R: 22406.82, KLD: 154.81), Beta: 3.600, LR: 1.00e-04, ValL: 17804.86 (R: 17256.93, KLD: 152.20)\n",
      "[INFO]   Fold 3/5 VAE E105/300, TrL: 22854.39 (R: 22239.97, KLD: 141.25), Beta: 4.350, LR: 1.00e-04, ValL: 17863.60 (R: 17263.81, KLD: 137.88)\n",
      "[INFO]   Fold 3/5 VAE E110/300, TrL: 22718.36 (R: 22120.52, KLD: 132.85), Beta: 4.500, LR: 1.00e-04, ValL: 17671.56 (R: 17085.96, KLD: 130.13)\n",
      "[INFO]   Fold 3/5 VAE E115/300, TrL: 22493.31 (R: 21899.11, KLD: 132.04), Beta: 4.500, LR: 1.00e-04, ValL: 17602.03 (R: 17039.45, KLD: 125.02)\n",
      "[INFO]   Fold 3/5 VAE E120/300, TrL: 22482.32 (R: 21878.71, KLD: 134.14), Beta: 4.500, LR: 1.00e-04, ValL: 17422.11 (R: 16874.69, KLD: 121.65)\n",
      "[INFO]   Fold 3/5 VAE E125/300, TrL: 22246.90 (R: 21630.57, KLD: 136.96), Beta: 4.500, LR: 1.00e-04, ValL: 17361.54 (R: 16809.28, KLD: 122.72)\n",
      "[INFO]   Fold 3/5 VAE E130/300, TrL: 22187.39 (R: 21594.42, KLD: 131.77), Beta: 4.500, LR: 1.00e-04, ValL: 17278.74 (R: 16724.26, KLD: 123.22)\n",
      "[INFO]   Fold 3/5 VAE E135/300, TrL: 22041.99 (R: 21434.60, KLD: 134.98), Beta: 4.500, LR: 1.00e-04, ValL: 17186.69 (R: 16627.00, KLD: 124.38)\n",
      "[INFO]   Fold 3/5 VAE E140/300, TrL: 21936.77 (R: 21352.88, KLD: 129.75), Beta: 4.500, LR: 1.00e-04, ValL: 17091.42 (R: 16575.63, KLD: 114.62)\n",
      "[INFO]   Fold 3/5 VAE E145/300, TrL: 21832.09 (R: 21237.98, KLD: 132.02), Beta: 4.500, LR: 1.00e-04, ValL: 17040.02 (R: 16513.90, KLD: 116.92)\n",
      "[INFO]   Fold 3/5 VAE E150/300, TrL: 21728.58 (R: 21134.95, KLD: 131.92), Beta: 4.500, LR: 1.00e-04, ValL: 16918.60 (R: 16425.89, KLD: 109.49)\n",
      "[INFO]   Fold 3/5 VAE E155/300, TrL: 21041.81 (R: 20924.17, KLD: 196.07), Beta: 0.600, LR: 1.00e-04, ValL: 16426.71 (R: 16311.61, KLD: 191.83)\n",
      "[INFO]   Fold 3/5 VAE E160/300, TrL: 21166.58 (R: 20870.60, KLD: 219.24), Beta: 1.350, LR: 1.00e-04, ValL: 16454.28 (R: 16171.92, KLD: 209.15)\n",
      "[INFO]   Fold 3/5 VAE E165/300, TrL: 21101.52 (R: 20678.10, KLD: 201.63), Beta: 2.100, LR: 1.00e-04, ValL: 16526.08 (R: 16124.64, KLD: 191.16)\n",
      "[INFO]   Fold 3/5 VAE E170/300, TrL: 21161.28 (R: 20648.65, KLD: 179.87), Beta: 2.850, LR: 1.00e-04, ValL: 16573.54 (R: 16113.15, KLD: 161.54)\n",
      "[INFO]   Fold 3/5 Learning rate reducido a 1.00e-05. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 3/5 VAE E175/300, TrL: 21170.10 (R: 20571.97, KLD: 166.15), Beta: 3.600, LR: 1.00e-05, ValL: 16663.91 (R: 16139.25, KLD: 145.74)\n",
      "[INFO]   Fold 3/5 VAE E180/300, TrL: 21363.26 (R: 20669.54, KLD: 159.48), Beta: 4.350, LR: 1.00e-05, ValL: 16691.03 (R: 16081.30, KLD: 140.17)\n",
      "[INFO]   Fold 3/5 VAE E185/300, TrL: 21295.35 (R: 20595.57, KLD: 155.51), Beta: 4.500, LR: 1.00e-05, ValL: 16683.30 (R: 16080.44, KLD: 133.97)\n",
      "[INFO]   Fold 3/5 Learning rate reducido a 1.00e-06. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 3/5 VAE E190/300, TrL: 21371.62 (R: 20686.76, KLD: 152.19), Beta: 4.500, LR: 1.00e-06, ValL: 16674.19 (R: 16087.52, KLD: 130.37)\n",
      "[INFO]   Fold 3/5 VAE E195/300, TrL: 21303.62 (R: 20616.79, KLD: 152.63), Beta: 4.500, LR: 1.00e-06, ValL: 16667.28 (R: 16082.48, KLD: 129.96)\n",
      "[INFO]   Fold 3/5 VAE E200/300, TrL: 21306.86 (R: 20625.55, KLD: 151.40), Beta: 4.500, LR: 1.00e-06, ValL: 16673.50 (R: 16089.65, KLD: 129.75)\n",
      "[INFO]   Fold 3/5 Learning rate reducido a 1.00e-07. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 3/5 VAE E205/300, TrL: 21360.65 (R: 20678.80, KLD: 151.52), Beta: 4.500, LR: 1.00e-06, ValL: 16690.72 (R: 16106.03, KLD: 129.93)\n",
      "[INFO]   Fold 3/5 VAE E210/300, TrL: 21255.68 (R: 20572.84, KLD: 151.74), Beta: 4.500, LR: 1.00e-07, ValL: 16723.64 (R: 16142.30, KLD: 129.19)\n",
      "[INFO]   Fold 3/5 VAE E215/300, TrL: 21312.14 (R: 20628.85, KLD: 151.84), Beta: 4.500, LR: 1.00e-07, ValL: 16642.84 (R: 16062.36, KLD: 128.99)\n",
      "[INFO]   Fold 3/5 VAE E220/300, TrL: 21195.35 (R: 20514.13, KLD: 151.38), Beta: 4.500, LR: 1.00e-07, ValL: 16631.86 (R: 16051.84, KLD: 128.89)\n",
      "[INFO]   Fold 3/5 Learning rate reducido a 1.00e-08. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 3/5 VAE E225/300, TrL: 21314.85 (R: 20634.98, KLD: 151.08), Beta: 4.500, LR: 1.00e-08, ValL: 16677.29 (R: 16098.04, KLD: 128.72)\n",
      "[INFO]   Fold 3/5 VAE E230/300, TrL: 20724.09 (R: 20633.00, KLD: 151.83), Beta: 0.600, LR: 1.00e-08, ValL: 16150.09 (R: 16072.27, KLD: 129.69)\n",
      "[INFO]   Fold 3/5 VAE E235/300, TrL: 20836.01 (R: 20632.15, KLD: 151.01), Beta: 1.350, LR: 1.00e-08, ValL: 16271.33 (R: 16097.34, KLD: 128.88)\n",
      "[INFO]   Fold 3/5 VAE E240/300, TrL: 20857.84 (R: 20537.42, KLD: 152.58), Beta: 2.100, LR: 1.00e-08, ValL: 16408.22 (R: 16135.22, KLD: 130.00)\n",
      "[INFO]   Fold 3/5 VAE E245/300, TrL: 21017.73 (R: 20589.57, KLD: 150.23), Beta: 2.850, LR: 1.00e-08, ValL: 16504.35 (R: 16137.44, KLD: 128.74)\n",
      "[INFO]   Fold 3/5 VAE E250/300, TrL: 21200.94 (R: 20654.51, KLD: 151.79), Beta: 3.600, LR: 1.00e-08, ValL: 16521.92 (R: 16059.05, KLD: 128.58)\n",
      "[INFO]   Fold 3/5 VAE E255/300, TrL: 21238.24 (R: 20580.67, KLD: 151.17), Beta: 4.350, LR: 1.00e-08, ValL: 16693.08 (R: 16134.13, KLD: 128.49)\n",
      "[INFO]   Fold 3/5 Early stopping VAE en epoch 258. Mejor val_loss: 16096.2065\n",
      "[INFO]   Fold 3/5 VAE final model loaded (best val_loss: 16096.2065).\n",
      "[INFO]   Fold 3/5 Modelo VAE guardado en: resultados_FIN_v2/fold_3/vae_model_fold_3.pt\n",
      "[INFO] Fold 3/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 74 (50.3%)\n",
      "      M: 73 (49.7%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 514)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 249, 'model__learning_rate': 0.00382871829407463, 'model__max_depth': 7, 'model__subsample': 0.9288868157402714, 'model__colsample_bytree': 0.7710615579730726, 'model__min_child_weight': 1.896531468696442}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 3 (xgb): AUC=0.8041, Bal.Acc=0.6725\n",
      "[INFO]       Pipeline completo de xgb del fold 3 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__C': 78.44912971853037, 'model__gamma': 1.3925936290053372e-05, 'model__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 3 (svm): AUC=0.8304, Bal.Acc=0.7281\n",
      "[INFO]       Pipeline completo de svm del fold 3 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.005301792356388339}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 3 (logreg): AUC=0.8246, Bal.Acc=0.7281\n",
      "[INFO]       Pipeline completo de logreg del fold 3 guardado.\n",
      "[INFO]   Fold 3/5 completado en 606.78 segundos.\n",
      "[INFO] --- Iniciando Fold 4/5 ---\n",
      "[INFO] Fold 4/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 18 (48.6%)\n",
      "      M: 19 (51.4%)\n",
      "[INFO] Fold 4/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 188 (47.7%)\n",
      "      M: 206 (52.3%)\n",
      "    Age_Group:\n",
      "      0: 99 (25.1%)\n",
      "      1: 96 (24.4%)\n",
      "      2: 98 (24.9%)\n",
      "      3: 101 (25.6%)\n",
      "[INFO]   Fold 4/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 4/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 62 (19.7%)\n",
      "      CN: 56 (17.8%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 150 (47.6%)\n",
      "      M: 165 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 80 (25.4%)\n",
      "      1: 77 (24.4%)\n",
      "      2: 78 (24.8%)\n",
      "      3: 80 (25.4%)\n",
      "[INFO] Fold 4/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 14 (17.7%)\n",
      "      CN: 15 (19.0%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 38 (48.1%)\n",
      "      M: 41 (51.9%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 19 (24.1%)\n",
      "      2: 20 (25.3%)\n",
      "      3: 21 (26.6%)\n",
      "[INFO]   Fold 4/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 2 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.775)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.403, std=1.693)\n",
      "[INFO]   Fold 4/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 4/5 Usando scheduler: ReduceLROnPlateau\n",
      "[INFO]   Fold 4/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 4/5 VAE E5/300, TrL: 44115.08 (R: 44006.91, KLD: 180.28), Beta: 0.600, LR: 1.00e-04, ValL: 39556.86 (R: 39499.94, KLD: 94.86)\n",
      "[INFO]   Fold 4/5 VAE E10/300, TrL: 40063.64 (R: 39611.45, KLD: 334.96), Beta: 1.350, LR: 1.00e-04, ValL: 34611.21 (R: 33662.01, KLD: 703.10)\n",
      "[INFO]   Fold 4/5 VAE E15/300, TrL: 34990.77 (R: 34313.82, KLD: 322.36), Beta: 2.100, LR: 1.00e-04, ValL: 30482.96 (R: 29882.95, KLD: 285.72)\n",
      "[INFO]   Fold 4/5 VAE E20/300, TrL: 32524.06 (R: 31954.54, KLD: 199.83), Beta: 2.850, LR: 1.00e-04, ValL: 28017.23 (R: 27447.61, KLD: 199.87)\n",
      "[INFO]   Fold 4/5 VAE E25/300, TrL: 30790.11 (R: 30223.02, KLD: 157.53), Beta: 3.600, LR: 1.00e-04, ValL: 26211.86 (R: 25567.59, KLD: 178.96)\n",
      "[INFO]   Fold 4/5 VAE E30/300, TrL: 29405.13 (R: 28791.15, KLD: 141.15), Beta: 4.350, LR: 1.00e-04, ValL: 24723.98 (R: 24151.29, KLD: 131.65)\n",
      "[INFO]   Fold 4/5 VAE E35/300, TrL: 28341.70 (R: 27736.06, KLD: 134.59), Beta: 4.500, LR: 1.00e-04, ValL: 23660.44 (R: 23125.83, KLD: 118.80)\n",
      "[INFO]   Fold 4/5 VAE E40/300, TrL: 27455.08 (R: 26880.11, KLD: 127.77), Beta: 4.500, LR: 1.00e-04, ValL: 22815.84 (R: 22326.63, KLD: 108.71)\n",
      "[INFO]   Fold 4/5 VAE E45/300, TrL: 26834.93 (R: 26280.52, KLD: 123.20), Beta: 4.500, LR: 1.00e-04, ValL: 22192.10 (R: 21682.60, KLD: 113.22)\n",
      "[INFO]   Fold 4/5 VAE E50/300, TrL: 26233.91 (R: 25695.02, KLD: 119.75), Beta: 4.500, LR: 1.00e-04, ValL: 21698.52 (R: 21192.94, KLD: 112.35)\n",
      "[INFO]   Fold 4/5 VAE E55/300, TrL: 25752.60 (R: 25224.65, KLD: 117.32), Beta: 4.500, LR: 1.00e-04, ValL: 21204.89 (R: 20689.22, KLD: 114.59)\n",
      "[INFO]   Fold 4/5 VAE E60/300, TrL: 25294.50 (R: 24756.86, KLD: 119.47), Beta: 4.500, LR: 1.00e-04, ValL: 20783.42 (R: 20329.90, KLD: 100.78)\n",
      "[INFO]   Fold 4/5 VAE E65/300, TrL: 25051.73 (R: 24507.68, KLD: 120.90), Beta: 4.500, LR: 1.00e-04, ValL: 20504.63 (R: 20001.52, KLD: 111.80)\n",
      "[INFO]   Fold 4/5 VAE E70/300, TrL: 24688.40 (R: 24158.75, KLD: 117.70), Beta: 4.500, LR: 1.00e-04, ValL: 20306.15 (R: 19840.29, KLD: 103.53)\n",
      "[INFO]   Fold 4/5 VAE E75/300, TrL: 24590.21 (R: 23930.32, KLD: 146.64), Beta: 4.500, LR: 1.00e-04, ValL: 20315.35 (R: 19665.73, KLD: 144.36)\n",
      "[INFO]   Fold 4/5 VAE E80/300, TrL: 23550.03 (R: 23432.56, KLD: 195.78), Beta: 0.600, LR: 1.00e-04, ValL: 19246.35 (R: 19134.98, KLD: 185.62)\n",
      "[INFO]   Fold 4/5 VAE E85/300, TrL: 23383.17 (R: 23091.90, KLD: 215.75), Beta: 1.350, LR: 1.00e-04, ValL: 19205.27 (R: 18922.36, KLD: 209.57)\n",
      "[INFO]   Fold 4/5 VAE E90/300, TrL: 23393.06 (R: 22997.17, KLD: 188.52), Beta: 2.100, LR: 1.00e-04, ValL: 19142.87 (R: 18782.07, KLD: 171.81)\n",
      "[INFO]   Fold 4/5 VAE E95/300, TrL: 23193.63 (R: 22720.26, KLD: 166.09), Beta: 2.850, LR: 1.00e-04, ValL: 19136.64 (R: 18691.90, KLD: 156.05)\n",
      "[INFO]   Fold 4/5 VAE E100/300, TrL: 23135.14 (R: 22588.63, KLD: 151.81), Beta: 3.600, LR: 1.00e-04, ValL: 19016.15 (R: 18537.67, KLD: 132.91)\n",
      "[INFO]   Fold 4/5 VAE E105/300, TrL: 23056.62 (R: 22454.09, KLD: 138.51), Beta: 4.350, LR: 1.00e-04, ValL: 18974.48 (R: 18457.38, KLD: 118.87)\n",
      "[INFO]   Fold 4/5 VAE E110/300, TrL: 23012.60 (R: 22411.73, KLD: 133.53), Beta: 4.500, LR: 1.00e-04, ValL: 18965.32 (R: 18445.40, KLD: 115.54)\n",
      "[INFO]   Fold 4/5 VAE E115/300, TrL: 22715.97 (R: 22106.82, KLD: 135.37), Beta: 4.500, LR: 1.00e-04, ValL: 18728.81 (R: 18231.38, KLD: 110.54)\n",
      "[INFO]   Fold 4/5 VAE E120/300, TrL: 22671.82 (R: 22048.29, KLD: 138.56), Beta: 4.500, LR: 1.00e-04, ValL: 18597.25 (R: 18082.97, KLD: 114.28)\n",
      "[INFO]   Fold 4/5 VAE E125/300, TrL: 22638.59 (R: 22047.89, KLD: 131.27), Beta: 4.500, LR: 1.00e-04, ValL: 18602.80 (R: 18075.83, KLD: 117.10)\n",
      "[INFO]   Fold 4/5 VAE E130/300, TrL: 22530.63 (R: 21938.56, KLD: 131.57), Beta: 4.500, LR: 1.00e-04, ValL: 18468.70 (R: 17983.60, KLD: 107.80)\n",
      "[INFO]   Fold 4/5 VAE E135/300, TrL: 22245.43 (R: 21651.37, KLD: 132.02), Beta: 4.500, LR: 1.00e-04, ValL: 18401.18 (R: 17914.47, KLD: 108.16)\n",
      "[INFO]   Fold 4/5 VAE E140/300, TrL: 22195.12 (R: 21600.75, KLD: 132.08), Beta: 4.500, LR: 1.00e-04, ValL: 18249.16 (R: 17748.68, KLD: 111.22)\n",
      "[INFO]   Fold 4/5 VAE E145/300, TrL: 22057.84 (R: 21462.48, KLD: 132.30), Beta: 4.500, LR: 1.00e-04, ValL: 18218.14 (R: 17733.95, KLD: 107.60)\n",
      "[INFO]   Fold 4/5 VAE E150/300, TrL: 21968.41 (R: 21352.01, KLD: 136.98), Beta: 4.500, LR: 1.00e-04, ValL: 18201.22 (R: 17696.00, KLD: 112.27)\n",
      "[INFO]   Fold 4/5 VAE E155/300, TrL: 21331.28 (R: 21216.64, KLD: 191.07), Beta: 0.600, LR: 1.00e-04, ValL: 17599.68 (R: 17494.60, KLD: 175.13)\n",
      "[INFO]   Fold 4/5 VAE E160/300, TrL: 21314.63 (R: 21021.36, KLD: 217.23), Beta: 1.350, LR: 1.00e-04, ValL: 17660.83 (R: 17394.49, KLD: 197.29)\n",
      "[INFO]   Fold 4/5 VAE E165/300, TrL: 21284.34 (R: 20854.49, KLD: 204.69), Beta: 2.100, LR: 1.00e-04, ValL: 17691.65 (R: 17321.38, KLD: 176.32)\n",
      "[INFO]   Fold 4/5 Learning rate reducido a 1.00e-05. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 4/5 VAE E170/300, TrL: 21338.69 (R: 20824.49, KLD: 180.42), Beta: 2.850, LR: 1.00e-04, ValL: 17746.15 (R: 17292.12, KLD: 159.31)\n",
      "[INFO]   Fold 4/5 VAE E175/300, TrL: 21418.62 (R: 20793.11, KLD: 173.75), Beta: 3.600, LR: 1.00e-05, ValL: 17753.83 (R: 17221.95, KLD: 147.75)\n",
      "[INFO]   Fold 4/5 VAE E180/300, TrL: 21552.31 (R: 20816.90, KLD: 169.06), Beta: 4.350, LR: 1.00e-05, ValL: 17859.37 (R: 17241.08, KLD: 142.14)\n",
      "[INFO]   Fold 4/5 VAE E185/300, TrL: 21577.62 (R: 20837.86, KLD: 164.39), Beta: 4.500, LR: 1.00e-05, ValL: 17862.91 (R: 17246.48, KLD: 136.99)\n",
      "[INFO]   Fold 4/5 Learning rate reducido a 1.00e-06. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 4/5 VAE E190/300, TrL: 21468.82 (R: 20751.28, KLD: 159.45), Beta: 4.500, LR: 1.00e-06, ValL: 17865.02 (R: 17263.09, KLD: 133.76)\n",
      "[INFO]   Fold 4/5 VAE E195/300, TrL: 21516.29 (R: 20803.84, KLD: 158.32), Beta: 4.500, LR: 1.00e-06, ValL: 17867.18 (R: 17271.09, KLD: 132.47)\n",
      "[INFO]   Fold 4/5 VAE E200/300, TrL: 21589.49 (R: 20869.02, KLD: 160.10), Beta: 4.500, LR: 1.00e-06, ValL: 17861.87 (R: 17267.98, KLD: 131.98)\n",
      "[INFO]   Fold 4/5 Learning rate reducido a 1.00e-07. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 4/5 VAE E205/300, TrL: 21458.01 (R: 20744.18, KLD: 158.63), Beta: 4.500, LR: 1.00e-07, ValL: 17849.28 (R: 17256.97, KLD: 131.62)\n",
      "[INFO]   Fold 4/5 VAE E210/300, TrL: 21451.28 (R: 20738.96, KLD: 158.29), Beta: 4.500, LR: 1.00e-07, ValL: 17891.40 (R: 17296.98, KLD: 132.09)\n",
      "[INFO]   Fold 4/5 VAE E215/300, TrL: 21553.18 (R: 20838.96, KLD: 158.71), Beta: 4.500, LR: 1.00e-07, ValL: 17871.28 (R: 17279.65, KLD: 131.47)\n",
      "[INFO]   Fold 4/5 Learning rate reducido a 1.00e-08. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 4/5 VAE E220/300, TrL: 21463.99 (R: 20753.06, KLD: 157.98), Beta: 4.500, LR: 1.00e-08, ValL: 17831.33 (R: 17243.10, KLD: 130.72)\n",
      "[INFO]   Fold 4/5 VAE E225/300, TrL: 21538.68 (R: 20829.72, KLD: 157.55), Beta: 4.500, LR: 1.00e-08, ValL: 17886.10 (R: 17294.53, KLD: 131.46)\n",
      "[INFO]   Fold 4/5 VAE E230/300, TrL: 20892.05 (R: 20796.55, KLD: 159.17), Beta: 0.600, LR: 1.00e-08, ValL: 17357.98 (R: 17279.76, KLD: 130.36)\n",
      "[INFO]   Fold 4/5 VAE E235/300, TrL: 21041.38 (R: 20826.15, KLD: 159.43), Beta: 1.350, LR: 1.00e-08, ValL: 17416.89 (R: 17240.07, KLD: 130.98)\n",
      "[INFO]   Fold 4/5 VAE E240/300, TrL: 21128.13 (R: 20794.53, KLD: 158.86), Beta: 2.100, LR: 1.00e-08, ValL: 17566.32 (R: 17289.40, KLD: 131.87)\n",
      "[INFO]   Fold 4/5 VAE E245/300, TrL: 21233.54 (R: 20780.30, KLD: 159.03), Beta: 2.850, LR: 1.00e-08, ValL: 17594.17 (R: 17220.01, KLD: 131.28)\n",
      "[INFO]   Fold 4/5 VAE E250/300, TrL: 21373.81 (R: 20795.80, KLD: 160.56), Beta: 3.600, LR: 1.00e-08, ValL: 17750.36 (R: 17273.43, KLD: 132.48)\n",
      "[INFO]   Fold 4/5 VAE E255/300, TrL: 21497.97 (R: 20809.34, KLD: 158.31), Beta: 4.350, LR: 1.00e-08, ValL: 17846.16 (R: 17271.29, KLD: 132.15)\n",
      "[INFO]   Fold 4/5 Early stopping VAE en epoch 257. Mejor val_loss: 17272.8167\n",
      "[INFO]   Fold 4/5 VAE final model loaded (best val_loss: 17272.8167).\n",
      "[INFO]   Fold 4/5 Modelo VAE guardado en: resultados_FIN_v2/fold_4/vae_model_fold_4.pt\n",
      "[INFO] Fold 4/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 74 (50.3%)\n",
      "      M: 73 (49.7%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 514)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 1174, 'model__learning_rate': 0.00814857792570601, 'model__max_depth': 9, 'model__subsample': 0.8768417217717125, 'model__colsample_bytree': 0.6342688447706875, 'model__min_child_weight': 1.1086419838448847}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 4 (xgb): AUC=0.7719, Bal.Acc=0.7544\n",
      "[INFO]       Pipeline completo de xgb del fold 4 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__C': 62.78246032815808, 'model__gamma': 3.320711130597673e-05, 'model__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 4 (svm): AUC=0.7778, Bal.Acc=0.7544\n",
      "[INFO]       Pipeline completo de svm del fold 4 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.0025233848389211774}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 4 (logreg): AUC=0.7719, Bal.Acc=0.7558\n",
      "[INFO]       Pipeline completo de logreg del fold 4 guardado.\n",
      "[INFO]   Fold 4/5 completado en 574.86 segundos.\n",
      "[INFO] --- Iniciando Fold 5/5 ---\n",
      "[INFO] Fold 5/5 Test Set (Clasificador) (N=36):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (52.8%)\n",
      "      CN: 17 (47.2%)\n",
      "    Sex:\n",
      "      F: 18 (50.0%)\n",
      "      M: 18 (50.0%)\n",
      "[INFO] Fold 5/5 Pool Entrenamiento VAE (N=395):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.2%)\n",
      "      CN: 72 (18.2%)\n",
      "      MCI: 247 (62.5%)\n",
      "    Sex:\n",
      "      F: 188 (47.6%)\n",
      "      M: 207 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 101 (25.6%)\n",
      "      1: 105 (26.6%)\n",
      "      2: 98 (24.8%)\n",
      "      3: 91 (23.0%)\n",
      "[INFO]   Fold 5/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 5/5 Actual Train Set (VAE) (N=316):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 61 (19.3%)\n",
      "      CN: 58 (18.4%)\n",
      "      MCI: 197 (62.3%)\n",
      "    Sex:\n",
      "      F: 151 (47.8%)\n",
      "      M: 165 (52.2%)\n",
      "    Age_Group:\n",
      "      0: 82 (25.9%)\n",
      "      1: 84 (26.6%)\n",
      "      2: 77 (24.4%)\n",
      "      3: 73 (23.1%)\n",
      "[INFO] Fold 5/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 15 (19.0%)\n",
      "      CN: 14 (17.7%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 37 (46.8%)\n",
      "      M: 42 (53.2%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 21 (26.6%)\n",
      "      2: 21 (26.6%)\n",
      "      3: 18 (22.8%)\n",
      "[INFO]   Fold 5/5 Sujetos VAE actual train: 316, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 2 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 316 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.777)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.407, std=1.702)\n",
      "[INFO]   Fold 5/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 5/5 Usando scheduler: ReduceLROnPlateau\n",
      "[INFO]   Fold 5/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 5/5 VAE E5/300, TrL: 44410.06 (R: 44302.00, KLD: 180.09), Beta: 0.600, LR: 1.00e-04, ValL: 43428.27 (R: 43370.47, KLD: 96.32)\n",
      "[INFO]   Fold 5/5 VAE E10/300, TrL: 40234.32 (R: 39747.12, KLD: 360.89), Beta: 1.350, LR: 1.00e-04, ValL: 38471.03 (R: 37539.08, KLD: 690.33)\n",
      "[INFO]   Fold 5/5 VAE E15/300, TrL: 35321.46 (R: 34680.53, KLD: 305.21), Beta: 2.100, LR: 1.00e-04, ValL: 34479.21 (R: 33942.41, KLD: 255.62)\n",
      "[INFO]   Fold 5/5 VAE E20/300, TrL: 33086.05 (R: 32524.90, KLD: 196.90), Beta: 2.850, LR: 1.00e-04, ValL: 32314.58 (R: 31779.58, KLD: 187.72)\n",
      "[INFO]   Fold 5/5 VAE E25/300, TrL: 31282.55 (R: 30711.43, KLD: 158.64), Beta: 3.600, LR: 1.00e-04, ValL: 30224.92 (R: 29690.43, KLD: 148.47)\n",
      "[INFO]   Fold 5/5 VAE E30/300, TrL: 29754.84 (R: 29179.46, KLD: 132.27), Beta: 4.350, LR: 1.00e-04, ValL: 28758.31 (R: 28203.20, KLD: 127.61)\n",
      "[INFO]   Fold 5/5 VAE E35/300, TrL: 28616.09 (R: 28051.21, KLD: 125.53), Beta: 4.500, LR: 1.00e-04, ValL: 27748.16 (R: 27142.73, KLD: 134.54)\n",
      "[INFO]   Fold 5/5 VAE E40/300, TrL: 27684.62 (R: 27162.04, KLD: 116.13), Beta: 4.500, LR: 1.00e-04, ValL: 26666.25 (R: 26247.57, KLD: 93.04)\n",
      "[INFO]   Fold 5/5 VAE E45/300, TrL: 27002.98 (R: 26503.51, KLD: 110.99), Beta: 4.500, LR: 1.00e-04, ValL: 26015.79 (R: 25620.23, KLD: 87.90)\n",
      "[INFO]   Fold 5/5 VAE E50/300, TrL: 26391.59 (R: 25874.02, KLD: 115.02), Beta: 4.500, LR: 1.00e-04, ValL: 25465.93 (R: 25045.83, KLD: 93.36)\n",
      "[INFO]   Fold 5/5 VAE E55/300, TrL: 25896.14 (R: 25393.61, KLD: 111.67), Beta: 4.500, LR: 1.00e-04, ValL: 24956.02 (R: 24567.66, KLD: 86.30)\n",
      "[INFO]   Fold 5/5 VAE E60/300, TrL: 25454.85 (R: 24940.02, KLD: 114.41), Beta: 4.500, LR: 1.00e-04, ValL: 24620.89 (R: 24191.60, KLD: 95.40)\n",
      "[INFO]   Fold 5/5 VAE E65/300, TrL: 25194.52 (R: 24648.35, KLD: 121.37), Beta: 4.500, LR: 1.00e-04, ValL: 24212.86 (R: 23766.80, KLD: 99.13)\n",
      "[INFO]   Fold 5/5 VAE E70/300, TrL: 24848.47 (R: 24292.70, KLD: 123.51), Beta: 4.500, LR: 1.00e-04, ValL: 23833.23 (R: 23408.46, KLD: 94.39)\n",
      "[INFO]   Fold 5/5 VAE E75/300, TrL: 24571.54 (R: 23928.21, KLD: 142.96), Beta: 4.500, LR: 1.00e-04, ValL: 23683.23 (R: 23181.35, KLD: 111.53)\n",
      "[INFO]   Fold 5/5 VAE E80/300, TrL: 23592.94 (R: 23466.13, KLD: 211.34), Beta: 0.600, LR: 1.00e-04, ValL: 22825.85 (R: 22718.78, KLD: 178.46)\n",
      "[INFO]   Fold 5/5 VAE E85/300, TrL: 23408.73 (R: 23112.07, KLD: 219.75), Beta: 1.350, LR: 1.00e-04, ValL: 22656.43 (R: 22399.67, KLD: 190.20)\n",
      "[INFO]   Fold 5/5 VAE E90/300, TrL: 23313.43 (R: 22908.98, KLD: 192.59), Beta: 2.100, LR: 1.00e-04, ValL: 22562.73 (R: 22200.92, KLD: 172.29)\n",
      "[INFO]   Fold 5/5 VAE E95/300, TrL: 23214.86 (R: 22718.77, KLD: 174.07), Beta: 2.850, LR: 1.00e-04, ValL: 22396.84 (R: 21995.99, KLD: 140.65)\n",
      "[INFO]   Fold 5/5 VAE E100/300, TrL: 23120.12 (R: 22568.45, KLD: 153.24), Beta: 3.600, LR: 1.00e-04, ValL: 22346.90 (R: 21900.63, KLD: 123.96)\n",
      "[INFO]   Fold 5/5 VAE E105/300, TrL: 23069.21 (R: 22450.19, KLD: 142.30), Beta: 4.350, LR: 1.00e-04, ValL: 22293.00 (R: 21790.07, KLD: 115.61)\n",
      "[INFO]   Fold 5/5 VAE E110/300, TrL: 22939.92 (R: 22331.39, KLD: 135.23), Beta: 4.500, LR: 1.00e-04, ValL: 22177.25 (R: 21691.55, KLD: 107.93)\n",
      "[INFO]   Fold 5/5 VAE E115/300, TrL: 22780.49 (R: 22157.60, KLD: 138.42), Beta: 4.500, LR: 1.00e-04, ValL: 22067.76 (R: 21581.25, KLD: 108.11)\n",
      "[INFO]   Fold 5/5 VAE E120/300, TrL: 22680.47 (R: 22062.28, KLD: 137.38), Beta: 4.500, LR: 1.00e-04, ValL: 21906.22 (R: 21443.01, KLD: 102.93)\n",
      "[INFO]   Fold 5/5 VAE E125/300, TrL: 22493.25 (R: 21904.27, KLD: 130.88), Beta: 4.500, LR: 1.00e-04, ValL: 21772.76 (R: 21321.19, KLD: 100.35)\n",
      "[INFO]   Fold 5/5 VAE E130/300, TrL: 22293.10 (R: 21694.87, KLD: 132.94), Beta: 4.500, LR: 1.00e-04, ValL: 21765.86 (R: 21298.63, KLD: 103.83)\n",
      "[INFO]   Fold 5/5 VAE E135/300, TrL: 22179.42 (R: 21596.77, KLD: 129.48), Beta: 4.500, LR: 1.00e-04, ValL: 21658.85 (R: 21204.43, KLD: 100.98)\n",
      "[INFO]   Fold 5/5 VAE E140/300, TrL: 22100.97 (R: 21509.05, KLD: 131.54), Beta: 4.500, LR: 1.00e-04, ValL: 21559.41 (R: 21114.06, KLD: 98.97)\n",
      "[INFO]   Fold 5/5 VAE E145/300, TrL: 22003.34 (R: 21406.94, KLD: 132.53), Beta: 4.500, LR: 1.00e-04, ValL: 21457.73 (R: 20994.89, KLD: 102.85)\n",
      "[INFO]   Fold 5/5 VAE E150/300, TrL: 21905.67 (R: 21322.99, KLD: 129.48), Beta: 4.500, LR: 1.00e-04, ValL: 21314.54 (R: 20861.34, KLD: 100.71)\n",
      "[INFO]   Fold 5/5 VAE E155/300, TrL: 21207.71 (R: 21089.06, KLD: 197.76), Beta: 0.600, LR: 1.00e-04, ValL: 20829.01 (R: 20729.67, KLD: 165.58)\n",
      "[INFO]   Fold 5/5 VAE E160/300, TrL: 21194.95 (R: 20905.96, KLD: 214.06), Beta: 1.350, LR: 1.00e-04, ValL: 20795.58 (R: 20555.58, KLD: 177.78)\n",
      "[INFO]   Fold 5/5 VAE E165/300, TrL: 21245.33 (R: 20821.53, KLD: 201.81), Beta: 2.100, LR: 1.00e-04, ValL: 20884.10 (R: 20517.39, KLD: 174.62)\n",
      "[INFO]   Fold 5/5 VAE E170/300, TrL: 21312.67 (R: 20795.64, KLD: 181.41), Beta: 2.850, LR: 1.00e-04, ValL: 20927.02 (R: 20506.81, KLD: 147.44)\n",
      "[INFO]   Fold 5/5 VAE E175/300, TrL: 21417.74 (R: 20812.80, KLD: 168.04), Beta: 3.600, LR: 1.00e-04, ValL: 21116.10 (R: 20610.21, KLD: 140.53)\n",
      "[INFO]   Fold 5/5 Learning rate reducido a 1.00e-05. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 5/5 VAE E180/300, TrL: 21326.77 (R: 20625.94, KLD: 161.11), Beta: 4.350, LR: 1.00e-05, ValL: 21056.57 (R: 20503.22, KLD: 127.21)\n",
      "[INFO]   Fold 5/5 VAE E185/300, TrL: 21481.16 (R: 20780.46, KLD: 155.71), Beta: 4.500, LR: 1.00e-05, ValL: 21057.80 (R: 20504.41, KLD: 122.98)\n",
      "[INFO]   Fold 5/5 VAE E190/300, TrL: 21313.16 (R: 20640.13, KLD: 149.56), Beta: 4.500, LR: 1.00e-05, ValL: 21009.18 (R: 20475.69, KLD: 118.55)\n",
      "[INFO]   Fold 5/5 Learning rate reducido a 1.00e-06. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 5/5 VAE E195/300, TrL: 21314.70 (R: 20644.69, KLD: 148.89), Beta: 4.500, LR: 1.00e-06, ValL: 20971.89 (R: 20438.95, KLD: 118.43)\n",
      "[INFO]   Fold 5/5 VAE E200/300, TrL: 21348.06 (R: 20679.36, KLD: 148.60), Beta: 4.500, LR: 1.00e-06, ValL: 21017.37 (R: 20488.16, KLD: 117.60)\n",
      "[INFO]   Fold 5/5 VAE E205/300, TrL: 21333.62 (R: 20667.37, KLD: 148.06), Beta: 4.500, LR: 1.00e-06, ValL: 21006.16 (R: 20477.29, KLD: 117.53)\n",
      "[INFO]   Fold 5/5 Learning rate reducido a 1.00e-07. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 5/5 VAE E210/300, TrL: 21259.19 (R: 20595.37, KLD: 147.52), Beta: 4.500, LR: 1.00e-07, ValL: 21044.79 (R: 20520.99, KLD: 116.40)\n",
      "[INFO]   Fold 5/5 VAE E215/300, TrL: 21308.35 (R: 20635.45, KLD: 149.53), Beta: 4.500, LR: 1.00e-07, ValL: 21027.72 (R: 20499.79, KLD: 117.32)\n",
      "[INFO]   Fold 5/5 VAE E220/300, TrL: 21397.43 (R: 20727.90, KLD: 148.78), Beta: 4.500, LR: 1.00e-07, ValL: 20974.14 (R: 20445.87, KLD: 117.39)\n",
      "[INFO]   Fold 5/5 Learning rate reducido a 1.00e-08. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 5/5 VAE E225/300, TrL: 21315.92 (R: 20652.33, KLD: 147.47), Beta: 4.500, LR: 1.00e-08, ValL: 20954.81 (R: 20431.71, KLD: 116.24)\n",
      "[INFO]   Fold 5/5 VAE E230/300, TrL: 20686.46 (R: 20598.58, KLD: 146.46), Beta: 0.600, LR: 1.00e-08, ValL: 20596.18 (R: 20525.79, KLD: 117.32)\n",
      "[INFO]   Fold 5/5 VAE E235/300, TrL: 20832.65 (R: 20633.87, KLD: 147.24), Beta: 1.350, LR: 1.00e-08, ValL: 20675.97 (R: 20518.37, KLD: 116.74)\n",
      "[INFO]   Fold 5/5 VAE E240/300, TrL: 20973.36 (R: 20659.48, KLD: 149.47), Beta: 2.100, LR: 1.00e-08, ValL: 20752.40 (R: 20506.51, KLD: 117.09)\n",
      "[INFO]   Fold 5/5 VAE E245/300, TrL: 21068.17 (R: 20641.02, KLD: 149.88), Beta: 2.850, LR: 1.00e-08, ValL: 20823.25 (R: 20490.12, KLD: 116.89)\n",
      "[INFO]   Fold 5/5 VAE E250/300, TrL: 21162.99 (R: 20630.41, KLD: 147.94), Beta: 3.600, LR: 1.00e-08, ValL: 20931.45 (R: 20509.90, KLD: 117.10)\n",
      "[INFO]   Fold 5/5 VAE E255/300, TrL: 21294.94 (R: 20645.09, KLD: 149.39), Beta: 4.350, LR: 1.00e-08, ValL: 20954.35 (R: 20446.77, KLD: 116.68)\n",
      "[INFO]   Fold 5/5 Early stopping VAE en epoch 256. Mejor val_loss: 20453.1589\n",
      "[INFO]   Fold 5/5 VAE final model loaded (best val_loss: 20453.1589).\n",
      "[INFO]   Fold 5/5 Modelo VAE guardado en: resultados_FIN_v2/fold_5/vae_model_fold_5.pt\n",
      "[INFO] Fold 5/5 Pool Train/Dev (Clasificador) (N=148):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.4%)\n",
      "      CN: 72 (48.6%)\n",
      "    Sex:\n",
      "      F: 74 (50.0%)\n",
      "      M: 74 (50.0%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (148, 514)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 994, 'model__learning_rate': 0.03799397859929026, 'model__max_depth': 9, 'model__subsample': 0.5240489222841571, 'model__colsample_bytree': 0.9155654472088389, 'model__min_child_weight': 4.780177078157821}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 5 (xgb): AUC=0.7399, Bal.Acc=0.6718\n",
      "[INFO]       Pipeline completo de xgb del fold 5 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__C': 6839.469747081367, 'model__gamma': 1.0231289437292908e-07, 'model__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 5 (svm): AUC=0.7337, Bal.Acc=0.7214\n",
      "[INFO]       Pipeline completo de svm del fold 5 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.004861526643614568}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 5 (logreg): AUC=0.7276, Bal.Acc=0.7214\n",
      "[INFO]       Pipeline completo de logreg del fold 5 guardado.\n",
      "[INFO]   Fold 5/5 completado en 497.40 segundos.\n",
      "[INFO] \n",
      "--- Resumen de Rendimiento para Clasificador: xgb (Promedio sobre Folds Externos) ---\n",
      "[INFO] Auc                 : 0.7802 +/- 0.0520\n",
      "[INFO] Pr_auc              : 0.7754 +/- 0.0676\n",
      "[INFO] Accuracy            : 0.7225 +/- 0.0470\n",
      "[INFO] Balanced_accuracy   : 0.7227 +/- 0.0461\n",
      "[INFO] Sensitivity         : 0.7368 +/- 0.1053\n",
      "[INFO] Specificity         : 0.7085 +/- 0.1050\n",
      "[INFO] F1_score            : 0.7308 +/- 0.0533\n",
      "[INFO] \n",
      "--- Resumen de Rendimiento para Clasificador: svm (Promedio sobre Folds Externos) ---\n",
      "[INFO] Auc                 : 0.7567 +/- 0.0506\n",
      "[INFO] Pr_auc              : 0.7490 +/- 0.0675\n",
      "[INFO] Accuracy            : 0.7174 +/- 0.0303\n",
      "[INFO] Balanced_accuracy   : 0.7159 +/- 0.0301\n",
      "[INFO] Sensitivity         : 0.7684 +/- 0.0471\n",
      "[INFO] Specificity         : 0.6634 +/- 0.0338\n",
      "[INFO] F1_score            : 0.7371 +/- 0.0308\n",
      "[INFO] \n",
      "--- Resumen de Rendimiento para Clasificador: logreg (Promedio sobre Folds Externos) ---\n",
      "[INFO] Auc                 : 0.7707 +/- 0.0410\n",
      "[INFO] Pr_auc              : 0.7670 +/- 0.0578\n",
      "[INFO] Accuracy            : 0.7336 +/- 0.0233\n",
      "[INFO] Balanced_accuracy   : 0.7323 +/- 0.0230\n",
      "[INFO] Sensitivity         : 0.7789 +/- 0.0440\n",
      "[INFO] Specificity         : 0.6856 +/- 0.0266\n",
      "[INFO] F1_score            : 0.7509 +/- 0.0250\n",
      "[INFO] Resultados detallados de todos los clasificadores guardados en: resultados_FIN_v2/all_folds_metrics_MULTI_xgb_vaeconvtranspose4l_ld512_beta4.5_normzscore_offdiag_ch2sel_intFCquarter_drop0.2_ln0_outer5x1_scoreroc_auc.csv\n",
      "[INFO] Sumario estadístico de métricas (por clasificador) guardado en: resultados_FIN_v2/summary_metrics_MULTI_xgb_vaeconvtranspose4l_ld512_beta4.5_normzscore_offdiag_ch2sel_intFCquarter_drop0.2_ln0_outer5x1_scoreroc_auc.txt\n",
      "[INFO] Pipeline completo en 2726.99 segundos.\n",
      "[INFO] --- Consideraciones Finales ---\n",
      "[INFO] Normalización: 'zscore_offdiag'. Activación VAE: 'tanh'. Asegurar compatibilidad.\n"
     ]
    }
   ],
   "source": [
    "!python serentipia3.py \\\n",
    "    --global_tensor_path /home/diego/Escritorio/limpio/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz \\\n",
    "    --metadata_path /home/diego/Escritorio/limpio/SubjectsData_AAL3_procesado.csv \\\n",
    "    --output_dir ./resultados_FIN_v2 \\\n",
    "    --channels_to_use 1 5 \\\n",
    "    --classifier_types xgb svm logreg \\\n",
    "    --outer_folds 5 \\\n",
    "    --repeated_outer_folds_n_repeats 1 \\\n",
    "    --epochs_vae 300 \\\n",
    "    --early_stopping_patience_vae 30 \\\n",
    "    --batch_size 64 \\\n",
    "    --beta_vae 4.5 \\\n",
    "    --latent_dim 512 \\\n",
    "    --n_jobs_gridsearch 8 \\\n",
    "    --metadata_features Age Sex \\\n",
    "    --use_smote \\\n",
    "    --use_optuna_pruner \\\n",
    "    --classifier_use_class_weight \\\n",
    "    --save_fold_artefacts \\\n",
    "    --gridsearch_scoring roc_auc \\\n",
    "    --save_vae_training_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
