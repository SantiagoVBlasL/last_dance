{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a943e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿GPU visible?: True\n",
      "¿GPU visible?: True\n",
      "torch.cuda.is_available -> True\n",
      "torch.version.cuda      -> 11.8\n",
      "cupy GPU visible        -> True\n",
      "fatal: no es un repositorio git (ni ninguno de los directorios superiores): .git\n",
      "[INFO] Git commit hash: N/A\n",
      "[INFO] --- Configuración de la Ejecución (v1.7.0) ---\n",
      "[INFO] batch_size: 64\n",
      "[INFO] beta_vae: 4.6\n",
      "[INFO] channels_to_use: [1, 2, 5]\n",
      "[INFO] classifier_calibrate: True\n",
      "[INFO] classifier_hp_tune_ratio: 0.25\n",
      "[INFO] classifier_stratify_cols: ['Sex']\n",
      "[INFO] classifier_types: ['xgb', 'svm', 'logreg']\n",
      "[INFO] classifier_use_class_weight: True\n",
      "[INFO] cyclical_beta_n_cycles: 4\n",
      "[INFO] cyclical_beta_ratio_increase: 0.4\n",
      "[INFO] decoder_type: convtranspose\n",
      "[INFO] dropout_rate_vae: 0.2\n",
      "[INFO] early_stopping_patience_vae: 30\n",
      "[INFO] epochs_vae: 300\n",
      "[INFO] git_hash: N/A\n",
      "[INFO] global_tensor_path: /home/diego/Escritorio/limpio/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "[INFO] gridsearch_scoring: roc_auc\n",
      "[INFO] inner_folds: 5\n",
      "[INFO] intermediate_fc_dim_vae: quarter\n",
      "[INFO] latent_dim: 512\n",
      "[INFO] latent_features_type: mu\n",
      "[INFO] log_interval_epochs_vae: 5\n",
      "[INFO] lr_scheduler_T0: 50\n",
      "[INFO] lr_scheduler_eta_min: 1e-07\n",
      "[INFO] lr_scheduler_patience_vae: 15\n",
      "[INFO] lr_scheduler_type: plateau\n",
      "[INFO] lr_vae: 0.0001\n",
      "[INFO] metadata_features: ['Age', 'Sex']\n",
      "[INFO] metadata_path: /home/diego/Escritorio/limpio/SubjectsData_AAL3_procesado.csv\n",
      "[INFO] mlp_classifier_hidden_layers: 64,16\n",
      "[INFO] n_jobs_gridsearch: 8\n",
      "[INFO] norm_mode: zscore_offdiag\n",
      "[INFO] num_conv_layers_encoder: 4\n",
      "[INFO] num_workers: 4\n",
      "[INFO] outer_folds: 5\n",
      "[INFO] output_dir: ./resultados_FIN_v2\n",
      "[INFO] repeated_outer_folds_n_repeats: 1\n",
      "[INFO] save_fold_artefacts: True\n",
      "[INFO] save_vae_training_history: True\n",
      "[INFO] seed: 42\n",
      "[INFO] tune_sampler_params: False\n",
      "[INFO] use_layernorm_vae_fc: False\n",
      "[INFO] use_optuna_pruner: True\n",
      "[INFO] use_smote: True\n",
      "[INFO] vae_final_activation: tanh\n",
      "[INFO] vae_val_split_ratio: 0.2\n",
      "[INFO] weight_decay_vae: 1e-05\n",
      "[INFO] ------------------------------------\n",
      "[INFO] Cargando tensor global desde: /home/diego/Escritorio/limpio/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "[INFO] Tensor global cargado. Forma: (431, 7, 131, 131)\n",
      "[INFO] Cargando metadatos desde: /home/diego/Escritorio/limpio/SubjectsData_AAL3_procesado.csv\n",
      "[INFO] Metadatos cargados. Forma: (434, 32)\n",
      "[INFO] Usando canales seleccionados (índices): [1, 2, 5]\n",
      "[INFO] Nombres de canales seleccionados: ['Pearson_Full_FisherZ_Signed', 'MI_KNN_Symmetric', 'DistanceCorr']\n",
      "[INFO] Estratificando folds del CLASIFICADOR por: ['ResearchGroup_Mapped', 'Sex']\n",
      "[INFO] Sujetos CN/AD para clasificación: 184. CN: 89, AD: 95\n",
      "[INFO] Usando CV externa: StratifiedKFold con 5 iteraciones totales.\n",
      "[INFO] --- Iniciando Fold 1/5 ---\n",
      "[INFO] Fold 1/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 19 (51.4%)\n",
      "      M: 18 (48.6%)\n",
      "[INFO] Fold 1/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 187 (47.5%)\n",
      "      M: 207 (52.5%)\n",
      "    Age_Group:\n",
      "      0: 104 (26.4%)\n",
      "      1: 102 (25.9%)\n",
      "      2: 91 (23.1%)\n",
      "      3: 97 (24.6%)\n",
      "[INFO]   Fold 1/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 1/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 62 (19.7%)\n",
      "      CN: 56 (17.8%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 149 (47.3%)\n",
      "      M: 166 (52.7%)\n",
      "    Age_Group:\n",
      "      0: 84 (26.7%)\n",
      "      1: 81 (25.7%)\n",
      "      2: 73 (23.2%)\n",
      "      3: 77 (24.4%)\n",
      "[INFO] Fold 1/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 14 (17.7%)\n",
      "      CN: 15 (19.0%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 38 (48.1%)\n",
      "      M: 41 (51.9%)\n",
      "    Age_Group:\n",
      "      0: 20 (25.3%)\n",
      "      1: 21 (26.6%)\n",
      "      2: 18 (22.8%)\n",
      "      3: 20 (25.3%)\n",
      "[INFO]   Fold 1/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.046, std=0.777)\n",
      "[INFO] Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.059, std=0.815)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.397, std=1.627)\n",
      "[INFO]   Fold 1/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 1/5 Usando scheduler: ReduceLROnPlateau\n",
      "[INFO]   Fold 1/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 1/5 VAE E5/300, TrL: 63573.77 (R: 63464.64, KLD: 177.92), Beta: 0.613, LR: 1.00e-04, ValL: 62401.93 (R: 62347.06, KLD: 89.46)\n",
      "[INFO]   Fold 1/5 VAE E10/300, TrL: 58785.73 (R: 58309.62, KLD: 345.01), Beta: 1.380, LR: 1.00e-04, ValL: 56459.55 (R: 55648.80, KLD: 587.50)\n",
      "[INFO]   Fold 1/5 VAE E15/300, TrL: 52082.15 (R: 51369.87, KLD: 331.80), Beta: 2.147, LR: 1.00e-04, ValL: 51043.88 (R: 50443.11, KLD: 279.86)\n",
      "[INFO]   Fold 1/5 VAE E20/300, TrL: 48952.08 (R: 48301.33, KLD: 223.37), Beta: 2.913, LR: 1.00e-04, ValL: 47502.38 (R: 46899.80, KLD: 206.83)\n",
      "[INFO]   Fold 1/5 VAE E25/300, TrL: 46110.26 (R: 45417.18, KLD: 188.34), Beta: 3.680, LR: 1.00e-04, ValL: 44302.39 (R: 43666.12, KLD: 172.90)\n",
      "[INFO]   Fold 1/5 VAE E30/300, TrL: 43869.46 (R: 43152.97, KLD: 161.13), Beta: 4.447, LR: 1.00e-04, ValL: 42125.70 (R: 41375.70, KLD: 168.67)\n",
      "[INFO]   Fold 1/5 VAE E35/300, TrL: 42020.39 (R: 41339.90, KLD: 147.93), Beta: 4.600, LR: 1.00e-04, ValL: 40194.89 (R: 39608.07, KLD: 127.57)\n",
      "[INFO]   Fold 1/5 VAE E40/300, TrL: 40885.19 (R: 40245.57, KLD: 139.05), Beta: 4.600, LR: 1.00e-04, ValL: 39160.67 (R: 38641.95, KLD: 112.76)\n",
      "[INFO]   Fold 1/5 VAE E45/300, TrL: 39818.52 (R: 39182.26, KLD: 138.32), Beta: 4.600, LR: 1.00e-04, ValL: 38215.60 (R: 37724.42, KLD: 106.78)\n",
      "[INFO]   Fold 1/5 VAE E50/300, TrL: 38995.41 (R: 38316.55, KLD: 147.58), Beta: 4.600, LR: 1.00e-04, ValL: 37595.48 (R: 37082.58, KLD: 111.50)\n",
      "[INFO]   Fold 1/5 VAE E55/300, TrL: 38370.15 (R: 37752.92, KLD: 134.18), Beta: 4.600, LR: 1.00e-04, ValL: 37102.67 (R: 36584.14, KLD: 112.72)\n",
      "[INFO]   Fold 1/5 VAE E60/300, TrL: 37736.61 (R: 37106.48, KLD: 136.98), Beta: 4.600, LR: 1.00e-04, ValL: 36484.20 (R: 36008.28, KLD: 103.46)\n",
      "[INFO]   Fold 1/5 VAE E65/300, TrL: 37368.18 (R: 36710.09, KLD: 143.06), Beta: 4.600, LR: 1.00e-04, ValL: 35934.91 (R: 35465.80, KLD: 101.98)\n",
      "[INFO]   Fold 1/5 VAE E70/300, TrL: 36754.88 (R: 36125.09, KLD: 136.91), Beta: 4.600, LR: 1.00e-04, ValL: 35540.86 (R: 35056.94, KLD: 105.20)\n",
      "[INFO]   Fold 1/5 VAE E75/300, TrL: 36457.91 (R: 35774.21, KLD: 148.63), Beta: 4.600, LR: 1.00e-04, ValL: 35247.57 (R: 34688.98, KLD: 121.43)\n",
      "[INFO]   Fold 1/5 VAE E80/300, TrL: 35158.97 (R: 35017.27, KLD: 231.03), Beta: 0.613, LR: 1.00e-04, ValL: 34265.16 (R: 34150.56, KLD: 186.84)\n",
      "[INFO]   Fold 1/5 VAE E85/300, TrL: 35049.19 (R: 34713.61, KLD: 243.17), Beta: 1.380, LR: 1.00e-04, ValL: 34057.58 (R: 33779.29, KLD: 201.66)\n",
      "[INFO]   Fold 1/5 VAE E90/300, TrL: 34795.92 (R: 34312.72, KLD: 225.09), Beta: 2.147, LR: 1.00e-04, ValL: 33915.20 (R: 33518.40, KLD: 184.84)\n",
      "[INFO]   Fold 1/5 VAE E95/300, TrL: 34796.79 (R: 34181.07, KLD: 211.34), Beta: 2.913, LR: 1.00e-04, ValL: 33887.84 (R: 33364.18, KLD: 179.74)\n",
      "[INFO]   Fold 1/5 VAE E100/300, TrL: 34491.69 (R: 33817.07, KLD: 183.32), Beta: 3.680, LR: 1.00e-04, ValL: 33706.60 (R: 33149.11, KLD: 151.49)\n",
      "[INFO]   Fold 1/5 VAE E105/300, TrL: 34330.53 (R: 33609.38, KLD: 162.18), Beta: 4.447, LR: 1.00e-04, ValL: 33512.40 (R: 32921.56, KLD: 132.87)\n",
      "[INFO]   Fold 1/5 VAE E110/300, TrL: 34304.60 (R: 33603.20, KLD: 152.48), Beta: 4.600, LR: 1.00e-04, ValL: 33398.83 (R: 32825.51, KLD: 124.64)\n",
      "[INFO]   Fold 1/5 VAE E115/300, TrL: 34001.38 (R: 33273.60, KLD: 158.21), Beta: 4.600, LR: 1.00e-04, ValL: 33187.16 (R: 32609.18, KLD: 125.65)\n",
      "[INFO]   Fold 1/5 VAE E120/300, TrL: 33797.57 (R: 33093.33, KLD: 153.10), Beta: 4.600, LR: 1.00e-04, ValL: 33075.72 (R: 32488.64, KLD: 127.63)\n",
      "[INFO]   Fold 1/5 VAE E125/300, TrL: 33599.30 (R: 32907.37, KLD: 150.42), Beta: 4.600, LR: 1.00e-04, ValL: 32915.48 (R: 32347.80, KLD: 123.41)\n",
      "[INFO]   Fold 1/5 VAE E130/300, TrL: 33311.70 (R: 32598.58, KLD: 155.03), Beta: 4.600, LR: 1.00e-04, ValL: 32793.23 (R: 32212.44, KLD: 126.26)\n",
      "[INFO]   Fold 1/5 VAE E135/300, TrL: 33188.76 (R: 32478.72, KLD: 154.36), Beta: 4.600, LR: 1.00e-04, ValL: 32635.64 (R: 32066.16, KLD: 123.80)\n",
      "[INFO]   Fold 1/5 VAE E140/300, TrL: 33049.97 (R: 32339.52, KLD: 154.44), Beta: 4.600, LR: 1.00e-04, ValL: 32520.54 (R: 31927.39, KLD: 128.95)\n",
      "[INFO]   Fold 1/5 VAE E145/300, TrL: 33073.83 (R: 32348.97, KLD: 157.58), Beta: 4.600, LR: 1.00e-04, ValL: 32398.17 (R: 31787.06, KLD: 132.85)\n",
      "[INFO]   Fold 1/5 VAE E150/300, TrL: 32701.46 (R: 31969.25, KLD: 159.18), Beta: 4.600, LR: 1.00e-04, ValL: 32283.04 (R: 31688.31, KLD: 129.29)\n",
      "[INFO]   Fold 1/5 VAE E155/300, TrL: 31822.43 (R: 31689.30, KLD: 217.07), Beta: 0.613, LR: 1.00e-04, ValL: 31588.46 (R: 31470.96, KLD: 191.58)\n",
      "[INFO]   Fold 1/5 VAE E160/300, TrL: 31830.17 (R: 31488.15, KLD: 247.84), Beta: 1.380, LR: 1.00e-04, ValL: 31605.91 (R: 31312.92, KLD: 212.31)\n",
      "[INFO]   Fold 1/5 VAE E165/300, TrL: 31792.37 (R: 31280.17, KLD: 238.60), Beta: 2.147, LR: 1.00e-04, ValL: 31625.95 (R: 31184.06, KLD: 205.85)\n",
      "[INFO]   Fold 1/5 Learning rate reducido a 1.00e-05. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 1/5 VAE E170/300, TrL: 31865.87 (R: 31226.63, KLD: 219.42), Beta: 2.913, LR: 1.00e-05, ValL: 31708.27 (R: 31162.27, KLD: 187.42)\n",
      "[INFO]   Fold 1/5 VAE E175/300, TrL: 31908.92 (R: 31118.26, KLD: 214.85), Beta: 3.680, LR: 1.00e-05, ValL: 31816.20 (R: 31149.13, KLD: 181.27)\n",
      "[INFO]   Fold 1/5 VAE E180/300, TrL: 31941.06 (R: 31020.30, KLD: 207.07), Beta: 4.447, LR: 1.00e-05, ValL: 31899.14 (R: 31117.58, KLD: 175.76)\n",
      "[INFO]   Fold 1/5 Learning rate reducido a 1.00e-06. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 1/5 VAE E185/300, TrL: 32098.26 (R: 31172.77, KLD: 201.19), Beta: 4.600, LR: 1.00e-05, ValL: 31880.09 (R: 31101.65, KLD: 169.23)\n",
      "[INFO]   Fold 1/5 VAE E190/300, TrL: 32047.01 (R: 31134.52, KLD: 198.37), Beta: 4.600, LR: 1.00e-06, ValL: 31936.23 (R: 31164.28, KLD: 167.82)\n",
      "[INFO]   Fold 1/5 VAE E195/300, TrL: 32032.27 (R: 31113.65, KLD: 199.70), Beta: 4.600, LR: 1.00e-06, ValL: 31915.30 (R: 31148.79, KLD: 166.63)\n",
      "[INFO]   Fold 1/5 VAE E200/300, TrL: 32229.77 (R: 31312.35, KLD: 199.44), Beta: 4.600, LR: 1.00e-06, ValL: 31922.88 (R: 31155.75, KLD: 166.77)\n",
      "[INFO]   Fold 1/5 Learning rate reducido a 1.00e-07. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 1/5 VAE E205/300, TrL: 32105.93 (R: 31195.35, KLD: 197.95), Beta: 4.600, LR: 1.00e-07, ValL: 31866.38 (R: 31104.29, KLD: 165.67)\n",
      "[INFO]   Fold 1/5 VAE E210/300, TrL: 32026.23 (R: 31114.36, KLD: 198.23), Beta: 4.600, LR: 1.00e-07, ValL: 31867.90 (R: 31109.25, KLD: 164.92)\n",
      "[INFO]   Fold 1/5 VAE E215/300, TrL: 31964.07 (R: 31056.22, KLD: 197.36), Beta: 4.600, LR: 1.00e-07, ValL: 31902.66 (R: 31143.78, KLD: 164.97)\n",
      "[INFO]   Fold 1/5 Learning rate reducido a 1.00e-08. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 1/5 VAE E220/300, TrL: 32064.29 (R: 31151.94, KLD: 198.34), Beta: 4.600, LR: 1.00e-08, ValL: 31891.72 (R: 31131.23, KLD: 165.32)\n",
      "[INFO]   Fold 1/5 VAE E225/300, TrL: 32055.47 (R: 31145.61, KLD: 197.80), Beta: 4.600, LR: 1.00e-08, ValL: 31894.77 (R: 31133.38, KLD: 165.52)\n",
      "[INFO]   Fold 1/5 VAE E230/300, TrL: 31373.66 (R: 31252.42, KLD: 197.67), Beta: 0.613, LR: 1.00e-08, ValL: 31222.97 (R: 31121.04, KLD: 166.19)\n",
      "[INFO]   Fold 1/5 VAE E235/300, TrL: 31357.00 (R: 31084.21, KLD: 197.68), Beta: 1.380, LR: 1.00e-08, ValL: 31375.31 (R: 31146.88, KLD: 165.53)\n",
      "[INFO]   Fold 1/5 VAE E240/300, TrL: 31466.05 (R: 31038.83, KLD: 199.02), Beta: 2.147, LR: 1.00e-08, ValL: 31463.52 (R: 31106.66, KLD: 166.24)\n",
      "[INFO]   Fold 1/5 VAE E245/300, TrL: 31752.86 (R: 31174.21, KLD: 198.62), Beta: 2.913, LR: 1.00e-08, ValL: 31590.08 (R: 31108.51, KLD: 165.30)\n",
      "[INFO]   Fold 1/5 VAE E250/300, TrL: 31935.82 (R: 31209.36, KLD: 197.41), Beta: 3.680, LR: 1.00e-08, ValL: 31743.82 (R: 31128.85, KLD: 167.11)\n",
      "[INFO]   Fold 1/5 VAE E255/300, TrL: 31956.02 (R: 31074.03, KLD: 198.35), Beta: 4.447, LR: 1.00e-08, ValL: 31922.57 (R: 31183.64, KLD: 166.18)\n",
      "[INFO]   Fold 1/5 Early stopping VAE en epoch 256. Mejor val_loss: 31143.4741\n",
      "[INFO]   Fold 1/5 VAE final model loaded (best val_loss: 31143.4741).\n",
      "[INFO]   Fold 1/5 Modelo VAE guardado en: resultados_FIN_v2/fold_1/vae_model_fold_1.pt\n",
      "[INFO] Fold 1/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 73 (49.7%)\n",
      "      M: 74 (50.3%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 514)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 297, 'model__learning_rate': 0.01403990706076864, 'model__max_depth': 12, 'model__subsample': 0.4602965575097925, 'model__colsample_bytree': 0.9741968568896886, 'model__min_child_weight': 3.4411589535975704}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 1 (xgb): AUC=0.8860, Bal.Acc=0.7558\n",
      "[INFO]       Pipeline completo de xgb del fold 1 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__estimator__C': 191.05740825746526, 'model__estimator__gamma': 0.00019321189089373936, 'model__estimator__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 1 (svm): AUC=0.8348, Bal.Acc=0.7602\n",
      "[INFO]       Pipeline completo de svm del fold 1 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.0006828252208682665}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 1 (logreg): AUC=0.9094, Bal.Acc=0.7822\n",
      "[INFO]       Pipeline completo de logreg del fold 1 guardado.\n",
      "[INFO]   Fold 1/5 completado en 225.30 segundos.\n",
      "[INFO] --- Iniciando Fold 2/5 ---\n",
      "[INFO] Fold 2/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 19 (51.4%)\n",
      "      M: 18 (48.6%)\n",
      "[INFO] Fold 2/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 187 (47.5%)\n",
      "      M: 207 (52.5%)\n",
      "    Age_Group:\n",
      "      0: 98 (24.9%)\n",
      "      1: 101 (25.6%)\n",
      "      2: 94 (23.9%)\n",
      "      3: 101 (25.6%)\n",
      "[INFO]   Fold 2/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 2/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 61 (19.4%)\n",
      "      CN: 57 (18.1%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 150 (47.6%)\n",
      "      M: 165 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 79 (25.1%)\n",
      "      1: 81 (25.7%)\n",
      "      2: 75 (23.8%)\n",
      "      3: 80 (25.4%)\n",
      "[INFO] Fold 2/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 15 (19.0%)\n",
      "      CN: 14 (17.7%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 37 (46.8%)\n",
      "      M: 42 (53.2%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 20 (25.3%)\n",
      "      2: 19 (24.1%)\n",
      "      3: 21 (26.6%)\n",
      "[INFO]   Fold 2/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.049, std=0.776)\n",
      "[INFO] Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.055, std=0.813)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.408, std=1.730)\n",
      "[INFO]   Fold 2/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 2/5 Usando scheduler: ReduceLROnPlateau\n",
      "[INFO]   Fold 2/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 2/5 VAE E5/300, TrL: 63497.19 (R: 63388.95, KLD: 176.48), Beta: 0.613, LR: 1.00e-04, ValL: 57467.31 (R: 57413.97, KLD: 86.96)\n",
      "[INFO]   Fold 2/5 VAE E10/300, TrL: 58660.13 (R: 58201.98, KLD: 331.99), Beta: 1.380, LR: 1.00e-04, ValL: 51596.71 (R: 50650.15, KLD: 685.91)\n",
      "[INFO]   Fold 2/5 VAE E15/300, TrL: 52533.28 (R: 51831.49, KLD: 326.92), Beta: 2.147, LR: 1.00e-04, ValL: 47548.29 (R: 46840.49, KLD: 329.72)\n",
      "[INFO]   Fold 2/5 VAE E20/300, TrL: 50216.13 (R: 49575.77, KLD: 219.80), Beta: 2.913, LR: 1.00e-04, ValL: 45078.63 (R: 44326.03, KLD: 258.33)\n",
      "[INFO]   Fold 2/5 VAE E25/300, TrL: 48025.70 (R: 47408.68, KLD: 167.67), Beta: 3.680, LR: 1.00e-04, ValL: 42419.34 (R: 41737.98, KLD: 185.15)\n",
      "[INFO]   Fold 2/5 VAE E30/300, TrL: 45650.45 (R: 44938.49, KLD: 160.11), Beta: 4.447, LR: 1.00e-04, ValL: 39589.61 (R: 38899.32, KLD: 155.24)\n",
      "[INFO]   Fold 2/5 VAE E35/300, TrL: 43511.11 (R: 42832.14, KLD: 147.60), Beta: 4.600, LR: 1.00e-04, ValL: 37104.12 (R: 36520.88, KLD: 126.79)\n",
      "[INFO]   Fold 2/5 VAE E40/300, TrL: 41912.29 (R: 41256.14, KLD: 142.64), Beta: 4.600, LR: 1.00e-04, ValL: 35626.07 (R: 35045.77, KLD: 126.15)\n",
      "[INFO]   Fold 2/5 VAE E45/300, TrL: 40588.15 (R: 39945.98, KLD: 139.60), Beta: 4.600, LR: 1.00e-04, ValL: 34637.05 (R: 34019.34, KLD: 134.29)\n",
      "[INFO]   Fold 2/5 VAE E50/300, TrL: 39512.56 (R: 38898.07, KLD: 133.58), Beta: 4.600, LR: 1.00e-04, ValL: 33511.98 (R: 32956.84, KLD: 120.68)\n",
      "[INFO]   Fold 2/5 VAE E55/300, TrL: 38752.10 (R: 38116.92, KLD: 138.08), Beta: 4.600, LR: 1.00e-04, ValL: 32752.03 (R: 32202.59, KLD: 119.45)\n",
      "[INFO]   Fold 2/5 VAE E60/300, TrL: 38135.27 (R: 37414.68, KLD: 156.65), Beta: 4.600, LR: 1.00e-04, ValL: 32054.65 (R: 31467.41, KLD: 127.66)\n",
      "[INFO]   Fold 2/5 VAE E65/300, TrL: 37593.04 (R: 36832.20, KLD: 165.40), Beta: 4.600, LR: 1.00e-04, ValL: 31706.01 (R: 30994.21, KLD: 154.74)\n",
      "[INFO]   Fold 2/5 VAE E70/300, TrL: 36925.52 (R: 36268.40, KLD: 142.85), Beta: 4.600, LR: 1.00e-04, ValL: 31083.92 (R: 30482.19, KLD: 130.81)\n",
      "[INFO]   Fold 2/5 VAE E75/300, TrL: 36632.66 (R: 35943.01, KLD: 149.92), Beta: 4.600, LR: 1.00e-04, ValL: 30788.39 (R: 30112.90, KLD: 146.85)\n",
      "[INFO]   Fold 2/5 VAE E80/300, TrL: 35452.63 (R: 35312.90, KLD: 227.82), Beta: 0.613, LR: 1.00e-04, ValL: 29755.29 (R: 29622.79, KLD: 216.02)\n",
      "[INFO]   Fold 2/5 VAE E85/300, TrL: 35139.52 (R: 34790.04, KLD: 253.24), Beta: 1.380, LR: 1.00e-04, ValL: 29584.76 (R: 29261.31, KLD: 234.38)\n",
      "[INFO]   Fold 2/5 VAE E90/300, TrL: 35121.54 (R: 34628.28, KLD: 229.78), Beta: 2.147, LR: 1.00e-04, ValL: 29416.29 (R: 28925.51, KLD: 228.63)\n",
      "[INFO]   Fold 2/5 VAE E95/300, TrL: 35020.62 (R: 34377.50, KLD: 220.75), Beta: 2.913, LR: 1.00e-04, ValL: 29419.09 (R: 28729.42, KLD: 236.73)\n",
      "[INFO]   Fold 2/5 VAE E100/300, TrL: 34698.34 (R: 33986.71, KLD: 193.38), Beta: 3.680, LR: 1.00e-04, ValL: 29329.29 (R: 28703.31, KLD: 170.11)\n",
      "[INFO]   Fold 2/5 VAE E105/300, TrL: 34652.83 (R: 33871.81, KLD: 175.64), Beta: 4.447, LR: 1.00e-04, ValL: 29167.53 (R: 28430.69, KLD: 165.71)\n",
      "[INFO]   Fold 2/5 VAE E110/300, TrL: 34425.05 (R: 33642.14, KLD: 170.20), Beta: 4.600, LR: 1.00e-04, ValL: 29234.35 (R: 28530.72, KLD: 152.96)\n",
      "[INFO]   Fold 2/5 VAE E115/300, TrL: 34239.88 (R: 33497.98, KLD: 161.28), Beta: 4.600, LR: 1.00e-04, ValL: 28892.95 (R: 28233.60, KLD: 143.34)\n",
      "[INFO]   Fold 2/5 VAE E120/300, TrL: 33947.65 (R: 33207.51, KLD: 160.90), Beta: 4.600, LR: 1.00e-04, ValL: 28724.69 (R: 28091.95, KLD: 137.55)\n",
      "[INFO]   Fold 2/5 VAE E125/300, TrL: 33668.86 (R: 32936.78, KLD: 159.15), Beta: 4.600, LR: 1.00e-04, ValL: 28617.97 (R: 28005.01, KLD: 133.25)\n",
      "[INFO]   Fold 2/5 VAE E130/300, TrL: 33611.00 (R: 32870.00, KLD: 161.09), Beta: 4.600, LR: 1.00e-04, ValL: 28472.11 (R: 27849.88, KLD: 135.27)\n",
      "[INFO]   Fold 2/5 VAE E135/300, TrL: 33502.79 (R: 32771.54, KLD: 158.97), Beta: 4.600, LR: 1.00e-04, ValL: 28330.42 (R: 27715.32, KLD: 133.72)\n",
      "[INFO]   Fold 2/5 VAE E140/300, TrL: 33157.03 (R: 32437.49, KLD: 156.42), Beta: 4.600, LR: 1.00e-04, ValL: 28267.61 (R: 27645.85, KLD: 135.16)\n",
      "[INFO]   Fold 2/5 VAE E145/300, TrL: 33127.99 (R: 32375.23, KLD: 163.64), Beta: 4.600, LR: 1.00e-04, ValL: 27960.66 (R: 27338.96, KLD: 135.15)\n",
      "[INFO]   Fold 2/5 VAE E150/300, TrL: 32860.22 (R: 32132.64, KLD: 158.17), Beta: 4.600, LR: 1.00e-04, ValL: 28088.54 (R: 27472.41, KLD: 133.94)\n",
      "[INFO]   Fold 2/5 VAE E155/300, TrL: 31991.92 (R: 31856.23, KLD: 221.24), Beta: 0.613, LR: 1.00e-04, ValL: 27192.54 (R: 27071.85, KLD: 196.77)\n",
      "[INFO]   Fold 2/5 VAE E160/300, TrL: 31999.05 (R: 31659.08, KLD: 246.36), Beta: 1.380, LR: 1.00e-04, ValL: 27156.23 (R: 26849.63, KLD: 222.17)\n",
      "[INFO]   Fold 2/5 VAE E165/300, TrL: 31989.46 (R: 31471.87, KLD: 241.11), Beta: 2.147, LR: 1.00e-04, ValL: 27403.04 (R: 26944.41, KLD: 213.65)\n",
      "[INFO]   Fold 2/5 VAE E170/300, TrL: 32107.27 (R: 31463.17, KLD: 221.09), Beta: 2.913, LR: 1.00e-04, ValL: 27470.40 (R: 26909.24, KLD: 192.62)\n",
      "[INFO]   Fold 2/5 VAE E175/300, TrL: 32086.55 (R: 31346.22, KLD: 201.17), Beta: 3.680, LR: 1.00e-04, ValL: 27474.59 (R: 26852.75, KLD: 168.98)\n",
      "[INFO]   Fold 2/5 Learning rate reducido a 1.00e-05. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 2/5 VAE E180/300, TrL: 32080.41 (R: 31216.35, KLD: 194.32), Beta: 4.447, LR: 1.00e-05, ValL: 27559.82 (R: 26838.10, KLD: 162.31)\n",
      "[INFO]   Fold 2/5 VAE E185/300, TrL: 32074.74 (R: 31203.48, KLD: 189.41), Beta: 4.600, LR: 1.00e-05, ValL: 27529.04 (R: 26810.87, KLD: 156.12)\n",
      "[INFO]   Fold 2/5 VAE E190/300, TrL: 32096.69 (R: 31242.83, KLD: 185.62), Beta: 4.600, LR: 1.00e-05, ValL: 27551.78 (R: 26843.18, KLD: 154.04)\n",
      "[INFO]   Fold 2/5 Learning rate reducido a 1.00e-06. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 2/5 VAE E195/300, TrL: 32079.50 (R: 31230.11, KLD: 184.65), Beta: 4.600, LR: 1.00e-06, ValL: 27609.71 (R: 26907.02, KLD: 152.76)\n",
      "[INFO]   Fold 2/5 VAE E200/300, TrL: 31962.05 (R: 31113.92, KLD: 184.37), Beta: 4.600, LR: 1.00e-06, ValL: 27567.57 (R: 26870.14, KLD: 151.62)\n",
      "[INFO]   Fold 2/5 VAE E205/300, TrL: 31979.61 (R: 31131.00, KLD: 184.48), Beta: 4.600, LR: 1.00e-06, ValL: 27581.10 (R: 26884.42, KLD: 151.45)\n",
      "[INFO]   Fold 2/5 Learning rate reducido a 1.00e-07. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 2/5 VAE E210/300, TrL: 31957.95 (R: 31108.39, KLD: 184.69), Beta: 4.600, LR: 1.00e-07, ValL: 27345.62 (R: 26649.39, KLD: 151.35)\n",
      "[INFO]   Fold 2/5 VAE E215/300, TrL: 32016.93 (R: 31171.17, KLD: 183.86), Beta: 4.600, LR: 1.00e-07, ValL: 27480.15 (R: 26781.11, KLD: 151.96)\n",
      "[INFO]   Fold 2/5 VAE E220/300, TrL: 32017.89 (R: 31167.29, KLD: 184.91), Beta: 4.600, LR: 1.00e-07, ValL: 27506.18 (R: 26811.25, KLD: 151.07)\n",
      "[INFO]   Fold 2/5 Learning rate reducido a 1.00e-08. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 2/5 VAE E225/300, TrL: 32019.42 (R: 31172.18, KLD: 184.18), Beta: 4.600, LR: 1.00e-08, ValL: 27563.86 (R: 26872.60, KLD: 150.28)\n",
      "[INFO]   Fold 2/5 VAE E230/300, TrL: 31314.15 (R: 31202.36, KLD: 182.27), Beta: 0.613, LR: 1.00e-08, ValL: 26842.33 (R: 26750.09, KLD: 150.39)\n",
      "[INFO]   Fold 2/5 VAE E235/300, TrL: 31479.00 (R: 31224.60, KLD: 184.35), Beta: 1.380, LR: 1.00e-08, ValL: 27029.90 (R: 26820.82, KLD: 151.51)\n",
      "[INFO]   Fold 2/5 VAE E240/300, TrL: 31662.15 (R: 31266.87, KLD: 184.14), Beta: 2.147, LR: 1.00e-08, ValL: 27223.50 (R: 26899.32, KLD: 151.02)\n",
      "[INFO]   Fold 2/5 VAE E245/300, TrL: 31805.13 (R: 31271.32, KLD: 183.23), Beta: 2.913, LR: 1.00e-08, ValL: 27301.82 (R: 26860.81, KLD: 151.38)\n",
      "[INFO]   Fold 2/5 VAE E250/300, TrL: 31852.03 (R: 31177.12, KLD: 183.40), Beta: 3.680, LR: 1.00e-08, ValL: 27434.45 (R: 26878.92, KLD: 150.96)\n",
      "[INFO]   Fold 2/5 VAE E255/300, TrL: 32002.05 (R: 31182.30, KLD: 184.35), Beta: 4.447, LR: 1.00e-08, ValL: 27510.32 (R: 26841.45, KLD: 150.42)\n",
      "[INFO]   Fold 2/5 Early stopping VAE en epoch 259. Mejor val_loss: 26733.2242\n",
      "[INFO]   Fold 2/5 VAE final model loaded (best val_loss: 26733.2242).\n",
      "[INFO]   Fold 2/5 Modelo VAE guardado en: resultados_FIN_v2/fold_2/vae_model_fold_2.pt\n",
      "[INFO] Fold 2/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 73 (49.7%)\n",
      "      M: 74 (50.3%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 514)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 391, 'model__learning_rate': 0.07407909831340798, 'model__max_depth': 4, 'model__subsample': 0.5288371857474508, 'model__colsample_bytree': 0.835694366903004, 'model__min_child_weight': 0.5034931173367659}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 2 (xgb): AUC=0.7895, Bal.Acc=0.7310\n",
      "[INFO]       Pipeline completo de xgb del fold 2 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__estimator__C': 0.04121652218421463, 'model__estimator__gamma': 9.292356666203762e-05, 'model__estimator__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 2 (svm): AUC=0.7178, Bal.Acc=0.6725\n",
      "[INFO]       Pipeline completo de svm del fold 2 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.001995122190506801}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 2 (logreg): AUC=0.7573, Bal.Acc=0.7295\n",
      "[INFO]       Pipeline completo de logreg del fold 2 guardado.\n",
      "[INFO]   Fold 2/5 completado en 207.48 segundos.\n",
      "[INFO] --- Iniciando Fold 3/5 ---\n",
      "[INFO] Fold 3/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 18 (48.6%)\n",
      "      M: 19 (51.4%)\n",
      "[INFO] Fold 3/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 188 (47.7%)\n",
      "      M: 206 (52.3%)\n",
      "    Age_Group:\n",
      "      0: 97 (24.6%)\n",
      "      1: 104 (26.4%)\n",
      "      2: 97 (24.6%)\n",
      "      3: 96 (24.4%)\n",
      "[INFO]   Fold 3/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 3/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 60 (19.0%)\n",
      "      CN: 58 (18.4%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 150 (47.6%)\n",
      "      M: 165 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 78 (24.8%)\n",
      "      1: 83 (26.3%)\n",
      "      2: 78 (24.8%)\n",
      "      3: 76 (24.1%)\n",
      "[INFO] Fold 3/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 16 (20.3%)\n",
      "      CN: 13 (16.5%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 38 (48.1%)\n",
      "      M: 41 (51.9%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 21 (26.6%)\n",
      "      2: 19 (24.1%)\n",
      "      3: 20 (25.3%)\n",
      "[INFO]   Fold 3/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.050, std=0.780)\n",
      "[INFO] Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.054, std=0.812)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.419, std=1.767)\n",
      "[INFO]   Fold 3/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 3/5 Usando scheduler: ReduceLROnPlateau\n",
      "[INFO]   Fold 3/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 3/5 VAE E5/300, TrL: 62993.98 (R: 62884.57, KLD: 178.38), Beta: 0.613, LR: 1.00e-04, ValL: 55498.10 (R: 55442.94, KLD: 89.93)\n",
      "[INFO]   Fold 3/5 VAE E10/300, TrL: 58042.33 (R: 57575.77, KLD: 338.09), Beta: 1.380, LR: 1.00e-04, ValL: 49806.82 (R: 48810.62, KLD: 721.88)\n",
      "[INFO]   Fold 3/5 VAE E15/300, TrL: 51573.77 (R: 50827.30, KLD: 347.74), Beta: 2.147, LR: 1.00e-04, ValL: 45097.88 (R: 44281.69, KLD: 380.22)\n",
      "[INFO]   Fold 3/5 VAE E20/300, TrL: 48518.33 (R: 47878.27, KLD: 219.70), Beta: 2.913, LR: 1.00e-04, ValL: 42247.87 (R: 41401.70, KLD: 290.45)\n",
      "[INFO]   Fold 3/5 VAE E25/300, TrL: 45950.04 (R: 45306.93, KLD: 174.76), Beta: 3.680, LR: 1.00e-04, ValL: 39800.13 (R: 38906.80, KLD: 242.75)\n",
      "[INFO]   Fold 3/5 VAE E30/300, TrL: 43976.12 (R: 43294.13, KLD: 153.37), Beta: 4.447, LR: 1.00e-04, ValL: 37851.39 (R: 36961.50, KLD: 200.12)\n",
      "[INFO]   Fold 3/5 VAE E35/300, TrL: 42540.73 (R: 41900.80, KLD: 139.11), Beta: 4.600, LR: 1.00e-04, ValL: 36318.54 (R: 35589.72, KLD: 158.44)\n",
      "[INFO]   Fold 3/5 VAE E40/300, TrL: 41412.69 (R: 40802.50, KLD: 132.65), Beta: 4.600, LR: 1.00e-04, ValL: 35201.93 (R: 34570.52, KLD: 137.26)\n",
      "[INFO]   Fold 3/5 VAE E45/300, TrL: 40376.39 (R: 39773.34, KLD: 131.10), Beta: 4.600, LR: 1.00e-04, ValL: 34376.16 (R: 33689.15, KLD: 149.35)\n",
      "[INFO]   Fold 3/5 VAE E50/300, TrL: 39633.40 (R: 39015.19, KLD: 134.40), Beta: 4.600, LR: 1.00e-04, ValL: 33652.95 (R: 32979.58, KLD: 146.38)\n",
      "[INFO]   Fold 3/5 VAE E55/300, TrL: 38683.69 (R: 38072.29, KLD: 132.91), Beta: 4.600, LR: 1.00e-04, ValL: 32966.82 (R: 32345.14, KLD: 135.15)\n",
      "[INFO]   Fold 3/5 VAE E60/300, TrL: 38225.60 (R: 37553.49, KLD: 146.11), Beta: 4.600, LR: 1.00e-04, ValL: 32234.57 (R: 31640.96, KLD: 129.05)\n",
      "[INFO]   Fold 3/5 VAE E65/300, TrL: 37680.13 (R: 37020.72, KLD: 143.35), Beta: 4.600, LR: 1.00e-04, ValL: 31822.96 (R: 31130.34, KLD: 150.57)\n",
      "[INFO]   Fold 3/5 VAE E70/300, TrL: 37037.09 (R: 36407.27, KLD: 136.92), Beta: 4.600, LR: 1.00e-04, ValL: 31271.24 (R: 30658.14, KLD: 133.28)\n",
      "[INFO]   Fold 3/5 VAE E75/300, TrL: 36601.80 (R: 35988.42, KLD: 133.34), Beta: 4.600, LR: 1.00e-04, ValL: 30845.79 (R: 30239.53, KLD: 131.79)\n",
      "[INFO]   Fold 3/5 VAE E80/300, TrL: 35392.55 (R: 35259.96, KLD: 216.18), Beta: 0.613, LR: 1.00e-04, ValL: 29930.61 (R: 29778.46, KLD: 248.08)\n",
      "[INFO]   Fold 3/5 VAE E85/300, TrL: 35214.74 (R: 34877.59, KLD: 244.31), Beta: 1.380, LR: 1.00e-04, ValL: 29756.05 (R: 29351.35, KLD: 293.26)\n",
      "[INFO]   Fold 3/5 VAE E90/300, TrL: 35068.06 (R: 34607.81, KLD: 214.40), Beta: 2.147, LR: 1.00e-04, ValL: 29625.02 (R: 29130.37, KLD: 230.43)\n",
      "[INFO]   Fold 3/5 VAE E95/300, TrL: 34947.09 (R: 34380.57, KLD: 194.46), Beta: 2.913, LR: 1.00e-04, ValL: 29536.47 (R: 28939.14, KLD: 205.03)\n",
      "[INFO]   Fold 3/5 VAE E100/300, TrL: 34773.56 (R: 34105.81, KLD: 181.45), Beta: 3.680, LR: 1.00e-04, ValL: 29482.50 (R: 28817.00, KLD: 180.84)\n",
      "[INFO]   Fold 3/5 VAE E105/300, TrL: 34565.35 (R: 33817.07, KLD: 168.28), Beta: 4.447, LR: 1.00e-04, ValL: 29361.54 (R: 28615.26, KLD: 167.83)\n",
      "[INFO]   Fold 3/5 VAE E110/300, TrL: 34357.35 (R: 33627.89, KLD: 158.58), Beta: 4.600, LR: 1.00e-04, ValL: 29044.06 (R: 28405.99, KLD: 138.71)\n",
      "[INFO]   Fold 3/5 VAE E115/300, TrL: 34067.59 (R: 33353.18, KLD: 155.31), Beta: 4.600, LR: 1.00e-04, ValL: 29060.59 (R: 28412.60, KLD: 140.87)\n",
      "[INFO]   Fold 3/5 VAE E120/300, TrL: 33887.62 (R: 33180.85, KLD: 153.65), Beta: 4.600, LR: 1.00e-04, ValL: 28791.95 (R: 28147.41, KLD: 140.12)\n",
      "[INFO]   Fold 3/5 VAE E125/300, TrL: 33762.06 (R: 33059.25, KLD: 152.79), Beta: 4.600, LR: 1.00e-04, ValL: 28719.09 (R: 28092.33, KLD: 136.25)\n",
      "[INFO]   Fold 3/5 VAE E130/300, TrL: 33632.24 (R: 32921.63, KLD: 154.48), Beta: 4.600, LR: 1.00e-04, ValL: 28676.94 (R: 28024.66, KLD: 141.80)\n",
      "[INFO]   Fold 3/5 VAE E135/300, TrL: 33352.54 (R: 32634.08, KLD: 156.19), Beta: 4.600, LR: 1.00e-04, ValL: 28477.57 (R: 27803.49, KLD: 146.54)\n",
      "[INFO]   Fold 3/5 VAE E140/300, TrL: 33226.72 (R: 32515.91, KLD: 154.52), Beta: 4.600, LR: 1.00e-04, ValL: 28319.45 (R: 27708.14, KLD: 132.89)\n",
      "[INFO]   Fold 3/5 VAE E145/300, TrL: 33351.90 (R: 32615.80, KLD: 160.02), Beta: 4.600, LR: 1.00e-04, ValL: 28249.67 (R: 27591.28, KLD: 143.13)\n",
      "[INFO]   Fold 3/5 VAE E150/300, TrL: 32951.21 (R: 32221.13, KLD: 158.71), Beta: 4.600, LR: 1.00e-04, ValL: 28125.27 (R: 27501.74, KLD: 135.55)\n",
      "[INFO]   Fold 3/5 VAE E155/300, TrL: 32104.29 (R: 31973.38, KLD: 213.43), Beta: 0.613, LR: 1.00e-04, ValL: 27418.83 (R: 27294.63, KLD: 202.51)\n",
      "[INFO]   Fold 3/5 VAE E160/300, TrL: 32091.84 (R: 31748.13, KLD: 249.07), Beta: 1.380, LR: 1.00e-04, ValL: 27417.06 (R: 27103.07, KLD: 227.53)\n",
      "[INFO]   Fold 3/5 VAE E165/300, TrL: 32111.43 (R: 31598.98, KLD: 238.72), Beta: 2.147, LR: 1.00e-04, ValL: 27436.41 (R: 26969.03, KLD: 217.72)\n",
      "[INFO]   Fold 3/5 VAE E170/300, TrL: 32109.02 (R: 31478.53, KLD: 216.41), Beta: 2.913, LR: 1.00e-04, ValL: 27440.24 (R: 26886.33, KLD: 190.13)\n",
      "[INFO]   Fold 3/5 Learning rate reducido a 1.00e-05. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 3/5 VAE E175/300, TrL: 32132.71 (R: 31411.04, KLD: 196.11), Beta: 3.680, LR: 1.00e-05, ValL: 27515.58 (R: 26886.61, KLD: 170.92)\n",
      "[INFO]   Fold 3/5 VAE E180/300, TrL: 32124.60 (R: 31264.73, KLD: 193.37), Beta: 4.447, LR: 1.00e-05, ValL: 27570.71 (R: 26844.11, KLD: 163.40)\n",
      "[INFO]   Fold 3/5 VAE E185/300, TrL: 32290.24 (R: 31429.83, KLD: 187.05), Beta: 4.600, LR: 1.00e-05, ValL: 27572.40 (R: 26853.39, KLD: 156.31)\n",
      "[INFO]   Fold 3/5 Learning rate reducido a 1.00e-06. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 3/5 VAE E190/300, TrL: 32184.93 (R: 31338.95, KLD: 183.91), Beta: 4.600, LR: 1.00e-05, ValL: 27515.72 (R: 26814.89, KLD: 152.35)\n",
      "[INFO]   Fold 3/5 VAE E195/300, TrL: 32217.05 (R: 31376.53, KLD: 182.72), Beta: 4.600, LR: 1.00e-06, ValL: 27661.75 (R: 26966.94, KLD: 151.04)\n",
      "[INFO]   Fold 3/5 VAE E200/300, TrL: 32094.80 (R: 31258.84, KLD: 181.73), Beta: 4.600, LR: 1.00e-06, ValL: 27550.31 (R: 26860.55, KLD: 149.95)\n",
      "[INFO]   Fold 3/5 VAE E205/300, TrL: 32134.91 (R: 31298.58, KLD: 181.81), Beta: 4.600, LR: 1.00e-06, ValL: 27523.01 (R: 26837.88, KLD: 148.94)\n",
      "[INFO]   Fold 3/5 Learning rate reducido a 1.00e-07. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 3/5 VAE E210/300, TrL: 32157.73 (R: 31326.19, KLD: 180.77), Beta: 4.600, LR: 1.00e-07, ValL: 27553.64 (R: 26864.66, KLD: 149.78)\n",
      "[INFO]   Fold 3/5 VAE E215/300, TrL: 32157.22 (R: 31321.59, KLD: 181.66), Beta: 4.600, LR: 1.00e-07, ValL: 27493.18 (R: 26803.91, KLD: 149.84)\n",
      "[INFO]   Fold 3/5 VAE E220/300, TrL: 32123.34 (R: 31289.12, KLD: 181.35), Beta: 4.600, LR: 1.00e-07, ValL: 27559.92 (R: 26870.96, KLD: 149.77)\n",
      "[INFO]   Fold 3/5 Learning rate reducido a 1.00e-08. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 3/5 VAE E225/300, TrL: 32155.91 (R: 31323.71, KLD: 180.91), Beta: 4.600, LR: 1.00e-08, ValL: 27575.71 (R: 26883.76, KLD: 150.42)\n",
      "[INFO]   Fold 3/5 VAE E230/300, TrL: 31501.23 (R: 31388.92, KLD: 183.12), Beta: 0.613, LR: 1.00e-08, ValL: 26930.80 (R: 26838.81, KLD: 149.99)\n",
      "[INFO]   Fold 3/5 VAE E235/300, TrL: 31558.28 (R: 31306.36, KLD: 182.55), Beta: 1.380, LR: 1.00e-08, ValL: 27061.82 (R: 26854.67, KLD: 150.11)\n",
      "[INFO]   Fold 3/5 VAE E240/300, TrL: 31737.17 (R: 31348.07, KLD: 181.25), Beta: 2.147, LR: 1.00e-08, ValL: 27142.05 (R: 26820.70, KLD: 149.70)\n",
      "[INFO]   Fold 3/5 VAE E245/300, TrL: 31774.51 (R: 31247.01, KLD: 181.06), Beta: 2.913, LR: 1.00e-08, ValL: 27252.53 (R: 26818.66, KLD: 148.93)\n",
      "[INFO]   Fold 3/5 VAE E250/300, TrL: 32099.68 (R: 31433.01, KLD: 181.16), Beta: 3.680, LR: 1.00e-08, ValL: 27394.35 (R: 26842.73, KLD: 149.90)\n",
      "[INFO]   Fold 3/5 VAE E255/300, TrL: 32060.99 (R: 31250.82, KLD: 182.20), Beta: 4.447, LR: 1.00e-08, ValL: 27563.19 (R: 26896.56, KLD: 149.92)\n",
      "[INFO]   Fold 3/5 Early stopping VAE en epoch 258. Mejor val_loss: 26871.5020\n",
      "[INFO]   Fold 3/5 VAE final model loaded (best val_loss: 26871.5020).\n",
      "[INFO]   Fold 3/5 Modelo VAE guardado en: resultados_FIN_v2/fold_3/vae_model_fold_3.pt\n",
      "[INFO] Fold 3/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 74 (50.3%)\n",
      "      M: 73 (49.7%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 514)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 1292, 'model__learning_rate': 0.01409004202693179, 'model__max_depth': 4, 'model__subsample': 0.8991850109897399, 'model__colsample_bytree': 0.957230883350235, 'model__min_child_weight': 10.686935961746872}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 3 (xgb): AUC=0.8304, Bal.Acc=0.8392\n",
      "[INFO]       Pipeline completo de xgb del fold 3 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__estimator__C': 4.120480030332733, 'model__estimator__gamma': 0.0073503602140292746, 'model__estimator__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 3 (svm): AUC=0.7924, Bal.Acc=0.7266\n",
      "[INFO]       Pipeline completo de svm del fold 3 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.003345003457119209}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 3 (logreg): AUC=0.8304, Bal.Acc=0.7018\n",
      "[INFO]       Pipeline completo de logreg del fold 3 guardado.\n",
      "[INFO]   Fold 3/5 completado en 263.14 segundos.\n",
      "[INFO] --- Iniciando Fold 4/5 ---\n",
      "[INFO] Fold 4/5 Test Set (Clasificador) (N=37):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (51.4%)\n",
      "      CN: 18 (48.6%)\n",
      "    Sex:\n",
      "      F: 18 (48.6%)\n",
      "      M: 19 (51.4%)\n",
      "[INFO] Fold 4/5 Pool Entrenamiento VAE (N=394):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.3%)\n",
      "      CN: 71 (18.0%)\n",
      "      MCI: 247 (62.7%)\n",
      "    Sex:\n",
      "      F: 188 (47.7%)\n",
      "      M: 206 (52.3%)\n",
      "    Age_Group:\n",
      "      0: 99 (25.1%)\n",
      "      1: 96 (24.4%)\n",
      "      2: 98 (24.9%)\n",
      "      3: 101 (25.6%)\n",
      "[INFO]   Fold 4/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 4/5 Actual Train Set (VAE) (N=315):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 62 (19.7%)\n",
      "      CN: 56 (17.8%)\n",
      "      MCI: 197 (62.5%)\n",
      "    Sex:\n",
      "      F: 150 (47.6%)\n",
      "      M: 165 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 80 (25.4%)\n",
      "      1: 77 (24.4%)\n",
      "      2: 78 (24.8%)\n",
      "      3: 80 (25.4%)\n",
      "[INFO] Fold 4/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 14 (17.7%)\n",
      "      CN: 15 (19.0%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 38 (48.1%)\n",
      "      M: 41 (51.9%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 19 (24.1%)\n",
      "      2: 20 (25.3%)\n",
      "      3: 21 (26.6%)\n",
      "[INFO]   Fold 4/5 Sujetos VAE actual train: 315, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.775)\n",
      "[INFO] Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.058, std=0.816)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.403, std=1.693)\n",
      "[INFO]   Fold 4/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 4/5 Usando scheduler: ReduceLROnPlateau\n",
      "[INFO]   Fold 4/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 4/5 VAE E5/300, TrL: 63682.98 (R: 63575.09, KLD: 175.90), Beta: 0.613, LR: 1.00e-04, ValL: 58114.63 (R: 58061.04, KLD: 87.37)\n",
      "[INFO]   Fold 4/5 VAE E10/300, TrL: 59518.51 (R: 59098.78, KLD: 304.15), Beta: 1.380, LR: 1.00e-04, ValL: 52659.93 (R: 51762.72, KLD: 650.15)\n",
      "[INFO]   Fold 4/5 VAE E15/300, TrL: 52814.71 (R: 52086.13, KLD: 339.40), Beta: 2.147, LR: 1.00e-04, ValL: 47058.98 (R: 46446.89, KLD: 285.13)\n",
      "[INFO]   Fold 4/5 VAE E20/300, TrL: 49546.11 (R: 48933.95, KLD: 210.12), Beta: 2.913, LR: 1.00e-04, ValL: 43897.73 (R: 43282.94, KLD: 211.03)\n",
      "[INFO]   Fold 4/5 VAE E25/300, TrL: 46908.10 (R: 46269.87, KLD: 173.43), Beta: 3.680, LR: 1.00e-04, ValL: 41129.72 (R: 40280.84, KLD: 230.67)\n",
      "[INFO]   Fold 4/5 VAE E30/300, TrL: 44801.04 (R: 44118.38, KLD: 153.52), Beta: 4.447, LR: 1.00e-04, ValL: 38816.79 (R: 38021.60, KLD: 178.83)\n",
      "[INFO]   Fold 4/5 VAE E35/300, TrL: 43096.09 (R: 42425.94, KLD: 145.68), Beta: 4.600, LR: 1.00e-04, ValL: 37415.92 (R: 36626.63, KLD: 171.59)\n",
      "[INFO]   Fold 4/5 VAE E40/300, TrL: 41889.60 (R: 41228.71, KLD: 143.67), Beta: 4.600, LR: 1.00e-04, ValL: 35986.05 (R: 35187.54, KLD: 173.59)\n",
      "[INFO]   Fold 4/5 VAE E45/300, TrL: 40728.03 (R: 40072.01, KLD: 142.61), Beta: 4.600, LR: 1.00e-04, ValL: 34819.25 (R: 34165.39, KLD: 142.14)\n",
      "[INFO]   Fold 4/5 VAE E50/300, TrL: 39882.43 (R: 39212.07, KLD: 145.73), Beta: 4.600, LR: 1.00e-04, ValL: 34039.23 (R: 33394.53, KLD: 140.15)\n",
      "[INFO]   Fold 4/5 VAE E55/300, TrL: 39227.92 (R: 38587.56, KLD: 139.21), Beta: 4.600, LR: 1.00e-04, ValL: 33467.05 (R: 32786.01, KLD: 148.05)\n",
      "[INFO]   Fold 4/5 VAE E60/300, TrL: 38412.53 (R: 37765.04, KLD: 140.76), Beta: 4.600, LR: 1.00e-04, ValL: 32474.39 (R: 31869.41, KLD: 131.52)\n",
      "[INFO]   Fold 4/5 VAE E65/300, TrL: 37706.60 (R: 37068.42, KLD: 138.74), Beta: 4.600, LR: 1.00e-04, ValL: 32181.95 (R: 31581.25, KLD: 130.59)\n",
      "[INFO]   Fold 4/5 VAE E70/300, TrL: 37322.64 (R: 36664.40, KLD: 143.09), Beta: 4.600, LR: 1.00e-04, ValL: 31564.51 (R: 30964.40, KLD: 130.46)\n",
      "[INFO]   Fold 4/5 VAE E75/300, TrL: 36914.06 (R: 36247.84, KLD: 144.83), Beta: 4.600, LR: 1.00e-04, ValL: 31323.31 (R: 30680.80, KLD: 139.68)\n",
      "[INFO]   Fold 4/5 VAE E80/300, TrL: 35708.66 (R: 35572.18, KLD: 222.52), Beta: 0.613, LR: 1.00e-04, ValL: 30194.85 (R: 30059.90, KLD: 220.01)\n",
      "[INFO]   Fold 4/5 VAE E85/300, TrL: 35358.64 (R: 35024.98, KLD: 241.78), Beta: 1.380, LR: 1.00e-04, ValL: 30097.26 (R: 29772.51, KLD: 235.32)\n",
      "[INFO]   Fold 4/5 VAE E90/300, TrL: 35244.70 (R: 34769.20, KLD: 221.51), Beta: 2.147, LR: 1.00e-04, ValL: 29711.49 (R: 29252.86, KLD: 213.65)\n",
      "[INFO]   Fold 4/5 VAE E95/300, TrL: 34996.71 (R: 34408.80, KLD: 201.80), Beta: 2.913, LR: 1.00e-04, ValL: 29716.61 (R: 29120.12, KLD: 204.75)\n",
      "[INFO]   Fold 4/5 VAE E100/300, TrL: 34940.44 (R: 34255.46, KLD: 186.14), Beta: 3.680, LR: 1.00e-04, ValL: 29735.81 (R: 29109.29, KLD: 170.25)\n",
      "[INFO]   Fold 4/5 VAE E105/300, TrL: 34760.63 (R: 34008.75, KLD: 169.09), Beta: 4.447, LR: 1.00e-04, ValL: 29483.78 (R: 28829.00, KLD: 147.25)\n",
      "[INFO]   Fold 4/5 VAE E110/300, TrL: 34630.46 (R: 33840.36, KLD: 171.76), Beta: 4.600, LR: 1.00e-04, ValL: 29485.73 (R: 28745.77, KLD: 160.86)\n",
      "[INFO]   Fold 4/5 VAE E115/300, TrL: 34346.83 (R: 33598.65, KLD: 162.65), Beta: 4.600, LR: 1.00e-04, ValL: 29265.62 (R: 28583.93, KLD: 148.19)\n",
      "[INFO]   Fold 4/5 VAE E120/300, TrL: 34111.40 (R: 33382.77, KLD: 158.40), Beta: 4.600, LR: 1.00e-04, ValL: 29213.55 (R: 28580.88, KLD: 137.54)\n",
      "[INFO]   Fold 4/5 VAE E125/300, TrL: 33947.51 (R: 33212.93, KLD: 159.69), Beta: 4.600, LR: 1.00e-04, ValL: 28954.92 (R: 28317.03, KLD: 138.67)\n",
      "[INFO]   Fold 4/5 VAE E130/300, TrL: 33743.98 (R: 32999.64, KLD: 161.81), Beta: 4.600, LR: 1.00e-04, ValL: 28666.76 (R: 28041.75, KLD: 135.87)\n",
      "[INFO]   Fold 4/5 VAE E135/300, TrL: 33523.58 (R: 32779.14, KLD: 161.83), Beta: 4.600, LR: 1.00e-04, ValL: 28684.01 (R: 28071.15, KLD: 133.23)\n",
      "[INFO]   Fold 4/5 VAE E140/300, TrL: 33348.81 (R: 32569.40, KLD: 169.44), Beta: 4.600, LR: 1.00e-04, ValL: 28649.70 (R: 27998.12, KLD: 141.65)\n",
      "[INFO]   Fold 4/5 VAE E145/300, TrL: 33172.24 (R: 32422.97, KLD: 162.88), Beta: 4.600, LR: 1.00e-04, ValL: 28561.87 (R: 27915.20, KLD: 140.58)\n",
      "[INFO]   Fold 4/5 VAE E150/300, TrL: 33006.96 (R: 32272.22, KLD: 159.73), Beta: 4.600, LR: 1.00e-04, ValL: 28340.28 (R: 27738.09, KLD: 130.91)\n",
      "[INFO]   Fold 4/5 VAE E155/300, TrL: 32076.17 (R: 31943.91, KLD: 215.65), Beta: 0.613, LR: 1.00e-04, ValL: 27599.44 (R: 27481.64, KLD: 192.06)\n",
      "[INFO]   Fold 4/5 VAE E160/300, TrL: 32114.31 (R: 31777.41, KLD: 244.13), Beta: 1.380, LR: 1.00e-04, ValL: 27716.92 (R: 27415.15, KLD: 218.67)\n",
      "[INFO]   Fold 4/5 VAE E165/300, TrL: 32202.10 (R: 31690.66, KLD: 238.25), Beta: 2.147, LR: 1.00e-04, ValL: 27698.07 (R: 27263.69, KLD: 202.35)\n",
      "[INFO]   Fold 4/5 VAE E170/300, TrL: 32168.42 (R: 31528.71, KLD: 219.58), Beta: 2.913, LR: 1.00e-04, ValL: 27654.04 (R: 27116.63, KLD: 184.47)\n",
      "[INFO]   Fold 4/5 Learning rate reducido a 1.00e-05. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 4/5 VAE E175/300, TrL: 32450.15 (R: 31670.24, KLD: 211.93), Beta: 3.680, LR: 1.00e-05, ValL: 27733.23 (R: 27088.38, KLD: 175.23)\n",
      "[INFO]   Fold 4/5 VAE E180/300, TrL: 32314.37 (R: 31406.45, KLD: 204.18), Beta: 4.447, LR: 1.00e-05, ValL: 27935.14 (R: 27187.15, KLD: 168.21)\n",
      "[INFO]   Fold 4/5 VAE E185/300, TrL: 32301.51 (R: 31376.75, KLD: 201.04), Beta: 4.600, LR: 1.00e-05, ValL: 27854.41 (R: 27100.22, KLD: 163.95)\n",
      "[INFO]   Fold 4/5 Learning rate reducido a 1.00e-06. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 4/5 VAE E190/300, TrL: 32303.20 (R: 31397.63, KLD: 196.86), Beta: 4.600, LR: 1.00e-06, ValL: 27830.15 (R: 27095.60, KLD: 159.68)\n",
      "[INFO]   Fold 4/5 VAE E195/300, TrL: 32311.42 (R: 31412.10, KLD: 195.50), Beta: 4.600, LR: 1.00e-06, ValL: 27911.92 (R: 27178.29, KLD: 159.48)\n",
      "[INFO]   Fold 4/5 VAE E200/300, TrL: 32314.90 (R: 31410.07, KLD: 196.70), Beta: 4.600, LR: 1.00e-06, ValL: 27927.23 (R: 27193.11, KLD: 159.59)\n",
      "[INFO]   Fold 4/5 Learning rate reducido a 1.00e-07. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 4/5 VAE E205/300, TrL: 32326.95 (R: 31424.11, KLD: 196.27), Beta: 4.600, LR: 1.00e-07, ValL: 27898.27 (R: 27172.24, KLD: 157.83)\n",
      "[INFO]   Fold 4/5 VAE E210/300, TrL: 32410.29 (R: 31516.85, KLD: 194.23), Beta: 4.600, LR: 1.00e-07, ValL: 27895.04 (R: 27167.46, KLD: 158.17)\n",
      "[INFO]   Fold 4/5 VAE E215/300, TrL: 32326.26 (R: 31424.06, KLD: 196.13), Beta: 4.600, LR: 1.00e-07, ValL: 27987.90 (R: 27257.72, KLD: 158.73)\n",
      "[INFO]   Fold 4/5 Learning rate reducido a 1.00e-08. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 4/5 VAE E220/300, TrL: 32441.32 (R: 31543.00, KLD: 195.29), Beta: 4.600, LR: 1.00e-08, ValL: 27959.38 (R: 27226.93, KLD: 159.23)\n",
      "[INFO]   Fold 4/5 VAE E225/300, TrL: 32236.35 (R: 31347.53, KLD: 193.22), Beta: 4.600, LR: 1.00e-08, ValL: 27961.21 (R: 27236.46, KLD: 157.56)\n",
      "[INFO]   Fold 4/5 VAE E230/300, TrL: 31537.53 (R: 31417.19, KLD: 196.22), Beta: 0.613, LR: 1.00e-08, ValL: 27276.71 (R: 27179.66, KLD: 158.24)\n",
      "[INFO]   Fold 4/5 VAE E235/300, TrL: 31672.75 (R: 31404.91, KLD: 194.09), Beta: 1.380, LR: 1.00e-08, ValL: 27390.04 (R: 27169.91, KLD: 159.52)\n",
      "[INFO]   Fold 4/5 VAE E240/300, TrL: 31882.62 (R: 31462.09, KLD: 195.90), Beta: 2.147, LR: 1.00e-08, ValL: 27435.19 (R: 27097.05, KLD: 157.51)\n",
      "[INFO]   Fold 4/5 VAE E245/300, TrL: 31963.00 (R: 31395.12, KLD: 194.93), Beta: 2.913, LR: 1.00e-08, ValL: 27657.34 (R: 27199.22, KLD: 157.25)\n",
      "[INFO]   Fold 4/5 VAE E250/300, TrL: 32170.40 (R: 31453.16, KLD: 194.90), Beta: 3.680, LR: 1.00e-08, ValL: 27788.37 (R: 27209.68, KLD: 157.25)\n",
      "[INFO]   Fold 4/5 VAE E255/300, TrL: 32302.01 (R: 31435.56, KLD: 194.85), Beta: 4.447, LR: 1.00e-08, ValL: 27789.41 (R: 27084.27, KLD: 158.58)\n",
      "[INFO]   Fold 4/5 Early stopping VAE en epoch 258. Mejor val_loss: 27130.9279\n",
      "[INFO]   Fold 4/5 VAE final model loaded (best val_loss: 27130.9279).\n",
      "[INFO]   Fold 4/5 Modelo VAE guardado en: resultados_FIN_v2/fold_4/vae_model_fold_4.pt\n",
      "[INFO] Fold 4/5 Pool Train/Dev (Clasificador) (N=147):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.7%)\n",
      "      CN: 71 (48.3%)\n",
      "    Sex:\n",
      "      F: 74 (50.3%)\n",
      "      M: 73 (49.7%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (147, 514)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 1363, 'model__learning_rate': 0.004599935326090106, 'model__max_depth': 4, 'model__subsample': 0.7590763179177118, 'model__colsample_bytree': 0.2339920599389484, 'model__min_child_weight': 1.3232615450365297}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 4 (xgb): AUC=0.7719, Bal.Acc=0.7295\n",
      "[INFO]       Pipeline completo de xgb del fold 4 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__estimator__C': 2661.3873132687036, 'model__estimator__gamma': 1.2367560575158713e-06, 'model__estimator__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 4 (svm): AUC=0.7135, Bal.Acc=0.7573\n",
      "[INFO]       Pipeline completo de svm del fold 4 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.14424703102433575}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 4 (logreg): AUC=0.7398, Bal.Acc=0.7003\n",
      "[INFO]       Pipeline completo de logreg del fold 4 guardado.\n",
      "[INFO]   Fold 4/5 completado en 269.12 segundos.\n",
      "[INFO] --- Iniciando Fold 5/5 ---\n",
      "[INFO] Fold 5/5 Test Set (Clasificador) (N=36):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 19 (52.8%)\n",
      "      CN: 17 (47.2%)\n",
      "    Sex:\n",
      "      F: 18 (50.0%)\n",
      "      M: 18 (50.0%)\n",
      "[INFO] Fold 5/5 Pool Entrenamiento VAE (N=395):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (19.2%)\n",
      "      CN: 72 (18.2%)\n",
      "      MCI: 247 (62.5%)\n",
      "    Sex:\n",
      "      F: 188 (47.6%)\n",
      "      M: 207 (52.4%)\n",
      "    Age_Group:\n",
      "      0: 101 (25.6%)\n",
      "      1: 105 (26.6%)\n",
      "      2: 98 (24.8%)\n",
      "      3: 91 (23.0%)\n",
      "[INFO]   Fold 5/5 VAE val split será estratificado por ['ResearchGroup_Mapped', 'Sex', 'Age_Group'].\n",
      "[INFO] Fold 5/5 Actual Train Set (VAE) (N=316):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 61 (19.3%)\n",
      "      CN: 58 (18.4%)\n",
      "      MCI: 197 (62.3%)\n",
      "    Sex:\n",
      "      F: 151 (47.8%)\n",
      "      M: 165 (52.2%)\n",
      "    Age_Group:\n",
      "      0: 82 (25.9%)\n",
      "      1: 84 (26.6%)\n",
      "      2: 77 (24.4%)\n",
      "      3: 73 (23.1%)\n",
      "[INFO] Fold 5/5 Internal Val Set (VAE) (N=79):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 15 (19.0%)\n",
      "      CN: 14 (17.7%)\n",
      "      MCI: 50 (63.3%)\n",
      "    Sex:\n",
      "      F: 37 (46.8%)\n",
      "      M: 42 (53.2%)\n",
      "    Age_Group:\n",
      "      0: 19 (24.1%)\n",
      "      1: 21 (26.6%)\n",
      "      2: 21 (26.6%)\n",
      "      3: 18 (22.8%)\n",
      "[INFO]   Fold 5/5 Sujetos VAE actual train: 316, VAE internal val: 79\n",
      "[INFO] Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "[INFO] Parámetros de normalización se calcularán usando 316 sujetos de entrenamiento.\n",
      "[INFO] Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.777)\n",
      "[INFO] Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.057, std=0.814)\n",
      "[INFO] Canal 'DistanceCorr': Off-diag zscore_offdiag (train_params: mean=-0.407, std=1.702)\n",
      "[INFO]   Fold 5/5 Usando dispositivo: cuda\n",
      "[INFO]   Fold 5/5 Usando scheduler: ReduceLROnPlateau\n",
      "[INFO]   Fold 5/5 Entrenando VAE (Decoder: convtranspose, Encoder Layers: 4)...\n",
      "[INFO]   Fold 5/5 VAE E5/300, TrL: 63482.42 (R: 63373.27, KLD: 177.97), Beta: 0.613, LR: 1.00e-04, ValL: 62062.16 (R: 62009.68, KLD: 85.56)\n",
      "[INFO]   Fold 5/5 VAE E10/300, TrL: 58645.63 (R: 58150.21, KLD: 359.00), Beta: 1.380, LR: 1.00e-04, ValL: 56070.69 (R: 55065.81, KLD: 728.17)\n",
      "[INFO]   Fold 5/5 VAE E15/300, TrL: 51862.63 (R: 51149.14, KLD: 332.37), Beta: 2.147, LR: 1.00e-04, ValL: 50765.89 (R: 50121.75, KLD: 300.06)\n",
      "[INFO]   Fold 5/5 VAE E20/300, TrL: 48838.75 (R: 48203.22, KLD: 218.14), Beta: 2.913, LR: 1.00e-04, ValL: 47539.20 (R: 46937.78, KLD: 206.44)\n",
      "[INFO]   Fold 5/5 VAE E25/300, TrL: 46296.83 (R: 45643.35, KLD: 177.58), Beta: 3.680, LR: 1.00e-04, ValL: 45047.46 (R: 44304.44, KLD: 201.91)\n",
      "[INFO]   Fold 5/5 VAE E30/300, TrL: 44190.17 (R: 43537.61, KLD: 146.75), Beta: 4.447, LR: 1.00e-04, ValL: 42848.40 (R: 42085.00, KLD: 171.68)\n",
      "[INFO]   Fold 5/5 VAE E35/300, TrL: 42449.03 (R: 41822.49, KLD: 136.20), Beta: 4.600, LR: 1.00e-04, ValL: 40834.33 (R: 40198.94, KLD: 138.13)\n",
      "[INFO]   Fold 5/5 VAE E40/300, TrL: 41077.41 (R: 40480.22, KLD: 129.83), Beta: 4.600, LR: 1.00e-04, ValL: 39570.31 (R: 38955.90, KLD: 133.57)\n",
      "[INFO]   Fold 5/5 VAE E45/300, TrL: 40025.90 (R: 39423.41, KLD: 130.98), Beta: 4.600, LR: 1.00e-04, ValL: 38561.04 (R: 37974.78, KLD: 127.45)\n",
      "[INFO]   Fold 5/5 VAE E50/300, TrL: 39228.37 (R: 38615.12, KLD: 133.32), Beta: 4.600, LR: 1.00e-04, ValL: 37686.60 (R: 37136.33, KLD: 119.62)\n",
      "[INFO]   Fold 5/5 VAE E55/300, TrL: 38464.86 (R: 37875.42, KLD: 128.14), Beta: 4.600, LR: 1.00e-04, ValL: 36939.69 (R: 36454.45, KLD: 105.49)\n",
      "[INFO]   Fold 5/5 VAE E60/300, TrL: 37779.91 (R: 37178.38, KLD: 130.77), Beta: 4.600, LR: 1.00e-04, ValL: 36480.02 (R: 35962.59, KLD: 112.48)\n",
      "[INFO]   Fold 5/5 VAE E65/300, TrL: 37316.00 (R: 36698.36, KLD: 134.27), Beta: 4.600, LR: 1.00e-04, ValL: 35922.95 (R: 35398.84, KLD: 113.94)\n",
      "[INFO]   Fold 5/5 VAE E70/300, TrL: 36887.85 (R: 36244.95, KLD: 139.76), Beta: 4.600, LR: 1.00e-04, ValL: 35596.99 (R: 35024.32, KLD: 124.49)\n",
      "[INFO]   Fold 5/5 VAE E75/300, TrL: 36374.58 (R: 35732.34, KLD: 139.62), Beta: 4.600, LR: 1.00e-04, ValL: 35125.30 (R: 34600.26, KLD: 114.14)\n",
      "[INFO]   Fold 5/5 VAE E80/300, TrL: 35400.29 (R: 35263.48, KLD: 223.05), Beta: 0.613, LR: 1.00e-04, ValL: 34300.26 (R: 34174.27, KLD: 205.41)\n",
      "[INFO]   Fold 5/5 VAE E85/300, TrL: 35197.37 (R: 34866.74, KLD: 239.59), Beta: 1.380, LR: 1.00e-04, ValL: 34212.55 (R: 33890.17, KLD: 233.61)\n",
      "[INFO]   Fold 5/5 VAE E90/300, TrL: 35053.38 (R: 34582.49, KLD: 219.36), Beta: 2.147, LR: 1.00e-04, ValL: 34079.45 (R: 33665.23, KLD: 192.96)\n",
      "[INFO]   Fold 5/5 VAE E95/300, TrL: 34884.16 (R: 34321.11, KLD: 193.27), Beta: 2.913, LR: 1.00e-04, ValL: 33848.61 (R: 33364.18, KLD: 166.28)\n",
      "[INFO]   Fold 5/5 VAE E100/300, TrL: 34726.46 (R: 34094.83, KLD: 171.64), Beta: 3.680, LR: 1.00e-04, ValL: 33940.55 (R: 33390.72, KLD: 149.41)\n",
      "[INFO]   Fold 5/5 VAE E105/300, TrL: 34605.08 (R: 33891.35, KLD: 160.51), Beta: 4.447, LR: 1.00e-04, ValL: 33666.46 (R: 33059.47, KLD: 136.51)\n",
      "[INFO]   Fold 5/5 VAE E110/300, TrL: 34383.61 (R: 33678.52, KLD: 153.28), Beta: 4.600, LR: 1.00e-04, ValL: 33581.71 (R: 33004.50, KLD: 125.48)\n",
      "[INFO]   Fold 5/5 VAE E115/300, TrL: 34090.85 (R: 33386.57, KLD: 153.10), Beta: 4.600, LR: 1.00e-04, ValL: 33365.07 (R: 32787.29, KLD: 125.60)\n",
      "[INFO]   Fold 5/5 VAE E120/300, TrL: 34011.66 (R: 33290.90, KLD: 156.69), Beta: 4.600, LR: 1.00e-04, ValL: 33233.59 (R: 32656.81, KLD: 125.39)\n",
      "[INFO]   Fold 5/5 VAE E125/300, TrL: 33813.63 (R: 33097.10, KLD: 155.77), Beta: 4.600, LR: 1.00e-04, ValL: 33034.97 (R: 32435.87, KLD: 130.24)\n",
      "[INFO]   Fold 5/5 VAE E130/300, TrL: 33562.95 (R: 32833.29, KLD: 158.62), Beta: 4.600, LR: 1.00e-04, ValL: 32941.48 (R: 32370.74, KLD: 124.07)\n",
      "[INFO]   Fold 5/5 VAE E135/300, TrL: 33517.66 (R: 32776.12, KLD: 161.21), Beta: 4.600, LR: 1.00e-04, ValL: 32881.63 (R: 32249.83, KLD: 137.35)\n",
      "[INFO]   Fold 5/5 VAE E140/300, TrL: 33178.09 (R: 32461.71, KLD: 155.73), Beta: 4.600, LR: 1.00e-04, ValL: 32745.72 (R: 32162.44, KLD: 126.80)\n",
      "[INFO]   Fold 5/5 VAE E145/300, TrL: 32980.78 (R: 32265.01, KLD: 155.60), Beta: 4.600, LR: 1.00e-04, ValL: 32565.78 (R: 32002.47, KLD: 122.46)\n",
      "[INFO]   Fold 5/5 VAE E150/300, TrL: 32885.24 (R: 32165.96, KLD: 156.37), Beta: 4.600, LR: 1.00e-04, ValL: 32432.38 (R: 31831.97, KLD: 130.53)\n",
      "[INFO]   Fold 5/5 VAE E155/300, TrL: 32104.91 (R: 31973.29, KLD: 214.60), Beta: 0.613, LR: 1.00e-04, ValL: 31804.70 (R: 31688.86, KLD: 188.87)\n",
      "[INFO]   Fold 5/5 VAE E160/300, TrL: 31895.30 (R: 31554.29, KLD: 247.11), Beta: 1.380, LR: 1.00e-04, ValL: 31812.24 (R: 31511.00, KLD: 218.29)\n",
      "[INFO]   Fold 5/5 VAE E165/300, TrL: 32061.38 (R: 31545.32, KLD: 240.40), Beta: 2.147, LR: 1.00e-04, ValL: 31798.85 (R: 31359.07, KLD: 204.87)\n",
      "[INFO]   Fold 5/5 Learning rate reducido a 1.00e-05. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 5/5 VAE E170/300, TrL: 32144.60 (R: 31509.48, KLD: 218.00), Beta: 2.913, LR: 1.00e-05, ValL: 32018.96 (R: 31474.14, KLD: 187.01)\n",
      "[INFO]   Fold 5/5 VAE E175/300, TrL: 32233.07 (R: 31455.40, KLD: 211.32), Beta: 3.680, LR: 1.00e-05, ValL: 32086.58 (R: 31430.04, KLD: 178.41)\n",
      "[INFO]   Fold 5/5 VAE E180/300, TrL: 32309.02 (R: 31399.82, KLD: 204.47), Beta: 4.447, LR: 1.00e-05, ValL: 32045.82 (R: 31284.01, KLD: 171.32)\n",
      "[INFO]   Fold 5/5 Learning rate reducido a 1.00e-06. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 5/5 VAE E185/300, TrL: 32488.17 (R: 31572.44, KLD: 199.07), Beta: 4.600, LR: 1.00e-05, ValL: 32218.88 (R: 31455.73, KLD: 165.90)\n",
      "[INFO]   Fold 5/5 VAE E190/300, TrL: 32224.48 (R: 31319.34, KLD: 196.77), Beta: 4.600, LR: 1.00e-06, ValL: 32153.32 (R: 31400.00, KLD: 163.76)\n",
      "[INFO]   Fold 5/5 VAE E195/300, TrL: 32263.45 (R: 31357.06, KLD: 197.04), Beta: 4.600, LR: 1.00e-06, ValL: 32210.13 (R: 31460.24, KLD: 163.02)\n",
      "[INFO]   Fold 5/5 VAE E200/300, TrL: 32339.08 (R: 31430.73, KLD: 197.47), Beta: 4.600, LR: 1.00e-06, ValL: 31976.88 (R: 31234.13, KLD: 161.47)\n",
      "[INFO]   Fold 5/5 Learning rate reducido a 1.00e-07. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 5/5 VAE E205/300, TrL: 32295.18 (R: 31387.98, KLD: 197.22), Beta: 4.600, LR: 1.00e-07, ValL: 32156.52 (R: 31407.97, KLD: 162.73)\n",
      "[INFO]   Fold 5/5 VAE E210/300, TrL: 32192.21 (R: 31294.58, KLD: 195.14), Beta: 4.600, LR: 1.00e-07, ValL: 32029.13 (R: 31291.75, KLD: 160.30)\n",
      "[INFO]   Fold 5/5 VAE E215/300, TrL: 32263.77 (R: 31359.59, KLD: 196.56), Beta: 4.600, LR: 1.00e-07, ValL: 32017.52 (R: 31276.89, KLD: 161.01)\n",
      "[INFO]   Fold 5/5 Learning rate reducido a 1.00e-08. Reiniciando contador de early stopping.\n",
      "[INFO]   Fold 5/5 VAE E220/300, TrL: 32325.05 (R: 31422.75, KLD: 196.15), Beta: 4.600, LR: 1.00e-08, ValL: 32020.91 (R: 31277.17, KLD: 161.68)\n",
      "[INFO]   Fold 5/5 VAE E225/300, TrL: 32254.35 (R: 31352.97, KLD: 195.95), Beta: 4.600, LR: 1.00e-08, ValL: 32228.94 (R: 31486.55, KLD: 161.39)\n",
      "[INFO]   Fold 5/5 VAE E230/300, TrL: 31464.17 (R: 31344.18, KLD: 195.65), Beta: 0.613, LR: 1.00e-08, ValL: 31523.75 (R: 31424.89, KLD: 161.19)\n",
      "[INFO]   Fold 5/5 VAE E235/300, TrL: 31875.07 (R: 31602.86, KLD: 197.26), Beta: 1.380, LR: 1.00e-08, ValL: 31650.94 (R: 31428.49, KLD: 161.19)\n",
      "[INFO]   Fold 5/5 VAE E240/300, TrL: 31770.91 (R: 31352.65, KLD: 194.84), Beta: 2.147, LR: 1.00e-08, ValL: 31742.48 (R: 31396.59, KLD: 161.13)\n",
      "[INFO]   Fold 5/5 VAE E245/300, TrL: 31949.97 (R: 31379.76, KLD: 195.72), Beta: 2.913, LR: 1.00e-08, ValL: 31885.68 (R: 31417.63, KLD: 160.66)\n",
      "[INFO]   Fold 5/5 VAE E250/300, TrL: 31985.04 (R: 31265.52, KLD: 195.52), Beta: 3.680, LR: 1.00e-08, ValL: 31942.85 (R: 31350.94, KLD: 160.85)\n",
      "[INFO]   Fold 5/5 VAE E255/300, TrL: 32231.65 (R: 31356.08, KLD: 196.90), Beta: 4.447, LR: 1.00e-08, ValL: 32174.11 (R: 31456.33, KLD: 161.42)\n",
      "[INFO]   Fold 5/5 Early stopping VAE en epoch 256. Mejor val_loss: 31358.6978\n",
      "[INFO]   Fold 5/5 VAE final model loaded (best val_loss: 31358.6978).\n",
      "[INFO]   Fold 5/5 Modelo VAE guardado en: resultados_FIN_v2/fold_5/vae_model_fold_5.pt\n",
      "[INFO] Fold 5/5 Pool Train/Dev (Clasificador) (N=148):\n",
      "    ResearchGroup_Mapped:\n",
      "      AD: 76 (51.4%)\n",
      "      CN: 72 (48.6%)\n",
      "    Sex:\n",
      "      F: 74 (50.0%)\n",
      "      M: 74 (50.0%)\n",
      "[INFO]   Añadiendo metadatos al clasificador: ['Age', 'Sex']\n",
      "[INFO]   Forma final del set de entrenamiento del clasificador: (148, 514)\n",
      "[INFO]     --- Entrenando Clasificador: xgb ---\n",
      "[XGBoost] ➜  Se usará GPU (device=cuda)\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'xgb'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para xgb: {'model__n_estimators': 1073, 'model__learning_rate': 0.0754616663600324, 'model__max_depth': 7, 'model__subsample': 0.6541447367309678, 'model__colsample_bytree': 0.23423538144403036, 'model__min_child_weight': 3.176720082443378}\n",
      "[INFO]       Modelo final (pipeline) para xgb listo.\n",
      "[INFO]       Resultados Fold 5 (xgb): AUC=0.7895, Bal.Acc=0.7508\n",
      "[INFO]       Pipeline completo de xgb del fold 5 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: svm ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'svm'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para svm: {'model__estimator__C': 389.5992574576285, 'model__estimator__gamma': 9.195570076294414e-06, 'model__estimator__kernel': 'rbf'}\n",
      "[INFO]       Modelo final (pipeline) para svm listo.\n",
      "[INFO]       Resultados Fold 5 (svm): AUC=0.7368, Bal.Acc=0.7012\n",
      "[INFO]       Pipeline completo de svm del fold 5 guardado.\n",
      "[INFO]     --- Entrenando Clasificador: logreg ---\n",
      "[INFO] [SMOTE] ➜ Usando implementación de imblearn (CPU) para el clasificador 'logreg'.\n",
      "[INFO]       Usando Optuna MedianPruner para acelerar la búsqueda.\n",
      "[INFO]       Mejores HPs para logreg: {'model__C': 0.0017283500508427274}\n",
      "[INFO]       Modelo final (pipeline) para logreg listo.\n",
      "[INFO]       Resultados Fold 5 (logreg): AUC=0.7554, Bal.Acc=0.6950\n",
      "[INFO]       Pipeline completo de logreg del fold 5 guardado.\n",
      "[INFO]   Fold 5/5 completado en 286.65 segundos.\n",
      "[INFO] \n",
      "--- Resumen de Rendimiento para Clasificador: xgb (Promedio sobre Folds Externos) ---\n",
      "[INFO] Auc                 : 0.8135 +/- 0.0459\n",
      "[INFO] Pr_auc              : 0.8074 +/- 0.0663\n",
      "[INFO] Accuracy            : 0.7608 +/- 0.0447\n",
      "[INFO] Balanced_accuracy   : 0.7613 +/- 0.0451\n",
      "[INFO] Sensitivity         : 0.7474 +/- 0.0440\n",
      "[INFO] Specificity         : 0.7752 +/- 0.0683\n",
      "[INFO] F1_score            : 0.7637 +/- 0.0429\n",
      "[INFO] \n",
      "--- Resumen de Rendimiento para Clasificador: svm (Promedio sobre Folds Externos) ---\n",
      "[INFO] Auc                 : 0.7591 +/- 0.0527\n",
      "[INFO] Pr_auc              : 0.7588 +/- 0.0771\n",
      "[INFO] Accuracy            : 0.7227 +/- 0.0367\n",
      "[INFO] Balanced_accuracy   : 0.7236 +/- 0.0374\n",
      "[INFO] Sensitivity         : 0.7158 +/- 0.1091\n",
      "[INFO] Specificity         : 0.7314 +/- 0.1422\n",
      "[INFO] F1_score            : 0.7254 +/- 0.0384\n",
      "[INFO] \n",
      "--- Resumen de Rendimiento para Clasificador: logreg (Promedio sobre Folds Externos) ---\n",
      "[INFO] Auc                 : 0.7985 +/- 0.0713\n",
      "[INFO] Pr_auc              : 0.8000 +/- 0.0796\n",
      "[INFO] Accuracy            : 0.7227 +/- 0.0367\n",
      "[INFO] Balanced_accuracy   : 0.7218 +/- 0.0363\n",
      "[INFO] Sensitivity         : 0.7579 +/- 0.0600\n",
      "[INFO] Specificity         : 0.6856 +/- 0.0474\n",
      "[INFO] F1_score            : 0.7378 +/- 0.0372\n",
      "[INFO] Resultados detallados de todos los clasificadores guardados en: resultados_FIN_v2/all_folds_metrics_MULTI_xgb_vaeconvtranspose4l_ld512_beta4.6_normzscore_offdiag_ch3sel_intFCquarter_drop0.2_ln0_outer5x1_scoreroc_auc.csv\n",
      "[INFO] Sumario estadístico de métricas (por clasificador) guardado en: resultados_FIN_v2/summary_metrics_MULTI_xgb_vaeconvtranspose4l_ld512_beta4.6_normzscore_offdiag_ch3sel_intFCquarter_drop0.2_ln0_outer5x1_scoreroc_auc.txt\n",
      "[INFO] Pipeline completo en 1251.75 segundos.\n",
      "[INFO] --- Consideraciones Finales ---\n",
      "[INFO] Normalización: 'zscore_offdiag'. Activación VAE: 'tanh'. Asegurar compatibilidad.\n"
     ]
    }
   ],
   "source": [
    "!python serentipia3.py \\\n",
    "    --global_tensor_path /home/diego/Escritorio/limpio/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz \\\n",
    "    --metadata_path /home/diego/Escritorio/limpio/SubjectsData_AAL3_procesado.csv \\\n",
    "    --output_dir ./resultados_FIN_v2 \\\n",
    "    --channels_to_use 1 2 5 \\\n",
    "    --classifier_types xgb svm logreg \\\n",
    "    --classifier_calibrate \\\n",
    "    --outer_folds 5 \\\n",
    "    --repeated_outer_folds_n_repeats 1 \\\n",
    "    --epochs_vae 300 \\\n",
    "    --early_stopping_patience_vae 30 \\\n",
    "    --batch_size 64 \\\n",
    "    --beta_vae 4.6 \\\n",
    "    --latent_dim 512 \\\n",
    "    --n_jobs_gridsearch 8 \\\n",
    "    --metadata_features Age Sex \\\n",
    "    --use_smote \\\n",
    "    --use_optuna_pruner \\\n",
    "    --classifier_use_class_weight \\\n",
    "    --save_fold_artefacts \\\n",
    "    --gridsearch_scoring roc_auc \\\n",
    "    --save_vae_training_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
